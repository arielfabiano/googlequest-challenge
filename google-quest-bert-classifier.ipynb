{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple BERT test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing preprocessed dataset with BERT minimalistic model from: https://www.kaggle.com/khoongweihao/bert-base-tf2-0-minimalistic-iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def set_seeds(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "SEED = 21937\n",
    "set_seeds(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dset = pd.read_csv(\"../input/google-quest-challenge/train.csv\")   # index_col='qa_id'\n",
    "test_dset = pd.read_csv(\"../input/google-quest-challenge/test.csv\")   # index_col='qa_id'\n",
    "df_sub = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\n",
    "\n",
    "free_text_columns = ['question_title', 'question_body', 'answer']\n",
    "\n",
    "category_columns = ['host', 'category']\n",
    "\n",
    "discard_columns = ['question_user_name', 'question_user_page',  'answer_user_name', 'answer_user_page', 'url']\n",
    "\n",
    "target_columns = ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational',\n",
    "                  'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                  'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent',\n",
    "                  'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                  'question_type_compare', 'question_type_consequence', 'question_type_definition',\n",
    "                  'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                  'question_type_reason_explanation', 'question_type_spelling', 'question_well_written',\n",
    "                  'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                  'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure',\n",
    "                  'answer_type_reason_explanation', 'answer_well_written']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../input/google-quest-challenge/'\n",
    "BERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n",
    "tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "\n",
    "output_categories = target_columns\n",
    "input_categories = ['question_title', 'question_body', 'answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = q[:q_new_len]\n",
    "        a = a[:a_new_len]\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, prefix, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance[prefix+'question_title'], instance[prefix+'question_body'], instance[prefix+'answer']   # instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "def compute_spearmanr2(preds, trues):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.nanmean(rhos), rhos\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predicted = self.model.predict(self.valid_inputs, batch_size=self.batch_size)\n",
    "        self.valid_predictions.append(predicted)\n",
    "        \n",
    "        rho_val = compute_spearmanr(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(f'epoch = {epoch}, valid_spearman = {rho_val}') \n",
    "        self.test_predictions.append(\n",
    "            self.model.predict(self.test_inputs, batch_size=self.batch_size))\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        score, rho_cols = compute_spearmanr2(np.average(self.valid_predictions, axis=0), self.valid_outputs)\n",
    "        rho_print = [print(target_columns[i] + \" rho: \" + str(rho_cols[i]) ) for i in range(0, len(target_columns))]  \n",
    "       \n",
    "        \n",
    "        \n",
    "def bert_model():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    pooled_output, _ = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    x = pooled_output\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n",
    "    \n",
    "    return model    \n",
    "        \n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold):\n",
    "        \n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=None)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed4f562bd1d4fb9a021565325a3c51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fadbc6cf6942e8891d48e97d5c0f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=5).split(X=train_dset.question_body, groups=train_dset.question_body)\n",
    "\n",
    "prefix = '' # 'clean_'\n",
    "outputs = compute_output_arrays(train_dset, output_categories)\n",
    "inputs = compute_input_arays(train_dset, input_categories, prefix, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arays(test_dset, input_categories, prefix, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.4053epoch = 0, valid_spearman = 0.3362605803587327\n",
      "4863/4863 [==============================] - 385s 79ms/sample - loss: 0.4053\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3687epoch = 1, valid_spearman = 0.36818624663054306\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3688\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3503epoch = 2, valid_spearman = 0.38164785407022533\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3503\n",
      "question_asker_intent_understanding rho: 0.40415201425893954\n",
      "question_body_critical rho: 0.6192314856316665\n",
      "question_conversational rho: 0.3782009668242842\n",
      "question_expect_short_answer rho: 0.3064941780446292\n",
      "question_fact_seeking rho: 0.33423235844269905\n",
      "question_has_commonly_accepted_answer rho: 0.4192171610591253\n",
      "question_interestingness_others rho: 0.3115673087139921\n",
      "question_interestingness_self rho: 0.46377248499820445\n",
      "question_multi_intent rho: 0.5211748057433565\n",
      "question_not_really_a_question rho: 0.05860357073554366\n",
      "question_opinion_seeking rho: 0.41233348541703746\n",
      "question_type_choice rho: 0.7194969720604961\n",
      "question_type_compare rho: 0.37181291767247\n",
      "question_type_consequence rho: 0.13328805106321928\n",
      "question_type_definition rho: 0.36405631146187245\n",
      "question_type_entity rho: 0.5081657821332632\n",
      "question_type_instructions rho: 0.7891357354455362\n",
      "question_type_procedure rho: 0.36466401136164456\n",
      "question_type_reason_explanation rho: 0.6295146154367056\n",
      "question_type_spelling rho: 0.01417974873107578\n",
      "question_well_written rho: 0.4714065442223862\n",
      "answer_helpful rho: 0.2104823004348334\n",
      "answer_level_of_information rho: 0.30230324817168025\n",
      "answer_plausible rho: 0.06330475997496976\n",
      "answer_relevance rho: 0.14289128306503412\n",
      "answer_satisfaction rho: 0.25904216994502344\n",
      "answer_type_instructions rho: 0.7635989623714259\n",
      "answer_type_procedure rho: 0.3222387530507182\n",
      "answer_type_reason_explanation rho: 0.6406701468747596\n",
      "answer_well_written rho: 0.15021480160854497\n",
      "fold 1\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.4035epoch = 0, valid_spearman = 0.3342393391379336\n",
      "4863/4863 [==============================] - 382s 79ms/sample - loss: 0.4035\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3673epoch = 1, valid_spearman = 0.35930802797798556\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3674\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3481epoch = 2, valid_spearman = 0.37087834735986325\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3481\n",
      "question_asker_intent_understanding rho: 0.38011262692544373\n",
      "question_body_critical rho: 0.6265438097865128\n",
      "question_conversational rho: 0.38536975041846055\n",
      "question_expect_short_answer rho: 0.287571626067831\n",
      "question_fact_seeking rho: 0.36689311154502713\n",
      "question_has_commonly_accepted_answer rho: 0.41342103637428795\n",
      "question_interestingness_others rho: 0.3054760480740133\n",
      "question_interestingness_self rho: 0.42706483192952904\n",
      "question_multi_intent rho: 0.4995499211341816\n",
      "question_not_really_a_question rho: 0.07567478750597441\n",
      "question_opinion_seeking rho: 0.46516787147018296\n",
      "question_type_choice rho: 0.7277788879642398\n",
      "question_type_compare rho: 0.3531152596864215\n",
      "question_type_consequence rho: 0.13964051207291855\n",
      "question_type_definition rho: 0.2872694825567061\n",
      "question_type_entity rho: 0.40197754863020246\n",
      "question_type_instructions rho: 0.7757342313036861\n",
      "question_type_procedure rho: 0.33366589160334087\n",
      "question_type_reason_explanation rho: 0.6329586566041874\n",
      "question_type_spelling rho: -0.015982706872782717\n",
      "question_well_written rho: 0.4894107646254645\n",
      "answer_helpful rho: 0.17313435914919198\n",
      "answer_level_of_information rho: 0.3549150605756647\n",
      "answer_plausible rho: 0.06243759960124451\n",
      "answer_relevance rho: 0.13075555215155943\n",
      "answer_satisfaction rho: 0.31484945874178094\n",
      "answer_type_instructions rho: 0.7281110398588111\n",
      "answer_type_procedure rho: 0.2412106668016304\n",
      "answer_type_reason_explanation rho: 0.6406286497748721\n",
      "answer_well_written rho: 0.12192039970491778\n",
      "fold 2\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.4065epoch = 0, valid_spearman = 0.3524492223299859\n",
      "4863/4863 [==============================] - 381s 78ms/sample - loss: 0.4064\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3687epoch = 1, valid_spearman = 0.38436810766026014\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3687\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3508epoch = 2, valid_spearman = 0.39632869445974706\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3508\n",
      "question_asker_intent_understanding rho: 0.3653493126076441\n",
      "question_body_critical rho: 0.5836389075601571\n",
      "question_conversational rho: 0.45394998112171947\n",
      "question_expect_short_answer rho: 0.3169288749469849\n",
      "question_fact_seeking rho: 0.3780510080427803\n",
      "question_has_commonly_accepted_answer rho: 0.47681054349927465\n",
      "question_interestingness_others rho: 0.33936655433110857\n",
      "question_interestingness_self rho: 0.5227057720513959\n",
      "question_multi_intent rho: 0.5260612542508698\n",
      "question_not_really_a_question rho: 0.04796811035865465\n",
      "question_opinion_seeking rho: 0.538091002483417\n",
      "question_type_choice rho: 0.7252119866223818\n",
      "question_type_compare rho: 0.3594106892190457\n",
      "question_type_consequence rho: 0.18495374492604982\n",
      "question_type_definition rho: 0.36121287600678154\n",
      "question_type_entity rho: 0.42056915155273505\n",
      "question_type_instructions rho: 0.7903332779579243\n",
      "question_type_procedure rho: 0.33578550766997506\n",
      "question_type_reason_explanation rho: 0.6685218847225954\n",
      "question_type_spelling rho: 0.04902625344382882\n",
      "question_well_written rho: 0.5238792483617645\n",
      "answer_helpful rho: 0.17263006749231177\n",
      "answer_level_of_information rho: 0.3396112850659627\n",
      "answer_plausible rho: 0.09578732564655236\n",
      "answer_relevance rho: 0.13578647539902133\n",
      "answer_satisfaction rho: 0.27042308751997723\n",
      "answer_type_instructions rho: 0.7731393705947303\n",
      "answer_type_procedure rho: 0.2852802579942853\n",
      "answer_type_reason_explanation rho: 0.6901310607255736\n",
      "answer_well_written rho: 0.1592884650578389\n",
      "fold 3\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.4084epoch = 0, valid_spearman = 0.34785425105500806\n",
      "4863/4863 [==============================] - 379s 78ms/sample - loss: 0.4083\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3708epoch = 1, valid_spearman = 0.37066050659117133\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3709\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3522epoch = 2, valid_spearman = 0.3836567775499925\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3522\n",
      "question_asker_intent_understanding rho: 0.31632880063242136\n",
      "question_body_critical rho: 0.5956025918020473\n",
      "question_conversational rho: 0.42824064569677533\n",
      "question_expect_short_answer rho: 0.3019767225176249\n",
      "question_fact_seeking rho: 0.3398898062862296\n",
      "question_has_commonly_accepted_answer rho: 0.39749957871738617\n",
      "question_interestingness_others rho: 0.34403752026577267\n",
      "question_interestingness_self rho: 0.46769265597978266\n",
      "question_multi_intent rho: 0.5918901580914203\n",
      "question_not_really_a_question rho: 0.023723066528821918\n",
      "question_opinion_seeking rho: 0.4411008053462905\n",
      "question_type_choice rho: 0.728943981957284\n",
      "question_type_compare rho: 0.31583397679840974\n",
      "question_type_consequence rho: 0.1944933799948364\n",
      "question_type_definition rho: 0.3749787753496498\n",
      "question_type_entity rho: 0.37597965093376456\n",
      "question_type_instructions rho: 0.7751235012883165\n",
      "question_type_procedure rho: 0.3837847552375005\n",
      "question_type_reason_explanation rho: 0.6999882406778908\n",
      "question_type_spelling rho: 0.0676424741202688\n",
      "question_well_written rho: 0.4478297982188251\n",
      "answer_helpful rho: 0.1525217628587533\n",
      "answer_level_of_information rho: 0.33971534554648786\n",
      "answer_plausible rho: 0.11233609728289885\n",
      "answer_relevance rho: 0.14402517126064623\n",
      "answer_satisfaction rho: 0.26490022317085865\n",
      "answer_type_instructions rho: 0.7585881101534965\n",
      "answer_type_procedure rho: 0.294754554489306\n",
      "answer_type_reason_explanation rho: 0.6919910535310864\n",
      "answer_well_written rho: 0.13829936577923174\n",
      "fold 4\n",
      "Train on 4864 samples\n",
      "Epoch 1/3\n",
      "4856/4864 [============================>.] - ETA: 0s - loss: 0.4068epoch = 0, valid_spearman = 0.33736486183953424\n",
      "4864/4864 [==============================] - 376s 77ms/sample - loss: 0.4068\n",
      "Epoch 2/3\n",
      "4856/4864 [============================>.] - ETA: 0s - loss: 0.3683epoch = 1, valid_spearman = 0.36514114490513516\n",
      "4864/4864 [==============================] - 351s 72ms/sample - loss: 0.3683\n",
      "Epoch 3/3\n",
      "4856/4864 [============================>.] - ETA: 0s - loss: 0.3501epoch = 2, valid_spearman = 0.3746977339642789\n",
      "4864/4864 [==============================] - 351s 72ms/sample - loss: 0.3500\n",
      "question_asker_intent_understanding rho: 0.3477296689461147\n",
      "question_body_critical rho: 0.564648542639959\n",
      "question_conversational rho: 0.35347923948627463\n",
      "question_expect_short_answer rho: 0.30509838458711763\n",
      "question_fact_seeking rho: 0.278523318456375\n",
      "question_has_commonly_accepted_answer rho: 0.4101974025284646\n",
      "question_interestingness_others rho: 0.3435708926488109\n",
      "question_interestingness_self rho: 0.49931277178668954\n",
      "question_multi_intent rho: 0.5354767758132911\n",
      "question_not_really_a_question rho: 0.040466836588094426\n",
      "question_opinion_seeking rho: 0.4164460060921022\n",
      "question_type_choice rho: 0.7047648950799\n",
      "question_type_compare rho: 0.3028233776456231\n",
      "question_type_consequence rho: 0.16875649512053023\n",
      "question_type_definition rho: 0.3729641402556917\n",
      "question_type_entity rho: 0.4708375594490165\n",
      "question_type_instructions rho: 0.7555011856530496\n",
      "question_type_procedure rho: 0.32285676499090865\n",
      "question_type_reason_explanation rho: 0.6559860687230499\n",
      "question_type_spelling rho: 0.08537734141594959\n",
      "question_well_written rho: 0.5250485806813978\n",
      "answer_helpful rho: 0.14332570893550028\n",
      "answer_level_of_information rho: 0.33134617765493635\n",
      "answer_plausible rho: 0.1208480164657896\n",
      "answer_relevance rho: 0.13773012272472823\n",
      "answer_satisfaction rho: 0.18719971141818573\n",
      "answer_type_instructions rho: 0.7527906552888377\n",
      "answer_type_procedure rho: 0.25318688034661785\n",
      "answer_type_reason_explanation rho: 0.659867030826842\n",
      "answer_well_written rho: 0.19476825054582805\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    print(f\"fold {fold}\")\n",
    "    K.clear_session()\n",
    "    model = bert_model()\n",
    "\n",
    "    train_inputs = [inputs[i][train_idx] for i in range(3)]\n",
    "    train_outputs = outputs[train_idx]\n",
    "\n",
    "    valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n",
    "    valid_outputs = outputs[valid_idx]\n",
    "\n",
    "    # history contains two lists of valid and test preds respectively:\n",
    "    #  [valid_predictions_{fold}, test_predictions_{fold}]\n",
    "    history = train_and_predict(model, \n",
    "                      train_data=(train_inputs, train_outputs), \n",
    "                      valid_data=(valid_inputs, valid_outputs),\n",
    "                      test_data=test_inputs, \n",
    "                      learning_rate=3e-5, epochs=3, batch_size=8,\n",
    "                      loss_function='binary_crossentropy', fold=fold)\n",
    "\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = [histories[i].test_predictions for i in range(len(histories))]\n",
    "test_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\n",
    "test_predictions = np.mean(test_predictions, axis=0)\n",
    "\n",
    "df_sub.iloc[:, 1:] = test_predictions\n",
    "\n",
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ed4f562bd1d4fb9a021565325a3c51e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5b80446a8bb246ff9d67fa570bda96fe",
        "IPY_MODEL_84c5f9eb84984ef3af0fa13f471fa141"
       ],
       "layout": "IPY_MODEL_f8dcf085f0744f33a505ed59403bf444"
      }
     },
     "1098bb0095b14411a0dad82b35111a66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "131cd178f7da4150954a3901e88ff003": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b99b0bd5cc10452599ed3005a7f2bd84",
       "placeholder": "​",
       "style": "IPY_MODEL_953bea966ae040e8b4c4774eff94cf17",
       "value": " 476/? [00:07&lt;00:00, 62.11it/s]"
      }
     },
     "23cc4fc48762430988d17e4c4b0aa90a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50efa2983fa34a488d2e425c14f1212d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5b80446a8bb246ff9d67fa570bda96fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1098bb0095b14411a0dad82b35111a66",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b673996c7aca4befbba7258f44ea3b9b",
       "value": 1
      }
     },
     "72fadbc6cf6942e8891d48e97d5c0f33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e885c65203e64c4d869dfbd4bbb24672",
        "IPY_MODEL_131cd178f7da4150954a3901e88ff003"
       ],
       "layout": "IPY_MODEL_8f961d0810b04d96ae9938094df4d5e8"
      }
     },
     "84c5f9eb84984ef3af0fa13f471fa141": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e46abdc7a9974440bdef8ae13bdf2053",
       "placeholder": "​",
       "style": "IPY_MODEL_50efa2983fa34a488d2e425c14f1212d",
       "value": " 6079/? [01:22&lt;00:00, 74.03it/s]"
      }
     },
     "8f961d0810b04d96ae9938094df4d5e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "953bea966ae040e8b4c4774eff94cf17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b673996c7aca4befbba7258f44ea3b9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b99b0bd5cc10452599ed3005a7f2bd84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e46abdc7a9974440bdef8ae13bdf2053": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e885c65203e64c4d869dfbd4bbb24672": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_23cc4fc48762430988d17e4c4b0aa90a",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ea34e18d524a4d3fa0c9c7bcc53c32fd",
       "value": 1
      }
     },
     "ea34e18d524a4d3fa0c9c7bcc53c32fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f8dcf085f0744f33a505ed59403bf444": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
