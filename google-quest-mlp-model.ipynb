{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "SEED = 21937\n",
    "set_seeds(SEED)\n",
    "\n",
    "SVD_QTY = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_colwidth', 120)\n",
    "\n",
    "train_dset = pd.read_csv(\"../input/google-quest-challenge/train.csv\", index_col='qa_id')\n",
    "test_dset = pd.read_csv(\"../input/google-quest-challenge/test.csv\", index_col='qa_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection of columns based of possibility of feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_text_columns = ['question_title', 'question_body', 'answer']\n",
    "\n",
    "category_columns = ['host', 'category']\n",
    "\n",
    "discard_columns = ['question_user_name', 'question_user_page',  'answer_user_name', 'answer_user_page', 'url']\n",
    "\n",
    "target_columns = ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational',\n",
    "                  'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                  'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent',\n",
    "                  'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                  'question_type_compare', 'question_type_consequence', 'question_type_definition',\n",
    "                  'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                  'question_type_reason_explanation', 'question_type_spelling', 'question_well_written',\n",
    "                  'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                  'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure',\n",
    "                  'answer_type_reason_explanation', 'answer_well_written']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_dset[target_columns].copy()\n",
    "train_dset = train_dset.drop(target_columns+discard_columns, axis=1)\n",
    "\n",
    "test_ids = test_dset.index\n",
    "test_dset = test_dset.drop(discard_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Tools class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import (sent_tokenize,\n",
    "                  word_tokenize,\n",
    "                  pos_tag)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "\n",
    "class NlpUtils:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.html_regex = re.compile('<.*?>')\n",
    "        self.stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "    def nlp_text(self, corpus: str) -> list:\n",
    "        \"\"\"\n",
    "        Processes a text by transforming it into a cleaned and lemmatized str, also counting PoSTags\n",
    "        \"\"\"\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        corpus = self._text_cleanup(corpus.strip())\n",
    "        pos_tag_counter = defaultdict(int)\n",
    "        corpus_tokens = []\n",
    "        if len(corpus) > 0:\n",
    "            corpus, pos_tag_counter, corpus_tokens = self._stopword_postag_lemma(corpus, lemmatizer)\n",
    "        return corpus, pos_tag_counter, corpus_tokens\n",
    "\n",
    "    def _text_cleanup(self, corpus: str) -> str:\n",
    "        \"\"\" General purpose text cleaner (removes html code and unnecessary punctuation for NLP) \"\"\"\n",
    "        corpus = corpus.lower()\n",
    "        if corpus != ' ' and re.search(r'\\w', corpus):\n",
    "            corpus = re.sub(self.html_regex, '', corpus)    # Remove html code blocks\n",
    "            corpus = re.sub(r'[;:,.!?\\n\\r]', '.', corpus).strip()   # Replace all sentence split punctuation by dot\n",
    "            if re.search(r'\\.+[a-z]', corpus):    # Sentence punctuation followed directly by char separation\n",
    "                corpus = re.sub(r'\\.+[a-z]', '. ', corpus)\n",
    "            corpus = re.sub(r'[\\\"\\'-()#@<>{}`+=~|\\[\\]]', ' ', corpus)   # Clean rest of usual symbols\n",
    "            if not corpus.endswith(\".\") or corpus.endswith(\" .\"):\n",
    "                corpus += \".\"\n",
    "        else:\n",
    "            corpus = \"\"\n",
    "        return corpus\n",
    "\n",
    "    def _split_delete_stopwords(self, text: str) -> (list, list):\n",
    "        \"\"\"\n",
    "        English stopword removal from a text and word tokenizer\n",
    "        \"\"\"\n",
    "        text_words = word_tokenize(text)\n",
    "        text_tokens_filtered = [word for word in text_words if word not in self.stopwords_set]\n",
    "        text_words = list(filter(lambda x: x != '.', text_words))\n",
    "        return text_tokens_filtered, text_words\n",
    "\n",
    "    def _stopword_postag_lemma(self, text: str, lemmatizer: WordNetLemmatizer) -> (str, dict, list):\n",
    "        \"\"\" Word Tokenizes a text, removing stopwords and then lemmatizes by PoSTagging (keeps ADJ, ADV, NOUN, VERB)\n",
    "            Returns cleaned text (no stopwords and lemmatized), PoSTag stats and word tokenized text \"\"\"\n",
    "        text_tokens_filtered, text_tokens = self._split_delete_stopwords(text)\n",
    "\n",
    "        sentence_pos_tag = pos_tag(text_tokens_filtered)\n",
    "        sentence_pos_tag_lemmas = []\n",
    "        pos_tag_counter = defaultdict(int)\n",
    "        for word, tag in sentence_pos_tag:\n",
    "            pos_tag_counter[tag] += 1\n",
    "            wordnet_tag = tag[0].lower()\n",
    "            wordnet_tag = wordnet_tag if wordnet_tag in ['a', 'r', 'n', 'v'] else None\n",
    "            if not wordnet_tag:\n",
    "                lemma = word\n",
    "            else:\n",
    "                lemma = lemmatizer.lemmatize(word, wordnet_tag)\n",
    "            sentence_pos_tag_lemmas.append(lemma)\n",
    "        result = ' '.join(sentence_pos_tag_lemmas)\n",
    "        return result, pos_tag_counter, text_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "\n",
    "\n",
    "nlp_utils = NlpUtils()\n",
    "POS_TAGS = ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS',\n",
    "            'PDT', 'POS', 'PRP', 'PRP', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP',\n",
    "            'VBZ', 'WDT', 'WP', 'WP', 'WRB']\n",
    "STOPWORDS_SET = set(stopwords.words('english'))\n",
    "PUNCTUATION_SET = {';', ':', ',', '.', '!', '?', '\\n', '\\r', '-', '(', ')', '`', '$', '<', '>', '=', '+'}\n",
    "QUESTION_WORDS = {'who', 'what', 'why', 'how', 'where', 'when', 'with', 'whose', 'whom', 'if', 'or'}\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text.apply(lambda x: pd.Series(nlp_utils.nlp_text(x)))\n",
    "\n",
    "\n",
    "def oh_encoder() -> Pipeline:\n",
    "    return Pipeline([('OHE', OneHotEncoder(drop_invariant=True))], verbose=True)\n",
    "\n",
    "\n",
    "def tfidf_pipeline() -> Pipeline:\n",
    "    return Pipeline([\n",
    "        ('Text-TF-IDF', TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=2, max_df=0.7, lowercase=False)),\n",
    "        ('Text-SVD', TruncatedSVD(n_components=SVD_QTY))], verbose=True)\n",
    "\n",
    "\n",
    "def custom_transformer(method) -> Pipeline:\n",
    "    return Pipeline([\n",
    "        ('Custom Function', FunctionTransformer(method, validate=False)),\n",
    "        ], verbose=True)\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def char_count(text: pd.Series) -> int:\n",
    "    return pd.DataFrame(text.apply(lambda row: len(row)))\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def word_count(text: pd.Series) -> int:\n",
    "    \"\"\" Given a word tokenized text it returns the quantity of words\"\"\"\n",
    "    return pd.DataFrame(text.apply(lambda row: len(row)))\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def unique_word_count(text: pd.Series) -> int:\n",
    "    \"\"\" Given a preprocessed text it returns the quantity of unique words \"\"\"\n",
    "    return pd.DataFrame(text.apply(lambda row: len(set(word_tokenize(row)))))\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def sentence_count(text: pd.Series) -> int:\n",
    "    return pd.DataFrame(text.apply(lambda row: len(sent_tokenize(row))))\n",
    "\n",
    "\n",
    "def postag_ratio_calc(postag_dict: dict) -> pd.DataFrame:\n",
    "    total_tags = sum(postag_dict.values())\n",
    "    postag_counter = {}\n",
    "    for tag in POS_TAGS:\n",
    "        try:\n",
    "            postag_counter[tag] = postag_dict.get(tag, 0) / total_tags\n",
    "        except ZeroDivisionError:\n",
    "            postag_counter[tag] = 0.0\n",
    "    return pd.DataFrame(postag_counter, index=[0]).iloc[0]\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def postag_ratio(postag_dict: pd.Series) -> pd.DataFrame:\n",
    "    return pd.DataFrame(postag_dict.apply(lambda row: postag_ratio_calc(row)))\n",
    "\n",
    "\n",
    "def match_word_calc(text_1: str, text_2: str) -> (float, float):\n",
    "    words_text_1 = set(text_1.replace('.', '').split(' '))\n",
    "    words_text_2 = set(text_2.replace('.', '').split(' '))\n",
    "    match_len = len(words_text_1 & words_text_2)\n",
    "    try:\n",
    "        text_1_ratio = match_len / len(words_text_1)\n",
    "        text_2_ratio = match_len / len(words_text_2)\n",
    "    except ZeroDivisionError:\n",
    "        text_1_ratio = text_2_ratio = 0.0\n",
    "    return text_1_ratio, text_2_ratio\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def matching_words(text_cols: pd.DataFrame) -> pd.DataFrame:\n",
    "    return text_cols.apply(lambda row: match_word_calc(row[0], row[1]), result_type='expand', axis=1)\n",
    "\n",
    "\n",
    "def stopword_ratio_calc(tokenized_text: str) -> float:\n",
    "    word_count = len(tokenized_text)\n",
    "    stopword_count = sum([1 if word.lower() in STOPWORDS_SET else 0 for word in tokenized_text])\n",
    "    try:\n",
    "        return stopword_count/word_count\n",
    "    except ZeroDivisionError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def stopword_ratio(text: pd.Series) -> pd.DataFrame:\n",
    "    return pd.DataFrame(text.apply(lambda row: stopword_ratio_calc(row)))\n",
    "\n",
    "\n",
    "def uppercase_ratio_calc(text: str) -> (float, float):\n",
    "    tokens = word_tokenize(text)\n",
    "    word_qty = len(tokens)\n",
    "    word_uppercase_count = sum([1 if word[0].isupper() else 0 for word in tokens])\n",
    "    char_qty = len(text)\n",
    "    total_uppercase_count = len(re.findall(r'[A-Z]', text))\n",
    "    try:\n",
    "        word_ratio = word_uppercase_count / word_qty\n",
    "        char_ratio = total_uppercase_count / char_qty\n",
    "    except ZeroDivisionError:\n",
    "        word_ratio = char_ratio = 0.0\n",
    "    return word_ratio, char_ratio\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def uppercase_ratio(text: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\" Given a word tokenized text it returns the ratio of words that begin with uppercase\n",
    "        and the ratio of uppercase letters\"\"\"\n",
    "    return text.to_frame().apply(lambda row: uppercase_ratio_calc(row[0]), result_type='expand', axis=1)\n",
    "\n",
    "\n",
    "def punctuation_count_calc(text: str) -> pd.DataFrame:\n",
    "    punct_counter = defaultdict(int)\n",
    "    for i, punctuation in enumerate(PUNCTUATION_SET):\n",
    "        punct_counter['key'+str(i)] = len(re.findall('[{}]'.format(punctuation), text))\n",
    "    return pd.DataFrame(punct_counter, index=[0]).iloc[0]\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def punctuation_count(text: pd.Series) -> pd.DataFrame:\n",
    "    return pd.DataFrame(text.apply(lambda row: punctuation_count_calc(row)))\n",
    "\n",
    "\n",
    "def qwords_count_calc(text: str) -> pd.DataFrame:\n",
    "    text = text.lower()\n",
    "    qword_counter = defaultdict(int)\n",
    "    for i, question in enumerate(QUESTION_WORDS):\n",
    "        qword_counter['key'+str(i)] = len(re.findall('[{}]'.format(question), text))\n",
    "    return pd.DataFrame(qword_counter, index=[0]).iloc[0]\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def qwords_count(text: pd.Series) -> pd.DataFrame:\n",
    "    return pd.DataFrame(text.apply(lambda row: qwords_count_calc(row)))\n",
    "\n",
    "\n",
    "@custom_transformer\n",
    "def number_count(text: pd.Series) -> pd.DataFrame:\n",
    "    return pd.DataFrame(text.apply(lambda row: len(re.findall(r'[0-9]', row))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in free_text_columns:\n",
    "    train_dset[['clean_'+col, 'postags_'+col, 'tokens_'+col]] = preprocess_text(train_dset[col])\n",
    "    test_dset[['clean_'+col, 'postags_'+col, 'tokens_'+col]] = preprocess_text(test_dset[col])\n",
    "\n",
    "train_dset['qt_qb'] = train_dset['question_title'] + '. ' + train_dset['question_body']\n",
    "train_dset['qb_a'] = train_dset['question_body'] + '. ' + train_dset['answer']\n",
    "train_dset['clean_qt_qb'] = train_dset['clean_question_title'] + '. ' + train_dset['clean_question_body']\n",
    "train_dset['clean_qb_a'] = train_dset['clean_question_body'] + '. ' + train_dset['clean_answer']\n",
    "\n",
    "test_dset['qt_qb'] = test_dset['question_title'] + '. ' + test_dset['question_body']\n",
    "test_dset['qb_a'] = test_dset['question_body'] + '. ' + test_dset['answer']\n",
    "test_dset['clean_qt_qb'] = test_dset['clean_question_title'] + '. ' + test_dset['clean_question_body']\n",
    "test_dset['clean_qb_a'] = test_dset['clean_question_body'] + '. ' + test_dset['clean_answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "text_encoder = tfidf_pipeline()\n",
    "ohe = oh_encoder()\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('qt_encoded', text_encoder, 'question_title'),\n",
    "    ('qb_encoded', text_encoder, 'question_body'),\n",
    "    ('qtb_encoded', text_encoder, 'qt_qb'),\n",
    "    ('a_encoded', text_encoder, 'answer'),\n",
    "    ('qa_encoded', text_encoder, 'qt_qb'),\n",
    "\n",
    "    ('clean_qt_encoded', text_encoder, 'clean_question_title'),\n",
    "    ('clean_qb_encoded', text_encoder, 'clean_question_body'),\n",
    "    ('clean_qtb_encoded', text_encoder, 'clean_qt_qb'),\n",
    "    ('clean_a_encoded', text_encoder, 'clean_answer'),\n",
    "    ('clean_qa_encoded', text_encoder, 'clean_qt_qb'),\n",
    "\n",
    "    ('qt_char_count', char_count, 'question_title'),\n",
    "    ('qb_char_count', char_count, 'question_body'),\n",
    "    ('a_char_count', char_count, 'answer'),\n",
    "    ('clean_qt_char_count', char_count, 'clean_question_title'),\n",
    "    ('clean_qb_char_count', char_count, 'clean_question_body'),\n",
    "    ('clean_a_char_count', char_count, 'clean_answer'),\n",
    "\n",
    "    ('qt_word_count', word_count, 'tokens_question_title'),\n",
    "    ('qb_word_count', word_count, 'tokens_question_body'),\n",
    "    ('a_word_count', word_count, 'tokens_answer'),\n",
    "\n",
    "    ('qt_unique_word_count', unique_word_count, 'clean_question_title'),\n",
    "    ('qb_unique_word_count', unique_word_count, 'clean_question_body'),\n",
    "    ('a_unique_word_count', unique_word_count, 'clean_answer'),\n",
    "\n",
    "    ('qt_sentence_count', sentence_count, 'clean_question_title'),\n",
    "    ('qb_sentence_count', sentence_count, 'clean_question_body'),\n",
    "    ('a_sentence_count', sentence_count, 'clean_answer'),\n",
    "\n",
    "    ('qt_postag_ratio', postag_ratio, 'postags_question_title'),\n",
    "    ('qb_postag_ratio', postag_ratio, 'postags_question_body'),\n",
    "    ('a_postag_ratio', postag_ratio, 'postags_answer'),\n",
    "\n",
    "    ('qtb_match_ratio', matching_words, ['clean_question_title', 'clean_question_body']),\n",
    "    ('qta_match_ratio', matching_words, ['clean_question_title', 'clean_answer']),\n",
    "    ('qba_match_ratio', matching_words, ['clean_question_body', 'clean_answer']),\n",
    "\n",
    "    ('qt_stopword_ratio', stopword_ratio, 'tokens_question_title'),\n",
    "    ('qb_stopword_ratio', stopword_ratio, 'tokens_question_body'),\n",
    "    ('a_stopword_ratio', stopword_ratio, 'tokens_answer'),\n",
    "\n",
    "    ('qt_uppercase_ratio', uppercase_ratio, 'question_title'),\n",
    "    ('qb_uppercase_ratio', uppercase_ratio, 'question_body'),\n",
    "    ('a_uppercase_ratio', uppercase_ratio, 'answer'),\n",
    "\n",
    "    ('qt_punctuation_count', punctuation_count, 'question_title'),\n",
    "    ('qb_punctuation_count', punctuation_count, 'question_body'),\n",
    "    ('a_punctuation_count', punctuation_count, 'answer'),\n",
    "\n",
    "    ('qt_qwords_count', qwords_count, 'question_title'),\n",
    "    ('qb_qwords_count', qwords_count, 'question_body'),\n",
    "    ('a_qwords_count', qwords_count, 'answer'),\n",
    "\n",
    "    ('qt_number_count', number_count, 'question_title'),\n",
    "    ('qb_number_count', number_count, 'question_body'),\n",
    "    ('a_number_count', number_count, 'answer'),\n",
    "\n",
    "    ('host_ohe', ohe, 'host'),\n",
    "    ('category_ohe', ohe, 'category')\n",
    "    ], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   0.5s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=   2.4s\n",
      "[ColumnTransformer] ... (1 of 48) Processing qt_encoded, total=   2.9s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   7.3s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=  31.7s\n",
      "[ColumnTransformer] ... (2 of 48) Processing qb_encoded, total=  38.9s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   7.9s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=  31.9s\n",
      "[ColumnTransformer] .. (3 of 48) Processing qtb_encoded, total=  39.8s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=  10.4s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=  10.8s\n",
      "[ColumnTransformer] .... (4 of 48) Processing a_encoded, total=  21.1s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   7.8s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=  32.3s\n",
      "[ColumnTransformer] ... (5 of 48) Processing qa_encoded, total=  40.1s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   0.3s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=   1.2s\n",
      "[ColumnTransformer]  (6 of 48) Processing clean_qt_encoded, total=   1.5s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   4.6s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=  20.5s\n",
      "[ColumnTransformer]  (7 of 48) Processing clean_qb_encoded, total=  25.1s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   5.0s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=  21.5s\n",
      "[ColumnTransformer]  (8 of 48) Processing clean_qtb_encoded, total=  26.5s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   6.7s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=   4.2s\n",
      "[ColumnTransformer]  (9 of 48) Processing clean_a_encoded, total=  10.9s\n",
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   5.0s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total=  21.8s\n",
      "[ColumnTransformer]  (10 of 48) Processing clean_qa_encoded, total=  26.8s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (11 of 48) Processing qt_char_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (12 of 48) Processing qb_char_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (13 of 48) Processing a_char_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (14 of 48) Processing clean_qt_char_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (15 of 48) Processing clean_qb_char_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (16 of 48) Processing clean_a_char_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (17 of 48) Processing qt_word_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (18 of 48) Processing qb_word_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (19 of 48) Processing a_word_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   1.3s\n",
      "[ColumnTransformer]  (20 of 48) Processing qt_unique_word_count, total=   1.3s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  22.4s\n",
      "[ColumnTransformer]  (21 of 48) Processing qb_unique_word_count, total=  22.4s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  21.2s\n",
      "[ColumnTransformer]  (22 of 48) Processing a_unique_word_count, total=  21.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.3s\n",
      "[ColumnTransformer]  (23 of 48) Processing qt_sentence_count, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   6.0s\n",
      "[ColumnTransformer]  (24 of 48) Processing qb_sentence_count, total=   6.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   5.9s\n",
      "[ColumnTransformer]  (25 of 48) Processing a_sentence_count, total=   5.9s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  32.1s\n",
      "[ColumnTransformer]  (26 of 48) Processing qt_postag_ratio, total=  32.1s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  34.1s\n",
      "[ColumnTransformer]  (27 of 48) Processing qb_postag_ratio, total=  34.1s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  32.2s\n",
      "[ColumnTransformer]  (28 of 48) Processing a_postag_ratio, total=  32.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   1.9s\n",
      "[ColumnTransformer]  (29 of 48) Processing qtb_match_ratio, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   1.9s\n",
      "[ColumnTransformer]  (30 of 48) Processing qta_match_ratio, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   2.0s\n",
      "[ColumnTransformer]  (31 of 48) Processing qba_match_ratio, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (32 of 48) Processing qt_stopword_ratio, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.2s\n",
      "[ColumnTransformer]  (33 of 48) Processing qb_stopword_ratio, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.3s\n",
      "[ColumnTransformer]  (34 of 48) Processing a_stopword_ratio, total=   0.3s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   3.3s\n",
      "[ColumnTransformer]  (35 of 48) Processing qt_uppercase_ratio, total=   3.3s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  17.9s\n",
      "[ColumnTransformer]  (36 of 48) Processing qb_uppercase_ratio, total=  17.9s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  18.2s\n",
      "[ColumnTransformer]  (37 of 48) Processing a_uppercase_ratio, total=  18.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  20.2s\n",
      "[ColumnTransformer]  (38 of 48) Processing qt_punctuation_count, total=  20.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  20.6s\n",
      "[ColumnTransformer]  (39 of 48) Processing qb_punctuation_count, total=  20.6s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  20.2s\n",
      "[ColumnTransformer]  (40 of 48) Processing a_punctuation_count, total=  20.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  15.3s\n",
      "[ColumnTransformer]  (41 of 48) Processing qt_qwords_count, total=  15.3s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  18.3s\n",
      "[ColumnTransformer]  (42 of 48) Processing qb_qwords_count, total=  18.3s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=  18.2s\n",
      "[ColumnTransformer]  (43 of 48) Processing a_qwords_count, total=  18.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.0s\n",
      "[ColumnTransformer]  (44 of 48) Processing qt_number_count, total=   0.0s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.2s\n",
      "[ColumnTransformer]  (45 of 48) Processing qb_number_count, total=   0.2s\n",
      "[Pipeline] ... (step 1 of 1) Processing Custom Function, total=   0.1s\n",
      "[ColumnTransformer]  (46 of 48) Processing a_number_count, total=   0.1s\n",
      "[Pipeline] ............... (step 1 of 1) Processing OHE, total=   0.0s\n",
      "[ColumnTransformer] .... (47 of 48) Processing host_ohe, total=   0.0s\n",
      "[Pipeline] ............... (step 1 of 1) Processing OHE, total=   0.0s\n",
      "[ColumnTransformer]  (48 of 48) Processing category_ohe, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "x_train = preprocess.fit_transform(train_dset)\n",
    "y_train = y_train.values\n",
    "x_test = preprocess.transform(test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .... (step 1 of 2) Processing Standarization, total=   0.3s\n",
      "[Pipeline] ........ (step 2 of 2) Processing Normalizer, total=   0.1s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "whitening_preprocess = Pipeline([\n",
    "                                ('Standarization', StandardScaler()),\n",
    "                                ('Normalizer', Normalizer()),\n",
    "                        ], verbose=True)\n",
    "\n",
    "x_train = whitening_preprocess.fit_transform(x_train)\n",
    "x_test = whitening_preprocess.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn.utils.weight_norm import weight_norm\n",
    "\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "class PyTorch:\n",
    "    \n",
    "    def __init__(self, in_features, out_features, n_epochs, patience):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n_epochs = n_epochs\n",
    "        self.patience = patience\n",
    "    \n",
    "    \n",
    "    def init_model(self):\n",
    "        \n",
    "        # define a model\n",
    "        self.model = Sequential(\n",
    "            weight_norm(Linear(self.in_features, 128)),\n",
    "            ReLU(),\n",
    "            weight_norm(Linear(128, 128)),\n",
    "            ReLU(),\n",
    "            weight_norm(Linear(128, self.out_features)),\n",
    "            Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # initialize model\n",
    "        for t in self.model:\n",
    "            if isinstance(t, Linear):\n",
    "                nn.init.kaiming_normal_(t.weight_v)\n",
    "                nn.init.kaiming_normal_(t.weight_g)\n",
    "                nn.init.constant_(t.bias, 0)\n",
    "        \n",
    "        # define loss function\n",
    "        self.loss_func = BCELoss()\n",
    "        \n",
    "        # define optimizer\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=1e-3)\n",
    "    \n",
    "    \n",
    "    def fit(self, x_train, y_train, x_valid, y_valid):\n",
    "        \n",
    "        validate = (x_valid is not None) & (y_valid is not None)\n",
    "        \n",
    "        self.init_model()\n",
    "        \n",
    "        x_train_tensor = torch.as_tensor(x_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.as_tensor(y_train, dtype=torch.float32)\n",
    "        \n",
    "        if validate:\n",
    "            x_valid_tensor = torch.as_tensor(x_valid, dtype=torch.float32)\n",
    "            y_valid_tensor = torch.as_tensor(y_valid, dtype=torch.float32)\n",
    "        \n",
    "        min_loss = np.inf\n",
    "        max_spear = 0\n",
    "        counter = 0\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            \n",
    "            self.model.train()\n",
    "            y_pred = self.model(x_train_tensor)\n",
    "            loss = self.loss_func(y_pred, y_train_tensor)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            current_loss = loss.item()\n",
    "\n",
    "            oof_part = self.predict(x_valid)\n",
    "    \n",
    "            spear, rho_cols = compute_spearmanr(oof_part, y_valid)\n",
    "            print(f'epoch = {epoch}, train_loss = {current_loss}, valid_spearman = {spear}')\n",
    "            \n",
    "            # early stopping\n",
    "            # if current_loss < min_loss:\n",
    "            if spear >= max_spear:\n",
    "                # min_loss = current_loss\n",
    "                max_spear = spear\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                # print('Early stopping: %i / %i' % (counter, self.patience))\n",
    "                if counter >= self.patience:\n",
    "                    # print('Early stopping at epoch', epoch + 1)\n",
    "                    break\n",
    "        return estimator, rho_cols \n",
    "    \n",
    "    def predict(self, x):\n",
    "        x_tensor = torch.as_tensor(x, dtype=torch.float32)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(x_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, rankdata\n",
    "\n",
    "\n",
    "def compute_spearmanr(preds, trues):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.nanmean(rhos), rhos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 0\n",
      "epoch = 0, train_loss = 0.6956472396850586, valid_spearman = 0.012171345817698048\n",
      "epoch = 1, train_loss = 0.6926380395889282, valid_spearman = 0.021133478186705953\n",
      "epoch = 2, train_loss = 0.6897417902946472, valid_spearman = 0.02798886970732094\n",
      "epoch = 3, train_loss = 0.6869376301765442, valid_spearman = 0.033754439036839966\n",
      "epoch = 4, train_loss = 0.6841873526573181, valid_spearman = 0.03858777260272057\n",
      "epoch = 5, train_loss = 0.6814516186714172, valid_spearman = 0.042014357280886414\n",
      "epoch = 6, train_loss = 0.678670346736908, valid_spearman = 0.04462086615486972\n",
      "epoch = 7, train_loss = 0.6758150458335876, valid_spearman = 0.047135798605950456\n",
      "epoch = 8, train_loss = 0.6728708744049072, valid_spearman = 0.04920068295520463\n",
      "epoch = 9, train_loss = 0.6697971224784851, valid_spearman = 0.05154788223960116\n",
      "epoch = 10, train_loss = 0.6666020154953003, valid_spearman = 0.05390074758550809\n",
      "epoch = 11, train_loss = 0.6632542014122009, valid_spearman = 0.056534353193097776\n",
      "epoch = 12, train_loss = 0.6597403883934021, valid_spearman = 0.05939315351097487\n",
      "epoch = 13, train_loss = 0.6560459733009338, valid_spearman = 0.06231762799565736\n",
      "epoch = 14, train_loss = 0.6521731615066528, valid_spearman = 0.0654312521699895\n",
      "epoch = 15, train_loss = 0.6481162309646606, valid_spearman = 0.06847914816647165\n",
      "epoch = 16, train_loss = 0.6438999176025391, valid_spearman = 0.07143349984234008\n",
      "epoch = 17, train_loss = 0.6395195722579956, valid_spearman = 0.07447211578159355\n",
      "epoch = 18, train_loss = 0.6349644660949707, valid_spearman = 0.07754662143012082\n",
      "epoch = 19, train_loss = 0.6302586793899536, valid_spearman = 0.08055550917649387\n",
      "epoch = 20, train_loss = 0.6253898739814758, valid_spearman = 0.08347904259257762\n",
      "epoch = 21, train_loss = 0.620381772518158, valid_spearman = 0.08608259122173537\n",
      "epoch = 22, train_loss = 0.6152260899543762, valid_spearman = 0.08879917467174757\n",
      "epoch = 23, train_loss = 0.6099551916122437, valid_spearman = 0.09150572052172465\n",
      "epoch = 24, train_loss = 0.604573130607605, valid_spearman = 0.09409116083490925\n",
      "epoch = 25, train_loss = 0.599091112613678, valid_spearman = 0.09678530601185996\n",
      "epoch = 26, train_loss = 0.5935379862785339, valid_spearman = 0.0991590379599934\n",
      "epoch = 27, train_loss = 0.5879243612289429, valid_spearman = 0.10159517568591162\n",
      "epoch = 28, train_loss = 0.5822625160217285, valid_spearman = 0.10405414757335146\n",
      "epoch = 29, train_loss = 0.576605498790741, valid_spearman = 0.10634555285930349\n",
      "epoch = 30, train_loss = 0.5709359645843506, valid_spearman = 0.10870176330686994\n",
      "epoch = 31, train_loss = 0.5653092861175537, valid_spearman = 0.11085730170713175\n",
      "epoch = 32, train_loss = 0.5597216486930847, valid_spearman = 0.1129542258059271\n",
      "epoch = 33, train_loss = 0.5542209148406982, valid_spearman = 0.11489863555327767\n",
      "epoch = 34, train_loss = 0.5487988591194153, valid_spearman = 0.11696200323588862\n",
      "epoch = 35, train_loss = 0.5434685945510864, valid_spearman = 0.11902172380392287\n",
      "epoch = 36, train_loss = 0.5382659435272217, valid_spearman = 0.1210875541299076\n",
      "epoch = 37, train_loss = 0.5331804752349854, valid_spearman = 0.12309472025850303\n",
      "epoch = 38, train_loss = 0.5282291769981384, valid_spearman = 0.12513210012411563\n",
      "epoch = 39, train_loss = 0.5234249234199524, valid_spearman = 0.1272047497210527\n",
      "epoch = 40, train_loss = 0.5187569856643677, valid_spearman = 0.12919471726975404\n",
      "epoch = 41, train_loss = 0.5142408609390259, valid_spearman = 0.13130878317616948\n",
      "epoch = 42, train_loss = 0.50986248254776, valid_spearman = 0.13336267007910343\n",
      "epoch = 43, train_loss = 0.5056173205375671, valid_spearman = 0.13543312490533652\n",
      "epoch = 44, train_loss = 0.5014826059341431, valid_spearman = 0.13756484735976696\n",
      "epoch = 45, train_loss = 0.49745726585388184, valid_spearman = 0.13968367720259517\n",
      "epoch = 46, train_loss = 0.4935130774974823, valid_spearman = 0.14185031382622604\n",
      "epoch = 47, train_loss = 0.4896480143070221, valid_spearman = 0.144039507150608\n",
      "epoch = 48, train_loss = 0.4858730137348175, valid_spearman = 0.14618117984012463\n",
      "epoch = 49, train_loss = 0.4821810722351074, valid_spearman = 0.14843865337261372\n",
      "epoch = 50, train_loss = 0.4785884916782379, valid_spearman = 0.1507067840777242\n",
      "epoch = 51, train_loss = 0.4750927984714508, valid_spearman = 0.15296803360503627\n",
      "epoch = 52, train_loss = 0.47170594334602356, valid_spearman = 0.1553313624321322\n",
      "epoch = 53, train_loss = 0.4684150815010071, valid_spearman = 0.1576966875291708\n",
      "epoch = 54, train_loss = 0.46521154046058655, valid_spearman = 0.1601816547980004\n",
      "epoch = 55, train_loss = 0.46209076046943665, valid_spearman = 0.16267943203338717\n",
      "epoch = 56, train_loss = 0.45903435349464417, valid_spearman = 0.16518057041679782\n",
      "epoch = 57, train_loss = 0.45604297518730164, valid_spearman = 0.16776121607898775\n",
      "epoch = 58, train_loss = 0.4531268775463104, valid_spearman = 0.17043048869990404\n",
      "epoch = 59, train_loss = 0.4502858519554138, valid_spearman = 0.17306575053523415\n",
      "epoch = 60, train_loss = 0.44755321741104126, valid_spearman = 0.17570232973246627\n",
      "epoch = 61, train_loss = 0.4449385702610016, valid_spearman = 0.17848886659552476\n",
      "epoch = 62, train_loss = 0.44244977831840515, valid_spearman = 0.18121214686600398\n",
      "epoch = 63, train_loss = 0.4400879740715027, valid_spearman = 0.18395563947902024\n",
      "epoch = 64, train_loss = 0.4378410875797272, valid_spearman = 0.18670695022144393\n",
      "epoch = 65, train_loss = 0.43570050597190857, valid_spearman = 0.18942985195963233\n",
      "epoch = 66, train_loss = 0.4336569011211395, valid_spearman = 0.19206372888174186\n",
      "epoch = 67, train_loss = 0.4316905736923218, valid_spearman = 0.1946349363471169\n",
      "epoch = 68, train_loss = 0.42978885769844055, valid_spearman = 0.1971281062619666\n",
      "epoch = 69, train_loss = 0.4279262125492096, valid_spearman = 0.19954289140670536\n",
      "epoch = 70, train_loss = 0.426096647977829, valid_spearman = 0.20202397254313628\n",
      "epoch = 71, train_loss = 0.42429277300834656, valid_spearman = 0.20439971001379437\n",
      "epoch = 72, train_loss = 0.4225151240825653, valid_spearman = 0.20675511696726104\n",
      "epoch = 73, train_loss = 0.42077556252479553, valid_spearman = 0.2090935985196182\n",
      "epoch = 74, train_loss = 0.4190874397754669, valid_spearman = 0.21135257900547236\n",
      "epoch = 75, train_loss = 0.41745734214782715, valid_spearman = 0.21353153495557156\n",
      "epoch = 76, train_loss = 0.4158913791179657, valid_spearman = 0.21558229345390656\n",
      "epoch = 77, train_loss = 0.4143795669078827, valid_spearman = 0.2176943198689161\n",
      "epoch = 78, train_loss = 0.41292354464530945, valid_spearman = 0.21964673600926893\n",
      "epoch = 79, train_loss = 0.4115179479122162, valid_spearman = 0.22169074168526642\n",
      "epoch = 80, train_loss = 0.4101637899875641, valid_spearman = 0.22366515260048253\n",
      "epoch = 81, train_loss = 0.40884634852409363, valid_spearman = 0.2256843204202768\n",
      "epoch = 82, train_loss = 0.4075826108455658, valid_spearman = 0.2277596867198353\n",
      "epoch = 83, train_loss = 0.40635043382644653, valid_spearman = 0.22975696258893238\n",
      "epoch = 84, train_loss = 0.40514934062957764, valid_spearman = 0.23177884983169916\n",
      "epoch = 85, train_loss = 0.4039846956729889, valid_spearman = 0.23373225827981\n",
      "epoch = 86, train_loss = 0.4028578996658325, valid_spearman = 0.23568490277032675\n",
      "epoch = 87, train_loss = 0.40176236629486084, valid_spearman = 0.23762001152974405\n",
      "epoch = 88, train_loss = 0.4006997048854828, valid_spearman = 0.2395115677223133\n",
      "epoch = 89, train_loss = 0.3996647596359253, valid_spearman = 0.241350564464656\n",
      "epoch = 90, train_loss = 0.39867454767227173, valid_spearman = 0.24307241002293\n",
      "epoch = 91, train_loss = 0.39771243929862976, valid_spearman = 0.24475420695739697\n",
      "epoch = 92, train_loss = 0.39677536487579346, valid_spearman = 0.24642181575537273\n",
      "epoch = 93, train_loss = 0.39586007595062256, valid_spearman = 0.24801123160852828\n",
      "epoch = 94, train_loss = 0.39496633410453796, valid_spearman = 0.24950302159449456\n",
      "epoch = 95, train_loss = 0.3940858840942383, valid_spearman = 0.2509242185321156\n",
      "epoch = 96, train_loss = 0.39323127269744873, valid_spearman = 0.25232158840599583\n",
      "epoch = 97, train_loss = 0.39239972829818726, valid_spearman = 0.25366424718461417\n",
      "epoch = 98, train_loss = 0.39158788323402405, valid_spearman = 0.25494973053904324\n",
      "epoch = 99, train_loss = 0.39080795645713806, valid_spearman = 0.2562018471062676\n",
      "epoch = 100, train_loss = 0.3900455832481384, valid_spearman = 0.2574539090436613\n",
      "epoch = 101, train_loss = 0.3893061876296997, valid_spearman = 0.25869077256155926\n",
      "epoch = 102, train_loss = 0.3885865807533264, valid_spearman = 0.25985253008687603\n",
      "epoch = 103, train_loss = 0.38788342475891113, valid_spearman = 0.2610441038685175\n",
      "epoch = 104, train_loss = 0.387196809053421, valid_spearman = 0.2622902130207553\n",
      "epoch = 105, train_loss = 0.3865249752998352, valid_spearman = 0.2633988658684344\n",
      "epoch = 106, train_loss = 0.3858725428581238, valid_spearman = 0.26454929585075976\n",
      "epoch = 107, train_loss = 0.3852389454841614, valid_spearman = 0.2656567463756825\n",
      "epoch = 108, train_loss = 0.3846163749694824, valid_spearman = 0.26674285138131604\n",
      "epoch = 109, train_loss = 0.3840144872665405, valid_spearman = 0.26782378258306466\n",
      "epoch = 110, train_loss = 0.3834230601787567, valid_spearman = 0.26892271978483767\n",
      "epoch = 111, train_loss = 0.3828469514846802, valid_spearman = 0.2699905539878549\n",
      "epoch = 112, train_loss = 0.3822826147079468, valid_spearman = 0.27103358524677784\n",
      "epoch = 113, train_loss = 0.3817237317562103, valid_spearman = 0.2720165597026142\n",
      "epoch = 114, train_loss = 0.38117608428001404, valid_spearman = 0.2729881071912927\n",
      "epoch = 115, train_loss = 0.38064318895339966, valid_spearman = 0.2739364412217078\n",
      "epoch = 116, train_loss = 0.38012415170669556, valid_spearman = 0.27487908494994023\n",
      "epoch = 117, train_loss = 0.3796129822731018, valid_spearman = 0.27579548307791396\n",
      "epoch = 118, train_loss = 0.3791125416755676, valid_spearman = 0.2766981706394251\n",
      "epoch = 119, train_loss = 0.37862494587898254, valid_spearman = 0.2775546029065449\n",
      "epoch = 120, train_loss = 0.37814512848854065, valid_spearman = 0.27829855122771796\n",
      "epoch = 121, train_loss = 0.3776709735393524, valid_spearman = 0.2790351690404609\n",
      "epoch = 122, train_loss = 0.37721019983291626, valid_spearman = 0.2797229121149408\n",
      "epoch = 123, train_loss = 0.37675169110298157, valid_spearman = 0.28043219476257264\n",
      "epoch = 124, train_loss = 0.37630748748779297, valid_spearman = 0.2811308668859892\n",
      "epoch = 125, train_loss = 0.3758631944656372, valid_spearman = 0.28176704059761304\n",
      "epoch = 126, train_loss = 0.37543395161628723, valid_spearman = 0.2823615933142758\n",
      "epoch = 127, train_loss = 0.37500935792922974, valid_spearman = 0.28294912026007235\n",
      "epoch = 128, train_loss = 0.3745914399623871, valid_spearman = 0.2835108082427943\n",
      "epoch = 129, train_loss = 0.37418118119239807, valid_spearman = 0.28414801102727627\n",
      "epoch = 130, train_loss = 0.37377944588661194, valid_spearman = 0.2846903160749551\n",
      "epoch = 131, train_loss = 0.3733869791030884, valid_spearman = 0.28528342234772286\n",
      "epoch = 132, train_loss = 0.3729947805404663, valid_spearman = 0.2858553061497778\n",
      "epoch = 133, train_loss = 0.3726123869419098, valid_spearman = 0.2864241842414028\n",
      "epoch = 134, train_loss = 0.3722308576107025, valid_spearman = 0.2869733473043363\n",
      "epoch = 135, train_loss = 0.3718608617782593, valid_spearman = 0.28754627056879517\n",
      "epoch = 136, train_loss = 0.37149760127067566, valid_spearman = 0.28812517330622595\n",
      "epoch = 137, train_loss = 0.3711370527744293, valid_spearman = 0.28865238246710356\n",
      "epoch = 138, train_loss = 0.3707820475101471, valid_spearman = 0.2891953020010481\n",
      "epoch = 139, train_loss = 0.37043142318725586, valid_spearman = 0.289703750026874\n",
      "epoch = 140, train_loss = 0.370086669921875, valid_spearman = 0.2901545519258469\n",
      "epoch = 141, train_loss = 0.36974817514419556, valid_spearman = 0.2906217613341224\n",
      "epoch = 142, train_loss = 0.36941149830818176, valid_spearman = 0.29109721964186686\n",
      "epoch = 143, train_loss = 0.36908480525016785, valid_spearman = 0.29157981006620265\n",
      "epoch = 144, train_loss = 0.36875876784324646, valid_spearman = 0.2920201925552757\n",
      "epoch = 145, train_loss = 0.3684322237968445, valid_spearman = 0.292400419727532\n",
      "epoch = 146, train_loss = 0.3681175112724304, valid_spearman = 0.2929049193828874\n",
      "epoch = 147, train_loss = 0.3678050935268402, valid_spearman = 0.29330918074257134\n",
      "epoch = 148, train_loss = 0.36749404668807983, valid_spearman = 0.293742617394524\n",
      "epoch = 149, train_loss = 0.3671872317790985, valid_spearman = 0.29415624209354746\n",
      "epoch = 150, train_loss = 0.36688441038131714, valid_spearman = 0.2945876302638362\n",
      "epoch = 151, train_loss = 0.3665889501571655, valid_spearman = 0.29500951956556143\n",
      "epoch = 152, train_loss = 0.366292804479599, valid_spearman = 0.2954165262671101\n",
      "epoch = 153, train_loss = 0.3660036623477936, valid_spearman = 0.2957632158560794\n",
      "epoch = 154, train_loss = 0.36572158336639404, valid_spearman = 0.2961492254067159\n",
      "epoch = 155, train_loss = 0.3654336929321289, valid_spearman = 0.2965100896510543\n",
      "epoch = 156, train_loss = 0.3651540279388428, valid_spearman = 0.29690325001338497\n",
      "epoch = 157, train_loss = 0.3648741543292999, valid_spearman = 0.2972467149197719\n",
      "epoch = 158, train_loss = 0.36459919810295105, valid_spearman = 0.29761280744016566\n",
      "epoch = 159, train_loss = 0.36432963609695435, valid_spearman = 0.2980035799591519\n",
      "epoch = 160, train_loss = 0.36405953764915466, valid_spearman = 0.29841313103784\n",
      "epoch = 161, train_loss = 0.363791286945343, valid_spearman = 0.2987649142322299\n",
      "epoch = 162, train_loss = 0.36353206634521484, valid_spearman = 0.29916061093584523\n",
      "epoch = 163, train_loss = 0.36327096819877625, valid_spearman = 0.2994760069603922\n",
      "epoch = 164, train_loss = 0.36301276087760925, valid_spearman = 0.29981365126625004\n",
      "epoch = 165, train_loss = 0.3627578318119049, valid_spearman = 0.3001231887859427\n",
      "epoch = 166, train_loss = 0.3625084161758423, valid_spearman = 0.3004405568040659\n",
      "epoch = 167, train_loss = 0.3622565269470215, valid_spearman = 0.3007885338952812\n",
      "epoch = 168, train_loss = 0.3620103597640991, valid_spearman = 0.30108186750350396\n",
      "epoch = 169, train_loss = 0.3617629408836365, valid_spearman = 0.30143027306405673\n",
      "epoch = 170, train_loss = 0.36152201890945435, valid_spearman = 0.3017134647856905\n",
      "epoch = 171, train_loss = 0.3612801730632782, valid_spearman = 0.30198110872748085\n",
      "epoch = 172, train_loss = 0.3610410690307617, valid_spearman = 0.30227299114274647\n",
      "epoch = 173, train_loss = 0.3608073592185974, valid_spearman = 0.3025086861743319\n",
      "epoch = 174, train_loss = 0.3605753481388092, valid_spearman = 0.3027732352003682\n",
      "epoch = 175, train_loss = 0.3603423833847046, valid_spearman = 0.30303911218012775\n",
      "epoch = 176, train_loss = 0.3601095378398895, valid_spearman = 0.3032809407744785\n",
      "epoch = 177, train_loss = 0.3598845899105072, valid_spearman = 0.30353886376030054\n",
      "epoch = 178, train_loss = 0.359658807516098, valid_spearman = 0.3037557805401789\n",
      "epoch = 179, train_loss = 0.35943496227264404, valid_spearman = 0.303956519719477\n",
      "epoch = 180, train_loss = 0.3592131733894348, valid_spearman = 0.30417392461768\n",
      "epoch = 181, train_loss = 0.3589909076690674, valid_spearman = 0.3044247835642995\n",
      "epoch = 182, train_loss = 0.3587745130062103, valid_spearman = 0.3046508736632115\n",
      "epoch = 183, train_loss = 0.358555406332016, valid_spearman = 0.3048907821611879\n",
      "epoch = 184, train_loss = 0.35834234952926636, valid_spearman = 0.30507847714256126\n",
      "epoch = 185, train_loss = 0.358132004737854, valid_spearman = 0.30526880883876395\n",
      "epoch = 186, train_loss = 0.3579185903072357, valid_spearman = 0.3055025187983142\n",
      "epoch = 187, train_loss = 0.3577086329460144, valid_spearman = 0.30567819401709173\n",
      "epoch = 188, train_loss = 0.3575003147125244, valid_spearman = 0.30588138357404093\n",
      "epoch = 189, train_loss = 0.35729217529296875, valid_spearman = 0.30607438756223754\n",
      "epoch = 190, train_loss = 0.3570861220359802, valid_spearman = 0.3062634606430748\n",
      "epoch = 191, train_loss = 0.35688555240631104, valid_spearman = 0.306445672439317\n",
      "epoch = 192, train_loss = 0.35668134689331055, valid_spearman = 0.30664412007447456\n",
      "epoch = 193, train_loss = 0.3564826548099518, valid_spearman = 0.3068256308037529\n",
      "epoch = 194, train_loss = 0.3562823534011841, valid_spearman = 0.30700855463613014\n",
      "epoch = 195, train_loss = 0.35608693957328796, valid_spearman = 0.30716151661796925\n",
      "epoch = 196, train_loss = 0.3558903932571411, valid_spearman = 0.3073203168561768\n",
      "epoch = 197, train_loss = 0.35569658875465393, valid_spearman = 0.3074783969422053\n",
      "epoch = 198, train_loss = 0.3555022180080414, valid_spearman = 0.30762302747647774\n",
      "epoch = 199, train_loss = 0.3553091287612915, valid_spearman = 0.3077563289120086\n",
      "epoch = 200, train_loss = 0.3551207482814789, valid_spearman = 0.3079172003186642\n",
      "epoch = 201, train_loss = 0.3549300730228424, valid_spearman = 0.3080414668948716\n",
      "epoch = 202, train_loss = 0.35474228858947754, valid_spearman = 0.3081595189750847\n",
      "epoch = 203, train_loss = 0.35455310344696045, valid_spearman = 0.30831484957060606\n",
      "epoch = 204, train_loss = 0.35436633229255676, valid_spearman = 0.30840693448678297\n",
      "epoch = 205, train_loss = 0.3541867434978485, valid_spearman = 0.30850074771830843\n",
      "epoch = 206, train_loss = 0.3540021777153015, valid_spearman = 0.30861527986145426\n",
      "epoch = 207, train_loss = 0.3538193702697754, valid_spearman = 0.3087171443738011\n",
      "epoch = 208, train_loss = 0.35363632440567017, valid_spearman = 0.3088304484570977\n",
      "epoch = 209, train_loss = 0.35345667600631714, valid_spearman = 0.3089572561283329\n",
      "epoch = 210, train_loss = 0.3532771170139313, valid_spearman = 0.3090625015573132\n",
      "epoch = 211, train_loss = 0.35310351848602295, valid_spearman = 0.30913519459649386\n",
      "epoch = 212, train_loss = 0.3529232442378998, valid_spearman = 0.30921677296713695\n",
      "epoch = 213, train_loss = 0.3527494966983795, valid_spearman = 0.3093137388725255\n",
      "epoch = 214, train_loss = 0.3525742292404175, valid_spearman = 0.3094024238495546\n",
      "epoch = 215, train_loss = 0.3524038791656494, valid_spearman = 0.30947168997987673\n",
      "epoch = 216, train_loss = 0.35222911834716797, valid_spearman = 0.3095262981713531\n",
      "epoch = 217, train_loss = 0.3520592749118805, valid_spearman = 0.30961182598461\n",
      "epoch = 218, train_loss = 0.35188934206962585, valid_spearman = 0.3097085940220982\n",
      "epoch = 219, train_loss = 0.35172149538993835, valid_spearman = 0.30984532716193236\n",
      "epoch = 220, train_loss = 0.35155367851257324, valid_spearman = 0.3099308105851118\n",
      "epoch = 221, train_loss = 0.35138726234436035, valid_spearman = 0.31002207979777346\n",
      "epoch = 222, train_loss = 0.3512212634086609, valid_spearman = 0.31008651056585285\n",
      "epoch = 223, train_loss = 0.3510562479496002, valid_spearman = 0.31016101285439635\n",
      "epoch = 224, train_loss = 0.3508940041065216, valid_spearman = 0.3102347477102276\n",
      "epoch = 225, train_loss = 0.35073208808898926, valid_spearman = 0.31029738657323314\n",
      "epoch = 226, train_loss = 0.3505709171295166, valid_spearman = 0.3103520043008271\n",
      "epoch = 227, train_loss = 0.3504103720188141, valid_spearman = 0.3104128159371055\n",
      "epoch = 228, train_loss = 0.3502514958381653, valid_spearman = 0.3104949362325699\n",
      "epoch = 229, train_loss = 0.3500915467739105, valid_spearman = 0.31052308857380856\n",
      "epoch = 230, train_loss = 0.3499339520931244, valid_spearman = 0.3105866793562217\n",
      "epoch = 231, train_loss = 0.3497757315635681, valid_spearman = 0.3106070529167992\n",
      "epoch = 232, train_loss = 0.3496206998825073, valid_spearman = 0.3106520260750631\n",
      "epoch = 233, train_loss = 0.34946808218955994, valid_spearman = 0.31066464229696344\n",
      "epoch = 234, train_loss = 0.3493126630783081, valid_spearman = 0.31072416195557545\n",
      "epoch = 235, train_loss = 0.3491576611995697, valid_spearman = 0.3107819426856919\n",
      "epoch = 236, train_loss = 0.34900596737861633, valid_spearman = 0.31082693879854445\n",
      "epoch = 237, train_loss = 0.34885311126708984, valid_spearman = 0.31086820452227915\n",
      "epoch = 238, train_loss = 0.3487016260623932, valid_spearman = 0.3109107908010403\n",
      "epoch = 239, train_loss = 0.34855425357818604, valid_spearman = 0.31096279693692414\n",
      "epoch = 240, train_loss = 0.3484044671058655, valid_spearman = 0.31100666376104946\n",
      "epoch = 241, train_loss = 0.348257452249527, valid_spearman = 0.3110224609680715\n",
      "epoch = 242, train_loss = 0.34811094403266907, valid_spearman = 0.31104267082754916\n",
      "epoch = 243, train_loss = 0.34796538949012756, valid_spearman = 0.3110624457579345\n",
      "epoch = 244, train_loss = 0.34781867265701294, valid_spearman = 0.31111770081108936\n",
      "epoch = 245, train_loss = 0.34767088294029236, valid_spearman = 0.3111566018923179\n",
      "epoch = 246, train_loss = 0.3475275933742523, valid_spearman = 0.3111847211525877\n",
      "epoch = 247, train_loss = 0.34738537669181824, valid_spearman = 0.3112086260722536\n",
      "epoch = 248, train_loss = 0.3472428321838379, valid_spearman = 0.3112462894512761\n",
      "epoch = 249, train_loss = 0.34710264205932617, valid_spearman = 0.3112686994174714\n",
      "epoch = 250, train_loss = 0.346962571144104, valid_spearman = 0.31128791528518635\n",
      "epoch = 251, train_loss = 0.3468211591243744, valid_spearman = 0.3112987806242174\n",
      "epoch = 252, train_loss = 0.3466828465461731, valid_spearman = 0.31131831637590474\n",
      "epoch = 253, train_loss = 0.3465456962585449, valid_spearman = 0.3113365397552373\n",
      "epoch = 254, train_loss = 0.34641149640083313, valid_spearman = 0.31136806313822873\n",
      "epoch = 255, train_loss = 0.3462742567062378, valid_spearman = 0.311369368150306\n",
      "epoch = 256, train_loss = 0.3461378216743469, valid_spearman = 0.31139068948699594\n",
      "epoch = 257, train_loss = 0.34600359201431274, valid_spearman = 0.3113634606491437\n",
      "epoch = 258, train_loss = 0.3458699584007263, valid_spearman = 0.3113422145835626\n",
      "question_asker_intent_understanding rho: 0.3286554820450383\n",
      "question_body_critical rho: 0.553755172708622\n",
      "question_conversational rho: 0.3223938793540719\n",
      "question_expect_short_answer rho: 0.224349574427739\n",
      "question_fact_seeking rho: 0.2045574580514705\n",
      "question_has_commonly_accepted_answer rho: 0.3460943706993568\n",
      "question_interestingness_others rho: 0.29404472471832527\n",
      "question_interestingness_self rho: 0.3946912474374107\n",
      "question_multi_intent rho: 0.34356458450080674\n",
      "question_not_really_a_question rho: 0.028734908005093745\n",
      "question_opinion_seeking rho: 0.28246804437445017\n",
      "question_type_choice rho: 0.5272774415658346\n",
      "question_type_compare rho: 0.2739467685148734\n",
      "question_type_consequence rho: 0.053805472014022575\n",
      "question_type_definition rho: 0.31255364938138785\n",
      "question_type_entity rho: 0.38559781207869936\n",
      "question_type_instructions rho: 0.7036973304218949\n",
      "question_type_procedure rho: 0.2660935599136298\n",
      "question_type_reason_explanation rho: 0.4763778477012246\n",
      "question_type_spelling rho: 0.03575585054666083\n",
      "question_well_written rho: 0.4227470161413074\n",
      "answer_helpful rho: 0.19936252635828913\n",
      "answer_level_of_information rho: 0.3256585578728785\n",
      "answer_plausible rho: 0.09469795263686771\n",
      "answer_relevance rho: 0.10598143300347047\n",
      "answer_satisfaction rho: 0.27549551585837495\n",
      "answer_type_instructions rho: 0.6894018555297344\n",
      "answer_type_procedure rho: 0.23132485406708655\n",
      "answer_type_reason_explanation rho: 0.5566602155821665\n",
      "answer_well_written rho: 0.08052133199609057\n",
      "fold = 1\n",
      "epoch = 0, train_loss = 0.6917240023612976, valid_spearman = 0.010446357729473662\n",
      "epoch = 1, train_loss = 0.6893733739852905, valid_spearman = 0.020317106420266746\n",
      "epoch = 2, train_loss = 0.6870124936103821, valid_spearman = 0.02986957756571482\n",
      "epoch = 3, train_loss = 0.6845992207527161, valid_spearman = 0.03853955701808547\n",
      "epoch = 4, train_loss = 0.6821030378341675, valid_spearman = 0.046312453392737485\n",
      "epoch = 5, train_loss = 0.6794934272766113, valid_spearman = 0.05332493835380299\n",
      "epoch = 6, train_loss = 0.6767730116844177, valid_spearman = 0.05936297231994855\n",
      "epoch = 7, train_loss = 0.6738951206207275, valid_spearman = 0.06490124546481699\n",
      "epoch = 8, train_loss = 0.6708751320838928, valid_spearman = 0.06999028696026152\n",
      "epoch = 9, train_loss = 0.6676791310310364, valid_spearman = 0.07465720749376689\n",
      "epoch = 10, train_loss = 0.6642968058586121, valid_spearman = 0.07894839506805683\n",
      "epoch = 11, train_loss = 0.6607329845428467, valid_spearman = 0.08286423687577657\n",
      "epoch = 12, train_loss = 0.6569687128067017, valid_spearman = 0.0865880868045028\n",
      "epoch = 13, train_loss = 0.6530057787895203, valid_spearman = 0.08990400872358308\n",
      "epoch = 14, train_loss = 0.6488323211669922, valid_spearman = 0.09293793367961643\n",
      "epoch = 15, train_loss = 0.6444699168205261, valid_spearman = 0.09574310634381902\n",
      "epoch = 16, train_loss = 0.639897346496582, valid_spearman = 0.09831504338814755\n",
      "epoch = 17, train_loss = 0.6351327896118164, valid_spearman = 0.10059416932293538\n",
      "epoch = 18, train_loss = 0.6301904916763306, valid_spearman = 0.10278313513635798\n",
      "epoch = 19, train_loss = 0.6250666379928589, valid_spearman = 0.10488064236995984\n",
      "epoch = 20, train_loss = 0.6197776198387146, valid_spearman = 0.10703691886427368\n",
      "epoch = 21, train_loss = 0.6143374443054199, valid_spearman = 0.10910879205741471\n",
      "epoch = 22, train_loss = 0.6087931990623474, valid_spearman = 0.11132743070553092\n",
      "epoch = 23, train_loss = 0.6031414866447449, valid_spearman = 0.11331825390807429\n",
      "epoch = 24, train_loss = 0.5974205732345581, valid_spearman = 0.11530330645728151\n",
      "epoch = 25, train_loss = 0.591640830039978, valid_spearman = 0.11724911068681755\n",
      "epoch = 26, train_loss = 0.5858268737792969, valid_spearman = 0.11885630076649147\n",
      "epoch = 27, train_loss = 0.5800058245658875, valid_spearman = 0.12031748370436236\n",
      "epoch = 28, train_loss = 0.5742042660713196, valid_spearman = 0.12156670571121521\n",
      "epoch = 29, train_loss = 0.5684329271316528, valid_spearman = 0.12289902736615635\n",
      "epoch = 30, train_loss = 0.5626993179321289, valid_spearman = 0.12411266281769055\n",
      "epoch = 31, train_loss = 0.5570191740989685, valid_spearman = 0.12531563171266438\n",
      "epoch = 32, train_loss = 0.5513879060745239, valid_spearman = 0.12659433088449648\n",
      "epoch = 33, train_loss = 0.5458260178565979, valid_spearman = 0.12777142636412087\n",
      "epoch = 34, train_loss = 0.5403351187705994, valid_spearman = 0.12901980086159162\n",
      "epoch = 35, train_loss = 0.5349254608154297, valid_spearman = 0.13031399078193365\n",
      "epoch = 36, train_loss = 0.5296011567115784, valid_spearman = 0.13159027430176076\n",
      "epoch = 37, train_loss = 0.5243674516677856, valid_spearman = 0.13305510873210982\n",
      "epoch = 38, train_loss = 0.5192275643348694, valid_spearman = 0.13454314388026198\n",
      "epoch = 39, train_loss = 0.5141940116882324, valid_spearman = 0.13630966134123773\n",
      "epoch = 40, train_loss = 0.509255588054657, valid_spearman = 0.13803802590545747\n",
      "epoch = 41, train_loss = 0.5044341683387756, valid_spearman = 0.1398069077875216\n",
      "epoch = 42, train_loss = 0.4997265636920929, valid_spearman = 0.14174406103429701\n",
      "epoch = 43, train_loss = 0.4951285123825073, valid_spearman = 0.14375697911101887\n",
      "epoch = 44, train_loss = 0.49065858125686646, valid_spearman = 0.14578771595343804\n",
      "epoch = 45, train_loss = 0.4863077402114868, valid_spearman = 0.14786692692779854\n",
      "epoch = 46, train_loss = 0.4820885956287384, valid_spearman = 0.15008150621246952\n",
      "epoch = 47, train_loss = 0.47799021005630493, valid_spearman = 0.15231463003560694\n",
      "epoch = 48, train_loss = 0.4740174114704132, valid_spearman = 0.15477634506108676\n",
      "epoch = 49, train_loss = 0.4701823592185974, valid_spearman = 0.1573372156888098\n",
      "epoch = 50, train_loss = 0.46645721793174744, valid_spearman = 0.15998434955664376\n",
      "epoch = 51, train_loss = 0.46285659074783325, valid_spearman = 0.162689974324368\n",
      "epoch = 52, train_loss = 0.4593832492828369, valid_spearman = 0.1654126435599119\n",
      "epoch = 53, train_loss = 0.45602551102638245, valid_spearman = 0.16817699447084092\n",
      "epoch = 54, train_loss = 0.45280027389526367, valid_spearman = 0.17083149557675936\n",
      "epoch = 55, train_loss = 0.4497120678424835, valid_spearman = 0.17354692605952343\n",
      "epoch = 56, train_loss = 0.4467577636241913, valid_spearman = 0.1761575126419519\n",
      "epoch = 57, train_loss = 0.4439389705657959, valid_spearman = 0.17879783701708823\n",
      "epoch = 58, train_loss = 0.4412534236907959, valid_spearman = 0.18124626958265638\n",
      "epoch = 59, train_loss = 0.4387037456035614, valid_spearman = 0.18373565815818244\n",
      "epoch = 60, train_loss = 0.436273455619812, valid_spearman = 0.18600059598593305\n",
      "epoch = 61, train_loss = 0.43394649028778076, valid_spearman = 0.18833660873910374\n",
      "epoch = 62, train_loss = 0.431720107793808, valid_spearman = 0.19056968549800476\n",
      "epoch = 63, train_loss = 0.4295935332775116, valid_spearman = 0.19262887273953097\n",
      "epoch = 64, train_loss = 0.4275616407394409, valid_spearman = 0.19458260682996759\n",
      "epoch = 65, train_loss = 0.42561647295951843, valid_spearman = 0.1966019361973253\n",
      "epoch = 66, train_loss = 0.4237767457962036, valid_spearman = 0.19851863335209533\n",
      "epoch = 67, train_loss = 0.422028511762619, valid_spearman = 0.20034877011444968\n",
      "epoch = 68, train_loss = 0.42037615180015564, valid_spearman = 0.20205936171399105\n",
      "epoch = 69, train_loss = 0.41880205273628235, valid_spearman = 0.20371084851834373\n",
      "epoch = 70, train_loss = 0.41730427742004395, valid_spearman = 0.20546359037827985\n",
      "epoch = 71, train_loss = 0.41587644815444946, valid_spearman = 0.20715474205081108\n",
      "epoch = 72, train_loss = 0.41450265049934387, valid_spearman = 0.2089232184598308\n",
      "epoch = 73, train_loss = 0.4131869673728943, valid_spearman = 0.21061343665191354\n",
      "epoch = 74, train_loss = 0.41191476583480835, valid_spearman = 0.21227652330143124\n",
      "epoch = 75, train_loss = 0.410698801279068, valid_spearman = 0.21404108772512495\n",
      "epoch = 76, train_loss = 0.4095262289047241, valid_spearman = 0.2157217676120334\n",
      "epoch = 77, train_loss = 0.4083922803401947, valid_spearman = 0.2174055952876693\n",
      "epoch = 78, train_loss = 0.4073043167591095, valid_spearman = 0.2191002398601243\n",
      "epoch = 79, train_loss = 0.4062510132789612, valid_spearman = 0.22082484224201812\n",
      "epoch = 80, train_loss = 0.4052494466304779, valid_spearman = 0.22247609138507668\n",
      "epoch = 81, train_loss = 0.4042835235595703, valid_spearman = 0.22407256128067043\n",
      "epoch = 82, train_loss = 0.4033690094947815, valid_spearman = 0.22561971780641404\n",
      "epoch = 83, train_loss = 0.40249231457710266, valid_spearman = 0.22701348265825105\n",
      "epoch = 84, train_loss = 0.4016512930393219, valid_spearman = 0.228457162215983\n",
      "epoch = 85, train_loss = 0.4008418023586273, valid_spearman = 0.22986510167961818\n",
      "epoch = 86, train_loss = 0.40004947781562805, valid_spearman = 0.23117794528166255\n",
      "epoch = 87, train_loss = 0.3992907404899597, valid_spearman = 0.23257404950068447\n",
      "epoch = 88, train_loss = 0.39855602383613586, valid_spearman = 0.23380210125212317\n",
      "epoch = 89, train_loss = 0.39784035086631775, valid_spearman = 0.23508528268972992\n",
      "epoch = 90, train_loss = 0.39713871479034424, valid_spearman = 0.23635160848434095\n",
      "epoch = 91, train_loss = 0.39645782113075256, valid_spearman = 0.23755926191382087\n",
      "epoch = 92, train_loss = 0.3957947790622711, valid_spearman = 0.23873162954138924\n",
      "epoch = 93, train_loss = 0.39515116810798645, valid_spearman = 0.23987394804951706\n",
      "epoch = 94, train_loss = 0.39452311396598816, valid_spearman = 0.24094944623378148\n",
      "epoch = 95, train_loss = 0.39391398429870605, valid_spearman = 0.24198174505784695\n",
      "epoch = 96, train_loss = 0.39332130551338196, valid_spearman = 0.24301470521982824\n",
      "epoch = 97, train_loss = 0.3927398920059204, valid_spearman = 0.24393757738229344\n",
      "epoch = 98, train_loss = 0.3921840488910675, valid_spearman = 0.2448646377362519\n",
      "epoch = 99, train_loss = 0.3916386067867279, valid_spearman = 0.24579577605448974\n",
      "epoch = 100, train_loss = 0.3911135792732239, valid_spearman = 0.24663652227824368\n",
      "epoch = 101, train_loss = 0.3906051218509674, valid_spearman = 0.247452577175472\n",
      "epoch = 102, train_loss = 0.3901098668575287, valid_spearman = 0.2483004647669129\n",
      "epoch = 103, train_loss = 0.389631062746048, valid_spearman = 0.24909679204696564\n",
      "epoch = 104, train_loss = 0.38916608691215515, valid_spearman = 0.24989195430036112\n",
      "epoch = 105, train_loss = 0.3887079358100891, valid_spearman = 0.2506807498262514\n",
      "epoch = 106, train_loss = 0.3882690668106079, valid_spearman = 0.2514372963765376\n",
      "epoch = 107, train_loss = 0.3878405690193176, valid_spearman = 0.25216605827828786\n",
      "epoch = 108, train_loss = 0.387422651052475, valid_spearman = 0.25286672384777975\n",
      "epoch = 109, train_loss = 0.38701337575912476, valid_spearman = 0.25356075486344365\n",
      "epoch = 110, train_loss = 0.3866119384765625, valid_spearman = 0.254187265846824\n",
      "epoch = 111, train_loss = 0.3862244784832001, valid_spearman = 0.2548733304415564\n",
      "epoch = 112, train_loss = 0.38584011793136597, valid_spearman = 0.2555353998926561\n",
      "epoch = 113, train_loss = 0.38546445965766907, valid_spearman = 0.2562031974143952\n",
      "epoch = 114, train_loss = 0.38509684801101685, valid_spearman = 0.256866349511327\n",
      "epoch = 115, train_loss = 0.3847375512123108, valid_spearman = 0.2575000761789418\n",
      "epoch = 116, train_loss = 0.38438495993614197, valid_spearman = 0.25808167897135864\n",
      "epoch = 117, train_loss = 0.38403910398483276, valid_spearman = 0.2586515032671944\n",
      "epoch = 118, train_loss = 0.3837036192417145, valid_spearman = 0.25921556945781016\n",
      "epoch = 119, train_loss = 0.38337400555610657, valid_spearman = 0.2597616266298467\n",
      "epoch = 120, train_loss = 0.3830520510673523, valid_spearman = 0.26032227479764314\n",
      "epoch = 121, train_loss = 0.38273486495018005, valid_spearman = 0.2609189237660965\n",
      "epoch = 122, train_loss = 0.3824242353439331, valid_spearman = 0.2614718467711535\n",
      "epoch = 123, train_loss = 0.3821195363998413, valid_spearman = 0.26200809055261715\n",
      "epoch = 124, train_loss = 0.381818026304245, valid_spearman = 0.2624821008301832\n",
      "epoch = 125, train_loss = 0.3815310001373291, valid_spearman = 0.26298491501239485\n",
      "epoch = 126, train_loss = 0.3812440037727356, valid_spearman = 0.26345406439828206\n",
      "epoch = 127, train_loss = 0.3809559941291809, valid_spearman = 0.2638864561240658\n",
      "epoch = 128, train_loss = 0.3806847929954529, valid_spearman = 0.264279066915069\n",
      "epoch = 129, train_loss = 0.3804095685482025, valid_spearman = 0.2647145847836797\n",
      "epoch = 130, train_loss = 0.3801424503326416, valid_spearman = 0.2651453339037937\n",
      "epoch = 131, train_loss = 0.37987399101257324, valid_spearman = 0.2655263910119219\n",
      "epoch = 132, train_loss = 0.37961629033088684, valid_spearman = 0.2659468062990216\n",
      "epoch = 133, train_loss = 0.3793606460094452, valid_spearman = 0.26632392669001237\n",
      "epoch = 134, train_loss = 0.37910595536231995, valid_spearman = 0.2666892358689047\n",
      "epoch = 135, train_loss = 0.3788547217845917, valid_spearman = 0.26708165625090063\n",
      "epoch = 136, train_loss = 0.3786109983921051, valid_spearman = 0.26742986965410437\n",
      "epoch = 137, train_loss = 0.37836942076683044, valid_spearman = 0.2677923114505746\n",
      "epoch = 138, train_loss = 0.37812861800193787, valid_spearman = 0.2681352583316268\n",
      "epoch = 139, train_loss = 0.37789151072502136, valid_spearman = 0.26850500497040886\n",
      "epoch = 140, train_loss = 0.377658486366272, valid_spearman = 0.2688361889336862\n",
      "epoch = 141, train_loss = 0.3774288296699524, valid_spearman = 0.2691816145014949\n",
      "epoch = 142, train_loss = 0.37720221281051636, valid_spearman = 0.26953408862855244\n",
      "epoch = 143, train_loss = 0.37697672843933105, valid_spearman = 0.2698590097461705\n",
      "epoch = 144, train_loss = 0.3767528533935547, valid_spearman = 0.27015281029278254\n",
      "epoch = 145, train_loss = 0.37653449177742004, valid_spearman = 0.27045027172563185\n",
      "epoch = 146, train_loss = 0.37631475925445557, valid_spearman = 0.27071576242241835\n",
      "epoch = 147, train_loss = 0.3761020600795746, valid_spearman = 0.270983119496912\n",
      "epoch = 148, train_loss = 0.3758840262889862, valid_spearman = 0.27128976731921356\n",
      "epoch = 149, train_loss = 0.37567204236984253, valid_spearman = 0.2715474780123755\n",
      "epoch = 150, train_loss = 0.37546131014823914, valid_spearman = 0.2718127345457291\n",
      "epoch = 151, train_loss = 0.375252902507782, valid_spearman = 0.27206818951315237\n",
      "epoch = 152, train_loss = 0.37504467368125916, valid_spearman = 0.2723299245589064\n",
      "epoch = 153, train_loss = 0.37483999133110046, valid_spearman = 0.27256239917898367\n",
      "epoch = 154, train_loss = 0.374639093875885, valid_spearman = 0.272785275297288\n",
      "epoch = 155, train_loss = 0.3744385540485382, valid_spearman = 0.2730206105286649\n",
      "epoch = 156, train_loss = 0.3742403984069824, valid_spearman = 0.2732905356779859\n",
      "epoch = 157, train_loss = 0.37404003739356995, valid_spearman = 0.2735045266027277\n",
      "epoch = 158, train_loss = 0.37384718656539917, valid_spearman = 0.2737524891821634\n",
      "epoch = 159, train_loss = 0.37364721298217773, valid_spearman = 0.2739795209217809\n",
      "epoch = 160, train_loss = 0.37345483899116516, valid_spearman = 0.2741793631382976\n",
      "epoch = 161, train_loss = 0.3732649087905884, valid_spearman = 0.27441481138972446\n",
      "epoch = 162, train_loss = 0.3730734586715698, valid_spearman = 0.27463056384911405\n",
      "epoch = 163, train_loss = 0.37288203835487366, valid_spearman = 0.27483750484188735\n",
      "epoch = 164, train_loss = 0.3726925551891327, valid_spearman = 0.27502823144220667\n",
      "epoch = 165, train_loss = 0.3725104033946991, valid_spearman = 0.2752389230089126\n",
      "epoch = 166, train_loss = 0.37232449650764465, valid_spearman = 0.2754783850649545\n",
      "epoch = 167, train_loss = 0.37214046716690063, valid_spearman = 0.27567267228318243\n",
      "epoch = 168, train_loss = 0.371958464384079, valid_spearman = 0.2758868758421415\n",
      "epoch = 169, train_loss = 0.37177610397338867, valid_spearman = 0.27613133940158474\n",
      "epoch = 170, train_loss = 0.37159591913223267, valid_spearman = 0.2763225084722075\n",
      "epoch = 171, train_loss = 0.3714151382446289, valid_spearman = 0.2764882225240027\n",
      "epoch = 172, train_loss = 0.3712349236011505, valid_spearman = 0.27666120691447443\n",
      "epoch = 173, train_loss = 0.37105584144592285, valid_spearman = 0.2768753485527318\n",
      "epoch = 174, train_loss = 0.37087881565093994, valid_spearman = 0.27703288499027895\n",
      "epoch = 175, train_loss = 0.3707030713558197, valid_spearman = 0.27718949215474553\n",
      "epoch = 176, train_loss = 0.3705276846885681, valid_spearman = 0.2773550031329567\n",
      "epoch = 177, train_loss = 0.3703565299510956, valid_spearman = 0.27752129743398496\n",
      "epoch = 178, train_loss = 0.3701835870742798, valid_spearman = 0.27767376070507954\n",
      "epoch = 179, train_loss = 0.37001296877861023, valid_spearman = 0.27783273470792874\n",
      "epoch = 180, train_loss = 0.36984381079673767, valid_spearman = 0.2779969005287451\n",
      "epoch = 181, train_loss = 0.36967194080352783, valid_spearman = 0.27816335231925055\n",
      "epoch = 182, train_loss = 0.3695049583911896, valid_spearman = 0.27830354937170476\n",
      "epoch = 183, train_loss = 0.3693350851535797, valid_spearman = 0.27843584611681754\n",
      "epoch = 184, train_loss = 0.3691674768924713, valid_spearman = 0.27856457331961754\n",
      "epoch = 185, train_loss = 0.3690040111541748, valid_spearman = 0.27869548756380885\n",
      "epoch = 186, train_loss = 0.3688354790210724, valid_spearman = 0.2788135139040795\n",
      "epoch = 187, train_loss = 0.3686707317829132, valid_spearman = 0.2788998554512111\n",
      "epoch = 188, train_loss = 0.3685048222541809, valid_spearman = 0.27903258319557905\n",
      "epoch = 189, train_loss = 0.368343710899353, valid_spearman = 0.2791723250972925\n",
      "epoch = 190, train_loss = 0.3681819438934326, valid_spearman = 0.2792682245718355\n",
      "epoch = 191, train_loss = 0.3680201768875122, valid_spearman = 0.2793884905118775\n",
      "epoch = 192, train_loss = 0.367856502532959, valid_spearman = 0.27950628355810847\n",
      "epoch = 193, train_loss = 0.36769813299179077, valid_spearman = 0.2796071364336002\n",
      "epoch = 194, train_loss = 0.3675380051136017, valid_spearman = 0.27971555668758413\n",
      "epoch = 195, train_loss = 0.36737653613090515, valid_spearman = 0.27980019496562913\n",
      "epoch = 196, train_loss = 0.3672189712524414, valid_spearman = 0.27991789979907583\n",
      "epoch = 197, train_loss = 0.3670620024204254, valid_spearman = 0.2800267623096018\n",
      "epoch = 198, train_loss = 0.3669091463088989, valid_spearman = 0.2801211636468339\n",
      "epoch = 199, train_loss = 0.3667512834072113, valid_spearman = 0.2802170687898238\n",
      "epoch = 200, train_loss = 0.3665948510169983, valid_spearman = 0.2803219415783433\n",
      "epoch = 201, train_loss = 0.3664393424987793, valid_spearman = 0.2804277095098193\n",
      "epoch = 202, train_loss = 0.3662879168987274, valid_spearman = 0.28050579342922777\n",
      "epoch = 203, train_loss = 0.3661346435546875, valid_spearman = 0.28059068778034885\n",
      "epoch = 204, train_loss = 0.3659813404083252, valid_spearman = 0.2806874763342006\n",
      "epoch = 205, train_loss = 0.36582982540130615, valid_spearman = 0.2807690615924233\n",
      "epoch = 206, train_loss = 0.36567968130111694, valid_spearman = 0.2808747190793889\n",
      "epoch = 207, train_loss = 0.3655295968055725, valid_spearman = 0.28096165187997096\n",
      "epoch = 208, train_loss = 0.3653807044029236, valid_spearman = 0.28103126567832504\n",
      "epoch = 209, train_loss = 0.36523017287254333, valid_spearman = 0.2811018933939173\n",
      "epoch = 210, train_loss = 0.36508065462112427, valid_spearman = 0.281126784055947\n",
      "epoch = 211, train_loss = 0.36493176221847534, valid_spearman = 0.28122257865664707\n",
      "epoch = 212, train_loss = 0.36478281021118164, valid_spearman = 0.28132357985424217\n",
      "epoch = 213, train_loss = 0.36463451385498047, valid_spearman = 0.2814036356929542\n",
      "epoch = 214, train_loss = 0.3644903302192688, valid_spearman = 0.2814934734216117\n",
      "epoch = 215, train_loss = 0.3643452525138855, valid_spearman = 0.28156487666326674\n",
      "epoch = 216, train_loss = 0.3641956150531769, valid_spearman = 0.28166019657543856\n",
      "epoch = 217, train_loss = 0.3640502691268921, valid_spearman = 0.28174725814761065\n",
      "epoch = 218, train_loss = 0.3639054596424103, valid_spearman = 0.2818463117604135\n",
      "epoch = 219, train_loss = 0.36376285552978516, valid_spearman = 0.28194463377041445\n",
      "epoch = 220, train_loss = 0.363619327545166, valid_spearman = 0.28202447890067595\n",
      "epoch = 221, train_loss = 0.36347702145576477, valid_spearman = 0.2821093685145728\n",
      "epoch = 222, train_loss = 0.3633328676223755, valid_spearman = 0.2821764191727576\n",
      "epoch = 223, train_loss = 0.3631911873817444, valid_spearman = 0.2822813590810903\n",
      "epoch = 224, train_loss = 0.36305105686187744, valid_spearman = 0.2823963890481147\n",
      "epoch = 225, train_loss = 0.36290955543518066, valid_spearman = 0.28247921091195166\n",
      "epoch = 226, train_loss = 0.3627699613571167, valid_spearman = 0.2825574354251769\n",
      "epoch = 227, train_loss = 0.3626290261745453, valid_spearman = 0.28262203763311405\n",
      "epoch = 228, train_loss = 0.36249423027038574, valid_spearman = 0.28269203712356705\n",
      "epoch = 229, train_loss = 0.36235684156417847, valid_spearman = 0.28279039704434045\n",
      "epoch = 230, train_loss = 0.36221954226493835, valid_spearman = 0.28286143423229826\n",
      "epoch = 231, train_loss = 0.3620842695236206, valid_spearman = 0.2829159722329049\n",
      "epoch = 232, train_loss = 0.3619486391544342, valid_spearman = 0.28297513602201974\n",
      "epoch = 233, train_loss = 0.36181211471557617, valid_spearman = 0.2830511927677591\n",
      "epoch = 234, train_loss = 0.3616791367530823, valid_spearman = 0.28309200378118\n",
      "epoch = 235, train_loss = 0.36154410243034363, valid_spearman = 0.28313634663486315\n",
      "epoch = 236, train_loss = 0.36140987277030945, valid_spearman = 0.2831821006417227\n",
      "epoch = 237, train_loss = 0.36127641797065735, valid_spearman = 0.2832280419606687\n",
      "epoch = 238, train_loss = 0.3611425459384918, valid_spearman = 0.283295981839191\n",
      "epoch = 239, train_loss = 0.361011266708374, valid_spearman = 0.28335066025792693\n",
      "epoch = 240, train_loss = 0.360880047082901, valid_spearman = 0.2834077478286468\n",
      "epoch = 241, train_loss = 0.3607507348060608, valid_spearman = 0.2834608641624693\n",
      "epoch = 242, train_loss = 0.3606211841106415, valid_spearman = 0.2835180617120902\n",
      "epoch = 243, train_loss = 0.36049118638038635, valid_spearman = 0.2835838029714024\n",
      "epoch = 244, train_loss = 0.3603631556034088, valid_spearman = 0.28364716723848377\n",
      "epoch = 245, train_loss = 0.3602374196052551, valid_spearman = 0.283696326879726\n",
      "epoch = 246, train_loss = 0.3601101040840149, valid_spearman = 0.2837579493794673\n",
      "epoch = 247, train_loss = 0.35998281836509705, valid_spearman = 0.2837845281342742\n",
      "epoch = 248, train_loss = 0.3598547875881195, valid_spearman = 0.28384536919989106\n",
      "epoch = 249, train_loss = 0.3597303628921509, valid_spearman = 0.2838945132667913\n",
      "epoch = 250, train_loss = 0.3596056401729584, valid_spearman = 0.28393502198320475\n",
      "epoch = 251, train_loss = 0.3594804108142853, valid_spearman = 0.2839906142957303\n",
      "epoch = 252, train_loss = 0.35935643315315247, valid_spearman = 0.2840834319407613\n",
      "epoch = 253, train_loss = 0.3592317998409271, valid_spearman = 0.28415129592146016\n",
      "epoch = 254, train_loss = 0.35910993814468384, valid_spearman = 0.2842024567632701\n",
      "epoch = 255, train_loss = 0.35898926854133606, valid_spearman = 0.28424110813435105\n",
      "epoch = 256, train_loss = 0.3588690459728241, valid_spearman = 0.2843050344741192\n",
      "epoch = 257, train_loss = 0.35874414443969727, valid_spearman = 0.2843942915862522\n",
      "epoch = 258, train_loss = 0.35862481594085693, valid_spearman = 0.28446988331315953\n",
      "epoch = 259, train_loss = 0.35850614309310913, valid_spearman = 0.2845422266330731\n",
      "epoch = 260, train_loss = 0.3583875298500061, valid_spearman = 0.2845658199586926\n",
      "epoch = 261, train_loss = 0.35826990008354187, valid_spearman = 0.2846141645727705\n",
      "epoch = 262, train_loss = 0.358150839805603, valid_spearman = 0.28468576083458735\n",
      "epoch = 263, train_loss = 0.35803520679473877, valid_spearman = 0.2847624947502665\n",
      "epoch = 264, train_loss = 0.3579178750514984, valid_spearman = 0.28485185584036266\n",
      "epoch = 265, train_loss = 0.35780152678489685, valid_spearman = 0.28491484693770636\n",
      "epoch = 266, train_loss = 0.35768720507621765, valid_spearman = 0.2850110628714188\n",
      "epoch = 267, train_loss = 0.3575710356235504, valid_spearman = 0.2850807032425491\n",
      "epoch = 268, train_loss = 0.3574538230895996, valid_spearman = 0.28511522937216033\n",
      "epoch = 269, train_loss = 0.35733911395072937, valid_spearman = 0.2851756521620728\n",
      "epoch = 270, train_loss = 0.35722771286964417, valid_spearman = 0.2852165510037562\n",
      "epoch = 271, train_loss = 0.3571142852306366, valid_spearman = 0.2852596616489685\n",
      "epoch = 272, train_loss = 0.35699737071990967, valid_spearman = 0.28530360390092163\n",
      "epoch = 273, train_loss = 0.3568865954875946, valid_spearman = 0.2853252937734169\n",
      "epoch = 274, train_loss = 0.3567736744880676, valid_spearman = 0.2853542715747318\n",
      "epoch = 275, train_loss = 0.3566628694534302, valid_spearman = 0.2853699804853843\n",
      "epoch = 276, train_loss = 0.3565536439418793, valid_spearman = 0.28539381570130157\n",
      "epoch = 277, train_loss = 0.35644182562828064, valid_spearman = 0.2854225758700437\n",
      "epoch = 278, train_loss = 0.35633280873298645, valid_spearman = 0.28543322430248785\n",
      "epoch = 279, train_loss = 0.35622498393058777, valid_spearman = 0.28545649342010804\n",
      "epoch = 280, train_loss = 0.3561165928840637, valid_spearman = 0.28547126725422556\n",
      "epoch = 281, train_loss = 0.3560076653957367, valid_spearman = 0.28550168138768106\n",
      "epoch = 282, train_loss = 0.3559006154537201, valid_spearman = 0.2855829499206117\n",
      "epoch = 283, train_loss = 0.3557963967323303, valid_spearman = 0.28560768437437\n",
      "epoch = 284, train_loss = 0.35569053888320923, valid_spearman = 0.2856282875357165\n",
      "epoch = 285, train_loss = 0.3555862009525299, valid_spearman = 0.28567302366422614\n",
      "epoch = 286, train_loss = 0.3554770350456238, valid_spearman = 0.2856975180538684\n",
      "epoch = 287, train_loss = 0.3553721606731415, valid_spearman = 0.2857440489532016\n",
      "epoch = 288, train_loss = 0.35526755452156067, valid_spearman = 0.2857925230212874\n",
      "epoch = 289, train_loss = 0.35516518354415894, valid_spearman = 0.2858176957796324\n",
      "epoch = 290, train_loss = 0.3550625145435333, valid_spearman = 0.2858499861661798\n",
      "epoch = 291, train_loss = 0.3549595773220062, valid_spearman = 0.2858845355054107\n",
      "epoch = 292, train_loss = 0.35485437512397766, valid_spearman = 0.2859318999946015\n",
      "epoch = 293, train_loss = 0.35475048422813416, valid_spearman = 0.2859736391986179\n",
      "epoch = 294, train_loss = 0.354646772146225, valid_spearman = 0.28603013579613934\n",
      "epoch = 295, train_loss = 0.35454732179641724, valid_spearman = 0.28606792199341846\n",
      "epoch = 296, train_loss = 0.35444921255111694, valid_spearman = 0.2860971930523541\n",
      "epoch = 297, train_loss = 0.3543485105037689, valid_spearman = 0.28613547534202255\n",
      "epoch = 298, train_loss = 0.354248583316803, valid_spearman = 0.28616793263873685\n",
      "epoch = 299, train_loss = 0.35414865612983704, valid_spearman = 0.286181093888185\n",
      "epoch = 300, train_loss = 0.354050874710083, valid_spearman = 0.28622580304353534\n",
      "epoch = 301, train_loss = 0.3539517819881439, valid_spearman = 0.2862908735105944\n",
      "epoch = 302, train_loss = 0.353854238986969, valid_spearman = 0.2863183234670653\n",
      "epoch = 303, train_loss = 0.35375431180000305, valid_spearman = 0.28633580832616706\n",
      "epoch = 304, train_loss = 0.35365918278694153, valid_spearman = 0.2863382392682407\n",
      "epoch = 305, train_loss = 0.3535616993904114, valid_spearman = 0.28636036617750155\n",
      "epoch = 306, train_loss = 0.3534661829471588, valid_spearman = 0.28640253416807704\n",
      "epoch = 307, train_loss = 0.3533674478530884, valid_spearman = 0.2864524887562983\n",
      "epoch = 308, train_loss = 0.3532736897468567, valid_spearman = 0.2865050594369308\n",
      "epoch = 309, train_loss = 0.3531787395477295, valid_spearman = 0.28653751138153377\n",
      "epoch = 310, train_loss = 0.35308638215065, valid_spearman = 0.28655970453249535\n",
      "epoch = 311, train_loss = 0.35299205780029297, valid_spearman = 0.28661021568943323\n",
      "epoch = 312, train_loss = 0.3528966009616852, valid_spearman = 0.28663405967864697\n",
      "epoch = 313, train_loss = 0.3528016209602356, valid_spearman = 0.28664211840104425\n",
      "epoch = 314, train_loss = 0.35271120071411133, valid_spearman = 0.2866551398917125\n",
      "epoch = 315, train_loss = 0.35261639952659607, valid_spearman = 0.28667138918913776\n",
      "epoch = 316, train_loss = 0.3525238633155823, valid_spearman = 0.2867066835938688\n",
      "epoch = 317, train_loss = 0.3524322807788849, valid_spearman = 0.28671841483526384\n",
      "epoch = 318, train_loss = 0.3523412048816681, valid_spearman = 0.2867390979268046\n",
      "epoch = 319, train_loss = 0.3522476553916931, valid_spearman = 0.2867628870654172\n",
      "epoch = 320, train_loss = 0.3521572947502136, valid_spearman = 0.2867964789957101\n",
      "epoch = 321, train_loss = 0.35206589102745056, valid_spearman = 0.2868064973436543\n",
      "epoch = 322, train_loss = 0.3519766330718994, valid_spearman = 0.2867791924749634\n",
      "epoch = 323, train_loss = 0.3518856167793274, valid_spearman = 0.28679201665177106\n",
      "question_asker_intent_understanding rho: 0.2992517830200287\n",
      "question_body_critical rho: 0.5868890390563256\n",
      "question_conversational rho: 0.3233454600168523\n",
      "question_expect_short_answer rho: 0.1929416306916511\n",
      "question_fact_seeking rho: 0.2725655726671238\n",
      "question_has_commonly_accepted_answer rho: 0.31525531357411835\n",
      "question_interestingness_others rho: 0.28429653994238563\n",
      "question_interestingness_self rho: 0.397025445617085\n",
      "question_multi_intent rho: 0.32001512197072335\n",
      "question_not_really_a_question rho: -0.014660764336876405\n",
      "question_opinion_seeking rho: 0.33327646905222647\n",
      "question_type_choice rho: 0.5384672545091514\n",
      "question_type_compare rho: 0.2785279721109645\n",
      "question_type_consequence rho: 0.09237351324583098\n",
      "question_type_definition rho: 0.2629620639476101\n",
      "question_type_entity rho: 0.21691425771063788\n",
      "question_type_instructions rho: 0.6191626435602513\n",
      "question_type_procedure rho: 0.24308742385286802\n",
      "question_type_reason_explanation rho: 0.45356436502361935\n",
      "question_type_spelling rho: 0.013172121215827923\n",
      "question_well_written rho: 0.3744114893334477\n",
      "answer_helpful rho: 0.10584910458895888\n",
      "answer_level_of_information rho: 0.3602553425621293\n",
      "answer_plausible rho: 0.038872126498069905\n",
      "answer_relevance rho: 0.08114132917658382\n",
      "answer_satisfaction rho: 0.16820545259789496\n",
      "answer_type_instructions rho: 0.6290777743829538\n",
      "answer_type_procedure rho: 0.16548611489186452\n",
      "answer_type_reason_explanation rho: 0.5247672644886929\n",
      "answer_well_written rho: 0.1272612745841319\n",
      "fold = 2\n",
      "epoch = 0, train_loss = 0.6937494277954102, valid_spearman = 0.012655811208479561\n",
      "epoch = 1, train_loss = 0.6919190883636475, valid_spearman = 0.022605169767393705\n",
      "epoch = 2, train_loss = 0.6900907158851624, valid_spearman = 0.03239308453203892\n",
      "epoch = 3, train_loss = 0.6882753372192383, valid_spearman = 0.04231316439735022\n",
      "epoch = 4, train_loss = 0.6864585876464844, valid_spearman = 0.05178875523438188\n",
      "epoch = 5, train_loss = 0.6846078038215637, valid_spearman = 0.060635364011914376\n",
      "epoch = 6, train_loss = 0.6827124953269958, valid_spearman = 0.0686521488010147\n",
      "epoch = 7, train_loss = 0.680727481842041, valid_spearman = 0.07613326659181685\n",
      "epoch = 8, train_loss = 0.6786572933197021, valid_spearman = 0.08327046440472709\n",
      "epoch = 9, train_loss = 0.6764864921569824, valid_spearman = 0.08985545171377413\n",
      "epoch = 10, train_loss = 0.6741887331008911, valid_spearman = 0.09576894543631818\n",
      "epoch = 11, train_loss = 0.6717744469642639, valid_spearman = 0.10109564988210583\n",
      "epoch = 12, train_loss = 0.6692168712615967, valid_spearman = 0.10579362932689347\n",
      "epoch = 13, train_loss = 0.6665064096450806, valid_spearman = 0.10983153822160943\n",
      "epoch = 14, train_loss = 0.6636438965797424, valid_spearman = 0.11330669717451453\n",
      "epoch = 15, train_loss = 0.6606058478355408, valid_spearman = 0.11641165613892693\n",
      "epoch = 16, train_loss = 0.6574294567108154, valid_spearman = 0.11916076808479437\n",
      "epoch = 17, train_loss = 0.6540746092796326, valid_spearman = 0.12157786100860207\n",
      "epoch = 18, train_loss = 0.650550901889801, valid_spearman = 0.12356817287662518\n",
      "epoch = 19, train_loss = 0.6468429565429688, valid_spearman = 0.12524115044051137\n",
      "epoch = 20, train_loss = 0.6429761648178101, valid_spearman = 0.1267092812043467\n",
      "epoch = 21, train_loss = 0.6389362812042236, valid_spearman = 0.12806827159477183\n",
      "epoch = 22, train_loss = 0.634732186794281, valid_spearman = 0.12928891047317684\n",
      "epoch = 23, train_loss = 0.6303446292877197, valid_spearman = 0.13040155951692006\n",
      "epoch = 24, train_loss = 0.6258071660995483, valid_spearman = 0.13148651513136192\n",
      "epoch = 25, train_loss = 0.6210890412330627, valid_spearman = 0.1325505531761674\n",
      "epoch = 26, train_loss = 0.6162241697311401, valid_spearman = 0.13360541592716196\n",
      "epoch = 27, train_loss = 0.6111904978752136, valid_spearman = 0.13466567975176752\n",
      "epoch = 28, train_loss = 0.6059948801994324, valid_spearman = 0.13562457161363936\n",
      "epoch = 29, train_loss = 0.6006672978401184, valid_spearman = 0.13666502338977263\n",
      "epoch = 30, train_loss = 0.5952039361000061, valid_spearman = 0.13776260493931208\n",
      "epoch = 31, train_loss = 0.5896347165107727, valid_spearman = 0.13882481467150942\n",
      "epoch = 32, train_loss = 0.5839592218399048, valid_spearman = 0.13997207684650667\n",
      "epoch = 33, train_loss = 0.5782143473625183, valid_spearman = 0.1412008533961295\n",
      "epoch = 34, train_loss = 0.5724048018455505, valid_spearman = 0.1424854023776275\n",
      "epoch = 35, train_loss = 0.5665677785873413, valid_spearman = 0.1437168389675848\n",
      "epoch = 36, train_loss = 0.5607274770736694, valid_spearman = 0.1449074219754883\n",
      "epoch = 37, train_loss = 0.5549065470695496, valid_spearman = 0.14609639504821453\n",
      "epoch = 38, train_loss = 0.5491265654563904, valid_spearman = 0.14738226001112714\n",
      "epoch = 39, train_loss = 0.5434158444404602, valid_spearman = 0.14865843972219242\n",
      "epoch = 40, train_loss = 0.5377981066703796, valid_spearman = 0.14993077322434134\n",
      "epoch = 41, train_loss = 0.5322889685630798, valid_spearman = 0.1512558660670984\n",
      "epoch = 42, train_loss = 0.5269219875335693, valid_spearman = 0.15262779133119675\n",
      "epoch = 43, train_loss = 0.521699070930481, valid_spearman = 0.1539599615419934\n",
      "epoch = 44, train_loss = 0.5166434645652771, valid_spearman = 0.15534386044377632\n",
      "epoch = 45, train_loss = 0.5117448568344116, valid_spearman = 0.15682645225408437\n",
      "epoch = 46, train_loss = 0.5070253014564514, valid_spearman = 0.15822540624688386\n",
      "epoch = 47, train_loss = 0.50246661901474, valid_spearman = 0.1597233815997013\n",
      "epoch = 48, train_loss = 0.4980625510215759, valid_spearman = 0.16124600293908017\n",
      "epoch = 49, train_loss = 0.4938165247440338, valid_spearman = 0.16278334294628688\n",
      "epoch = 50, train_loss = 0.4897039830684662, valid_spearman = 0.16436029539308453\n",
      "epoch = 51, train_loss = 0.48574188351631165, valid_spearman = 0.16596737090899588\n",
      "epoch = 52, train_loss = 0.4819279611110687, valid_spearman = 0.1676573638300577\n",
      "epoch = 53, train_loss = 0.4782635271549225, valid_spearman = 0.1693021061824467\n",
      "epoch = 54, train_loss = 0.4747607409954071, valid_spearman = 0.17096081512434588\n",
      "epoch = 55, train_loss = 0.4714259207248688, valid_spearman = 0.17258910201944436\n",
      "epoch = 56, train_loss = 0.46824249625205994, valid_spearman = 0.17435164706060266\n",
      "epoch = 57, train_loss = 0.46520665287971497, valid_spearman = 0.17610775408568421\n",
      "epoch = 58, train_loss = 0.4623207151889801, valid_spearman = 0.17788866759849734\n",
      "epoch = 59, train_loss = 0.4595649838447571, valid_spearman = 0.17962850854752802\n",
      "epoch = 60, train_loss = 0.45691531896591187, valid_spearman = 0.18146169778066262\n",
      "epoch = 61, train_loss = 0.454359769821167, valid_spearman = 0.1833273876268275\n",
      "epoch = 62, train_loss = 0.4518873393535614, valid_spearman = 0.18526418524476346\n",
      "epoch = 63, train_loss = 0.44948703050613403, valid_spearman = 0.1872170968189823\n",
      "epoch = 64, train_loss = 0.4471568763256073, valid_spearman = 0.18921906124315935\n",
      "epoch = 65, train_loss = 0.4449061453342438, valid_spearman = 0.1911906319221415\n",
      "epoch = 66, train_loss = 0.4427279829978943, valid_spearman = 0.19324650736700055\n",
      "epoch = 67, train_loss = 0.44062408804893494, valid_spearman = 0.19524120173822673\n",
      "epoch = 68, train_loss = 0.4385986924171448, valid_spearman = 0.19709476521426766\n",
      "epoch = 69, train_loss = 0.43663132190704346, valid_spearman = 0.19893523073943056\n",
      "epoch = 70, train_loss = 0.43470996618270874, valid_spearman = 0.2006899979818296\n",
      "epoch = 71, train_loss = 0.4328274428844452, valid_spearman = 0.20242066101901188\n",
      "epoch = 72, train_loss = 0.43099716305732727, valid_spearman = 0.2040665948199757\n",
      "epoch = 73, train_loss = 0.4292185604572296, valid_spearman = 0.20568530081153844\n",
      "epoch = 74, train_loss = 0.42749619483947754, valid_spearman = 0.20717418910541496\n",
      "epoch = 75, train_loss = 0.42582857608795166, valid_spearman = 0.20868939238803613\n",
      "epoch = 76, train_loss = 0.42420971393585205, valid_spearman = 0.21017139818058048\n",
      "epoch = 77, train_loss = 0.4226442575454712, valid_spearman = 0.2115870416825773\n",
      "epoch = 78, train_loss = 0.42112013697624207, valid_spearman = 0.21290260817623707\n",
      "epoch = 79, train_loss = 0.4196504056453705, valid_spearman = 0.2141133127430736\n",
      "epoch = 80, train_loss = 0.418232262134552, valid_spearman = 0.21525103847649577\n",
      "epoch = 81, train_loss = 0.41686707735061646, valid_spearman = 0.21641237493553325\n",
      "epoch = 82, train_loss = 0.4155385494232178, valid_spearman = 0.217486520077674\n",
      "epoch = 83, train_loss = 0.4142560362815857, valid_spearman = 0.21851134909640985\n",
      "epoch = 84, train_loss = 0.4129985570907593, valid_spearman = 0.2195741508340886\n",
      "epoch = 85, train_loss = 0.41177359223365784, valid_spearman = 0.2205359585031559\n",
      "epoch = 86, train_loss = 0.41056615114212036, valid_spearman = 0.22148154574815893\n",
      "epoch = 87, train_loss = 0.4093846380710602, valid_spearman = 0.22242159077029658\n",
      "epoch = 88, train_loss = 0.4082343876361847, valid_spearman = 0.22332464291115478\n",
      "epoch = 89, train_loss = 0.40711116790771484, valid_spearman = 0.22414089864026038\n",
      "epoch = 90, train_loss = 0.4060160517692566, valid_spearman = 0.22500467602869328\n",
      "epoch = 91, train_loss = 0.40495434403419495, valid_spearman = 0.22595042523822464\n",
      "epoch = 92, train_loss = 0.4039166569709778, valid_spearman = 0.22683794207925997\n",
      "epoch = 93, train_loss = 0.4029156565666199, valid_spearman = 0.22776893258484748\n",
      "epoch = 94, train_loss = 0.40194687247276306, valid_spearman = 0.22873426673531852\n",
      "epoch = 95, train_loss = 0.4010053277015686, valid_spearman = 0.22972458839425977\n",
      "epoch = 96, train_loss = 0.4000928997993469, valid_spearman = 0.23074865215950757\n",
      "epoch = 97, train_loss = 0.3992059528827667, valid_spearman = 0.23166263164409145\n",
      "epoch = 98, train_loss = 0.3983370065689087, valid_spearman = 0.23269727869520546\n",
      "epoch = 99, train_loss = 0.3974986970424652, valid_spearman = 0.2337033097148363\n",
      "epoch = 100, train_loss = 0.39667677879333496, valid_spearman = 0.23464939630559373\n",
      "epoch = 101, train_loss = 0.39588549733161926, valid_spearman = 0.23561630007833725\n",
      "epoch = 102, train_loss = 0.3951060175895691, valid_spearman = 0.23652374814266108\n",
      "epoch = 103, train_loss = 0.39434683322906494, valid_spearman = 0.23741924016740965\n",
      "epoch = 104, train_loss = 0.39360880851745605, valid_spearman = 0.2383055637518615\n",
      "epoch = 105, train_loss = 0.3928883671760559, valid_spearman = 0.2391627028625189\n",
      "epoch = 106, train_loss = 0.39218589663505554, valid_spearman = 0.23999008519591178\n",
      "epoch = 107, train_loss = 0.3915036618709564, valid_spearman = 0.2407661794166599\n",
      "epoch = 108, train_loss = 0.3908405005931854, valid_spearman = 0.24154129795335097\n",
      "epoch = 109, train_loss = 0.39019259810447693, valid_spearman = 0.24230682753708205\n",
      "epoch = 110, train_loss = 0.3895629048347473, valid_spearman = 0.24307273749364589\n",
      "epoch = 111, train_loss = 0.3889525830745697, valid_spearman = 0.24389411529070312\n",
      "epoch = 112, train_loss = 0.3883512020111084, valid_spearman = 0.24470100665981723\n",
      "epoch = 113, train_loss = 0.38776516914367676, valid_spearman = 0.24550532399688188\n",
      "epoch = 114, train_loss = 0.3871973752975464, valid_spearman = 0.2463138866405424\n",
      "epoch = 115, train_loss = 0.3866426348686218, valid_spearman = 0.24707454569346285\n",
      "epoch = 116, train_loss = 0.3861003518104553, valid_spearman = 0.24781780437709305\n",
      "epoch = 117, train_loss = 0.3855707347393036, valid_spearman = 0.24857863553536916\n",
      "epoch = 118, train_loss = 0.3850526511669159, valid_spearman = 0.24931571760646418\n",
      "epoch = 119, train_loss = 0.38455405831336975, valid_spearman = 0.2500601964926072\n",
      "epoch = 120, train_loss = 0.38405725359916687, valid_spearman = 0.25075514399570564\n",
      "epoch = 121, train_loss = 0.3835771679878235, valid_spearman = 0.25151218359759053\n",
      "epoch = 122, train_loss = 0.38310834765434265, valid_spearman = 0.2522269291199583\n",
      "epoch = 123, train_loss = 0.38264840841293335, valid_spearman = 0.2529631382807793\n",
      "epoch = 124, train_loss = 0.38220053911209106, valid_spearman = 0.2536775603300275\n",
      "epoch = 125, train_loss = 0.3817608058452606, valid_spearman = 0.2543914919961409\n",
      "epoch = 126, train_loss = 0.3813299238681793, valid_spearman = 0.2550931331568364\n",
      "epoch = 127, train_loss = 0.38090980052948, valid_spearman = 0.25581891004815904\n",
      "epoch = 128, train_loss = 0.3804938495159149, valid_spearman = 0.25658046115887917\n",
      "epoch = 129, train_loss = 0.3800892233848572, valid_spearman = 0.25730363612012536\n",
      "epoch = 130, train_loss = 0.3796887993812561, valid_spearman = 0.25806871310376495\n",
      "epoch = 131, train_loss = 0.37929636240005493, valid_spearman = 0.258800472646598\n",
      "epoch = 132, train_loss = 0.3789074718952179, valid_spearman = 0.2595198827593591\n",
      "epoch = 133, train_loss = 0.3785278797149658, valid_spearman = 0.2602575464944372\n",
      "epoch = 134, train_loss = 0.37815335392951965, valid_spearman = 0.261037587441949\n",
      "epoch = 135, train_loss = 0.3777870833873749, valid_spearman = 0.26174898575671696\n",
      "epoch = 136, train_loss = 0.3774239718914032, valid_spearman = 0.26247124188740917\n",
      "epoch = 137, train_loss = 0.37706950306892395, valid_spearman = 0.2631165671444001\n",
      "epoch = 138, train_loss = 0.3767162263393402, valid_spearman = 0.2638235354532688\n",
      "epoch = 139, train_loss = 0.37637823820114136, valid_spearman = 0.2645237342365132\n",
      "epoch = 140, train_loss = 0.37603434920310974, valid_spearman = 0.26517844935097057\n",
      "epoch = 141, train_loss = 0.375699520111084, valid_spearman = 0.26582141781036817\n",
      "epoch = 142, train_loss = 0.37537333369255066, valid_spearman = 0.26652712130309514\n",
      "epoch = 143, train_loss = 0.37504884600639343, valid_spearman = 0.26718335597703907\n",
      "epoch = 144, train_loss = 0.37472885847091675, valid_spearman = 0.26785309935160384\n",
      "epoch = 145, train_loss = 0.37441056966781616, valid_spearman = 0.26845980875200764\n",
      "epoch = 146, train_loss = 0.3740990161895752, valid_spearman = 0.2690929464183341\n",
      "epoch = 147, train_loss = 0.3737899363040924, valid_spearman = 0.2696752077577937\n",
      "epoch = 148, train_loss = 0.37348830699920654, valid_spearman = 0.2702771615793737\n",
      "epoch = 149, train_loss = 0.3731902241706848, valid_spearman = 0.2708034120213789\n",
      "epoch = 150, train_loss = 0.37289467453956604, valid_spearman = 0.2713793029523376\n",
      "epoch = 151, train_loss = 0.37260258197784424, valid_spearman = 0.2719788873180031\n",
      "epoch = 152, train_loss = 0.37231749296188354, valid_spearman = 0.27255324687953647\n",
      "epoch = 153, train_loss = 0.37203872203826904, valid_spearman = 0.2731549242654887\n",
      "epoch = 154, train_loss = 0.3717556297779083, valid_spearman = 0.2737489334181213\n",
      "epoch = 155, train_loss = 0.37147873640060425, valid_spearman = 0.27433410227730004\n",
      "epoch = 156, train_loss = 0.3712047040462494, valid_spearman = 0.27490130873552004\n",
      "epoch = 157, train_loss = 0.37093397974967957, valid_spearman = 0.275473532280695\n",
      "epoch = 158, train_loss = 0.3706691861152649, valid_spearman = 0.27596830954664997\n",
      "epoch = 159, train_loss = 0.3704069256782532, valid_spearman = 0.2765252967287434\n",
      "epoch = 160, train_loss = 0.370148241519928, valid_spearman = 0.27703261237031557\n",
      "epoch = 161, train_loss = 0.36988961696624756, valid_spearman = 0.2775626903651297\n",
      "epoch = 162, train_loss = 0.3696340322494507, valid_spearman = 0.2780974744714923\n",
      "epoch = 163, train_loss = 0.36938410997390747, valid_spearman = 0.27864076760598266\n",
      "epoch = 164, train_loss = 0.36913490295410156, valid_spearman = 0.279131867193134\n",
      "epoch = 165, train_loss = 0.36889010667800903, valid_spearman = 0.27965461796377933\n",
      "epoch = 166, train_loss = 0.36864373087882996, valid_spearman = 0.28015024006168693\n",
      "epoch = 167, train_loss = 0.36840584874153137, valid_spearman = 0.2806277293628373\n",
      "epoch = 168, train_loss = 0.3681681454181671, valid_spearman = 0.28110976063860627\n",
      "epoch = 169, train_loss = 0.36792945861816406, valid_spearman = 0.28157211397990894\n",
      "epoch = 170, train_loss = 0.36769890785217285, valid_spearman = 0.2820701701636229\n",
      "epoch = 171, train_loss = 0.3674655258655548, valid_spearman = 0.2825335467321543\n",
      "epoch = 172, train_loss = 0.36723753809928894, valid_spearman = 0.2829660005204993\n",
      "epoch = 173, train_loss = 0.3670091927051544, valid_spearman = 0.2833904584755462\n",
      "epoch = 174, train_loss = 0.36678650975227356, valid_spearman = 0.2838092464192908\n",
      "epoch = 175, train_loss = 0.3665686249732971, valid_spearman = 0.28422077518814554\n",
      "epoch = 176, train_loss = 0.36634814739227295, valid_spearman = 0.28459713240489914\n",
      "epoch = 177, train_loss = 0.36613330245018005, valid_spearman = 0.28500521594174316\n",
      "epoch = 178, train_loss = 0.3659188449382782, valid_spearman = 0.28541101375772865\n",
      "epoch = 179, train_loss = 0.3657037615776062, valid_spearman = 0.28582226096999264\n",
      "epoch = 180, train_loss = 0.36549192667007446, valid_spearman = 0.2862206933605419\n",
      "epoch = 181, train_loss = 0.3652816414833069, valid_spearman = 0.28663887073831573\n",
      "epoch = 182, train_loss = 0.3650752305984497, valid_spearman = 0.28698164952244015\n",
      "epoch = 183, train_loss = 0.3648739457130432, valid_spearman = 0.2873441638606019\n",
      "epoch = 184, train_loss = 0.36467358469963074, valid_spearman = 0.28770753610171085\n",
      "epoch = 185, train_loss = 0.36447635293006897, valid_spearman = 0.2880094110891714\n",
      "epoch = 186, train_loss = 0.3642750084400177, valid_spearman = 0.28836307244565634\n",
      "epoch = 187, train_loss = 0.36407601833343506, valid_spearman = 0.2886662394288278\n",
      "epoch = 188, train_loss = 0.3638792634010315, valid_spearman = 0.28897373599666204\n",
      "epoch = 189, train_loss = 0.3636845052242279, valid_spearman = 0.28925559867603134\n",
      "epoch = 190, train_loss = 0.3634909987449646, valid_spearman = 0.2895360946745935\n",
      "epoch = 191, train_loss = 0.36330166459083557, valid_spearman = 0.28983792886327714\n",
      "epoch = 192, train_loss = 0.3631131947040558, valid_spearman = 0.29015487512279164\n",
      "epoch = 193, train_loss = 0.3629261255264282, valid_spearman = 0.29040471567302556\n",
      "epoch = 194, train_loss = 0.36274251341819763, valid_spearman = 0.2906994167680701\n",
      "epoch = 195, train_loss = 0.3625577688217163, valid_spearman = 0.2909835760243407\n",
      "epoch = 196, train_loss = 0.3623737692832947, valid_spearman = 0.29124362044770435\n",
      "epoch = 197, train_loss = 0.36219459772109985, valid_spearman = 0.29150443557980643\n",
      "epoch = 198, train_loss = 0.3620147109031677, valid_spearman = 0.29179802315495496\n",
      "epoch = 199, train_loss = 0.3618399500846863, valid_spearman = 0.2920382771378971\n",
      "epoch = 200, train_loss = 0.36166200041770935, valid_spearman = 0.2922727618156683\n",
      "epoch = 201, train_loss = 0.3614870309829712, valid_spearman = 0.2925002796236783\n",
      "epoch = 202, train_loss = 0.3613114356994629, valid_spearman = 0.29274442227923475\n",
      "epoch = 203, train_loss = 0.3611418902873993, valid_spearman = 0.2930002448530534\n",
      "epoch = 204, train_loss = 0.36097174882888794, valid_spearman = 0.2932377858407255\n",
      "epoch = 205, train_loss = 0.3608011305332184, valid_spearman = 0.29346534969792004\n",
      "epoch = 206, train_loss = 0.3606318235397339, valid_spearman = 0.2937144430445818\n",
      "epoch = 207, train_loss = 0.36046868562698364, valid_spearman = 0.2939499529018404\n",
      "epoch = 208, train_loss = 0.3603043854236603, valid_spearman = 0.29417996754866405\n",
      "epoch = 209, train_loss = 0.3601396679878235, valid_spearman = 0.29440886229633895\n",
      "epoch = 210, train_loss = 0.3599769175052643, valid_spearman = 0.2946217665505216\n",
      "epoch = 211, train_loss = 0.359811931848526, valid_spearman = 0.29483369208672855\n",
      "epoch = 212, train_loss = 0.3596542179584503, valid_spearman = 0.2950106800831185\n",
      "epoch = 213, train_loss = 0.35949254035949707, valid_spearman = 0.29519207627614\n",
      "epoch = 214, train_loss = 0.35933172702789307, valid_spearman = 0.29536215226056745\n",
      "epoch = 215, train_loss = 0.3591756224632263, valid_spearman = 0.29560850142927464\n",
      "epoch = 216, train_loss = 0.3590168356895447, valid_spearman = 0.2957815127833554\n",
      "epoch = 217, train_loss = 0.35886338353157043, valid_spearman = 0.29596557916096533\n",
      "epoch = 218, train_loss = 0.3587130904197693, valid_spearman = 0.2960928492349565\n",
      "epoch = 219, train_loss = 0.3585585951805115, valid_spearman = 0.29624425447279157\n",
      "epoch = 220, train_loss = 0.35840803384780884, valid_spearman = 0.296409734103918\n",
      "epoch = 221, train_loss = 0.35825493931770325, valid_spearman = 0.29655153698916975\n",
      "epoch = 222, train_loss = 0.3581066429615021, valid_spearman = 0.29670074826612086\n",
      "epoch = 223, train_loss = 0.35795485973358154, valid_spearman = 0.29683604140159836\n",
      "epoch = 224, train_loss = 0.3578084111213684, valid_spearman = 0.2969739557465487\n",
      "epoch = 225, train_loss = 0.3576582670211792, valid_spearman = 0.29713376394317326\n",
      "epoch = 226, train_loss = 0.35751163959503174, valid_spearman = 0.2972863283676196\n",
      "epoch = 227, train_loss = 0.3573649227619171, valid_spearman = 0.29744556202713385\n",
      "epoch = 228, train_loss = 0.3572221100330353, valid_spearman = 0.2975453462094844\n",
      "epoch = 229, train_loss = 0.357081800699234, valid_spearman = 0.2976442252566626\n",
      "epoch = 230, train_loss = 0.35693979263305664, valid_spearman = 0.297746485202536\n",
      "epoch = 231, train_loss = 0.3567979335784912, valid_spearman = 0.29787412403826335\n",
      "epoch = 232, train_loss = 0.3566555678844452, valid_spearman = 0.2979859239894024\n",
      "epoch = 233, train_loss = 0.3565165102481842, valid_spearman = 0.2980585269426571\n",
      "epoch = 234, train_loss = 0.3563785254955292, valid_spearman = 0.298164746154889\n",
      "epoch = 235, train_loss = 0.35624071955680847, valid_spearman = 0.2982649820997367\n",
      "epoch = 236, train_loss = 0.35610342025756836, valid_spearman = 0.29836245793093485\n",
      "epoch = 237, train_loss = 0.35596999526023865, valid_spearman = 0.29845091740005253\n",
      "epoch = 238, train_loss = 0.35583552718162537, valid_spearman = 0.29855897248181196\n",
      "epoch = 239, train_loss = 0.3557003140449524, valid_spearman = 0.29866901849797534\n",
      "epoch = 240, train_loss = 0.35556524991989136, valid_spearman = 0.2987676549244898\n",
      "epoch = 241, train_loss = 0.3554321527481079, valid_spearman = 0.2988625254263141\n",
      "epoch = 242, train_loss = 0.35529759526252747, valid_spearman = 0.29895705062081307\n",
      "epoch = 243, train_loss = 0.3551670014858246, valid_spearman = 0.2990290708844415\n",
      "epoch = 244, train_loss = 0.35503339767456055, valid_spearman = 0.2990967724855641\n",
      "epoch = 245, train_loss = 0.3549041152000427, valid_spearman = 0.29918806891494243\n",
      "epoch = 246, train_loss = 0.3547744154930115, valid_spearman = 0.29930277325445886\n",
      "epoch = 247, train_loss = 0.3546471893787384, valid_spearman = 0.2993827041689611\n",
      "epoch = 248, train_loss = 0.35451969504356384, valid_spearman = 0.2994953683572979\n",
      "epoch = 249, train_loss = 0.3543906509876251, valid_spearman = 0.29957175962025046\n",
      "epoch = 250, train_loss = 0.35426533222198486, valid_spearman = 0.29961408212199864\n",
      "epoch = 251, train_loss = 0.3541422188282013, valid_spearman = 0.2996630452727698\n",
      "epoch = 252, train_loss = 0.35401880741119385, valid_spearman = 0.29974590399065043\n",
      "epoch = 253, train_loss = 0.3538919985294342, valid_spearman = 0.2998383007611951\n",
      "epoch = 254, train_loss = 0.35376760363578796, valid_spearman = 0.2999489540530156\n",
      "epoch = 255, train_loss = 0.35364484786987305, valid_spearman = 0.30001341512035024\n",
      "epoch = 256, train_loss = 0.35352471470832825, valid_spearman = 0.3001002045653927\n",
      "epoch = 257, train_loss = 0.3534013628959656, valid_spearman = 0.30014859342864847\n",
      "epoch = 258, train_loss = 0.35328197479248047, valid_spearman = 0.3002179724938464\n",
      "epoch = 259, train_loss = 0.3531574606895447, valid_spearman = 0.3002981706139339\n",
      "epoch = 260, train_loss = 0.353036105632782, valid_spearman = 0.30040812390602156\n",
      "epoch = 261, train_loss = 0.3529176115989685, valid_spearman = 0.3004838750856639\n",
      "epoch = 262, train_loss = 0.3527999520301819, valid_spearman = 0.3005472842516847\n",
      "epoch = 263, train_loss = 0.35268062353134155, valid_spearman = 0.3006056011649726\n",
      "epoch = 264, train_loss = 0.35256314277648926, valid_spearman = 0.30070334429380846\n",
      "epoch = 265, train_loss = 0.3524462878704071, valid_spearman = 0.3007718350418241\n",
      "epoch = 266, train_loss = 0.3523305654525757, valid_spearman = 0.30084290696242705\n",
      "epoch = 267, train_loss = 0.3522169589996338, valid_spearman = 0.3009057911412665\n",
      "epoch = 268, train_loss = 0.35210153460502625, valid_spearman = 0.3009702849857442\n",
      "epoch = 269, train_loss = 0.351987361907959, valid_spearman = 0.301045309204755\n",
      "epoch = 270, train_loss = 0.35187458992004395, valid_spearman = 0.3011133526774763\n",
      "epoch = 271, train_loss = 0.3517623543739319, valid_spearman = 0.30118595180430346\n",
      "epoch = 272, train_loss = 0.3516470193862915, valid_spearman = 0.30128319130926656\n",
      "epoch = 273, train_loss = 0.35153359174728394, valid_spearman = 0.30136667793688016\n",
      "epoch = 274, train_loss = 0.3514231741428375, valid_spearman = 0.3014275307021165\n",
      "epoch = 275, train_loss = 0.35131150484085083, valid_spearman = 0.3014922380558552\n",
      "epoch = 276, train_loss = 0.35119831562042236, valid_spearman = 0.3015682470897779\n",
      "epoch = 277, train_loss = 0.3510878086090088, valid_spearman = 0.30163800295314225\n",
      "epoch = 278, train_loss = 0.35097721219062805, valid_spearman = 0.3017237144898796\n",
      "epoch = 279, train_loss = 0.3508717119693756, valid_spearman = 0.30179247374555274\n",
      "epoch = 280, train_loss = 0.3507627844810486, valid_spearman = 0.3018556695250132\n",
      "epoch = 281, train_loss = 0.35065266489982605, valid_spearman = 0.3019253449151196\n",
      "epoch = 282, train_loss = 0.35054540634155273, valid_spearman = 0.30199408903410657\n",
      "epoch = 283, train_loss = 0.3504381775856018, valid_spearman = 0.3020469180836744\n",
      "epoch = 284, train_loss = 0.3503327965736389, valid_spearman = 0.3021079124719296\n",
      "epoch = 285, train_loss = 0.35022857785224915, valid_spearman = 0.30214332768351865\n",
      "epoch = 286, train_loss = 0.35011935234069824, valid_spearman = 0.3021950154989532\n",
      "epoch = 287, train_loss = 0.3500157594680786, valid_spearman = 0.30224358904582876\n",
      "epoch = 288, train_loss = 0.3499091565608978, valid_spearman = 0.3023024866451795\n",
      "epoch = 289, train_loss = 0.34980273246765137, valid_spearman = 0.30235444920231785\n",
      "epoch = 290, train_loss = 0.3496997058391571, valid_spearman = 0.302388199423331\n",
      "epoch = 291, train_loss = 0.3495970368385315, valid_spearman = 0.3024204601011785\n",
      "epoch = 292, train_loss = 0.34949326515197754, valid_spearman = 0.3025078052861602\n",
      "epoch = 293, train_loss = 0.3493906259536743, valid_spearman = 0.30253624560989056\n",
      "epoch = 294, train_loss = 0.34928658604621887, valid_spearman = 0.30260518356391686\n",
      "epoch = 295, train_loss = 0.3491848111152649, valid_spearman = 0.3026396646544799\n",
      "epoch = 296, train_loss = 0.3490849435329437, valid_spearman = 0.30269135952541393\n",
      "epoch = 297, train_loss = 0.34898024797439575, valid_spearman = 0.30271672741798644\n",
      "epoch = 298, train_loss = 0.34887993335723877, valid_spearman = 0.30274681386911084\n",
      "epoch = 299, train_loss = 0.3487784266471863, valid_spearman = 0.3027914665130442\n",
      "epoch = 300, train_loss = 0.34868305921554565, valid_spearman = 0.3028602284778821\n",
      "epoch = 301, train_loss = 0.3485834300518036, valid_spearman = 0.30288291753900104\n",
      "epoch = 302, train_loss = 0.3484812080860138, valid_spearman = 0.30295185379520284\n",
      "epoch = 303, train_loss = 0.3483814299106598, valid_spearman = 0.30298143274515066\n",
      "epoch = 304, train_loss = 0.3482818007469177, valid_spearman = 0.3030808552922451\n",
      "epoch = 305, train_loss = 0.34818366169929504, valid_spearman = 0.30315782267794417\n",
      "epoch = 306, train_loss = 0.3480818569660187, valid_spearman = 0.3032040815943742\n",
      "epoch = 307, train_loss = 0.3479824960231781, valid_spearman = 0.30324298123833293\n",
      "epoch = 308, train_loss = 0.3478839099407196, valid_spearman = 0.3032605674651129\n",
      "epoch = 309, train_loss = 0.34778928756713867, valid_spearman = 0.3033289043759907\n",
      "epoch = 310, train_loss = 0.3476904630661011, valid_spearman = 0.3033887347164962\n",
      "epoch = 311, train_loss = 0.34759578108787537, valid_spearman = 0.303444712478551\n",
      "epoch = 312, train_loss = 0.3474970757961273, valid_spearman = 0.3034664144130529\n",
      "epoch = 313, train_loss = 0.3474009335041046, valid_spearman = 0.30354476801462305\n",
      "epoch = 314, train_loss = 0.347307026386261, valid_spearman = 0.303565761067919\n",
      "epoch = 315, train_loss = 0.3472107946872711, valid_spearman = 0.30362914387640877\n",
      "epoch = 316, train_loss = 0.3471151888370514, valid_spearman = 0.3036930665063196\n",
      "epoch = 317, train_loss = 0.34702005982398987, valid_spearman = 0.30378747990245236\n",
      "epoch = 318, train_loss = 0.3469237983226776, valid_spearman = 0.3038442438983147\n",
      "epoch = 319, train_loss = 0.34682977199554443, valid_spearman = 0.3038695396994805\n",
      "epoch = 320, train_loss = 0.3467380106449127, valid_spearman = 0.3039018492323317\n",
      "epoch = 321, train_loss = 0.3466441333293915, valid_spearman = 0.30391475542898133\n",
      "epoch = 322, train_loss = 0.346548855304718, valid_spearman = 0.3039910874457407\n",
      "epoch = 323, train_loss = 0.34645456075668335, valid_spearman = 0.3040317616896643\n",
      "epoch = 324, train_loss = 0.3463631570339203, valid_spearman = 0.3041222377556778\n",
      "epoch = 325, train_loss = 0.3462667465209961, valid_spearman = 0.30415360306011724\n",
      "epoch = 326, train_loss = 0.3461761474609375, valid_spearman = 0.3042213333640041\n",
      "epoch = 327, train_loss = 0.34608402848243713, valid_spearman = 0.3042650458363371\n",
      "epoch = 328, train_loss = 0.3459914028644562, valid_spearman = 0.30437489083618996\n",
      "epoch = 329, train_loss = 0.34589821100234985, valid_spearman = 0.30444405782103307\n",
      "epoch = 330, train_loss = 0.34580913186073303, valid_spearman = 0.30450852051777616\n",
      "epoch = 331, train_loss = 0.34571853280067444, valid_spearman = 0.3045647818039985\n",
      "epoch = 332, train_loss = 0.3456245958805084, valid_spearman = 0.3045989728079953\n",
      "epoch = 333, train_loss = 0.34553489089012146, valid_spearman = 0.30465448575548126\n",
      "epoch = 334, train_loss = 0.3454475402832031, valid_spearman = 0.3046907781821099\n",
      "epoch = 335, train_loss = 0.3453581929206848, valid_spearman = 0.3047931239148223\n",
      "epoch = 336, train_loss = 0.3452693819999695, valid_spearman = 0.3048509677570187\n",
      "epoch = 337, train_loss = 0.3451770842075348, valid_spearman = 0.30492441420830546\n",
      "epoch = 338, train_loss = 0.3450906276702881, valid_spearman = 0.3050031864909746\n",
      "epoch = 339, train_loss = 0.34499987959861755, valid_spearman = 0.30505986070982405\n",
      "epoch = 340, train_loss = 0.3449108302593231, valid_spearman = 0.30512597456125906\n",
      "epoch = 341, train_loss = 0.3448256850242615, valid_spearman = 0.30518618703218003\n",
      "epoch = 342, train_loss = 0.34473544359207153, valid_spearman = 0.3052333788605692\n",
      "epoch = 343, train_loss = 0.3446478247642517, valid_spearman = 0.3052713877505778\n",
      "epoch = 344, train_loss = 0.3445591330528259, valid_spearman = 0.3053090220228247\n",
      "epoch = 345, train_loss = 0.3444715738296509, valid_spearman = 0.3053585932060814\n",
      "epoch = 346, train_loss = 0.3443828523159027, valid_spearman = 0.305368590816235\n",
      "epoch = 347, train_loss = 0.3442988395690918, valid_spearman = 0.30541755172020846\n",
      "epoch = 348, train_loss = 0.34421002864837646, valid_spearman = 0.30547936525000713\n",
      "epoch = 349, train_loss = 0.3441239595413208, valid_spearman = 0.30552408941199655\n",
      "epoch = 350, train_loss = 0.34403592348098755, valid_spearman = 0.30557528984671495\n",
      "epoch = 351, train_loss = 0.3439498543739319, valid_spearman = 0.30560655021659927\n",
      "epoch = 352, train_loss = 0.343862920999527, valid_spearman = 0.30566444830586925\n",
      "epoch = 353, train_loss = 0.34377923607826233, valid_spearman = 0.305687201149467\n",
      "epoch = 354, train_loss = 0.3436886668205261, valid_spearman = 0.3057212408218884\n",
      "epoch = 355, train_loss = 0.343605101108551, valid_spearman = 0.3057433315988245\n",
      "epoch = 356, train_loss = 0.3435210585594177, valid_spearman = 0.3058030384520902\n",
      "epoch = 357, train_loss = 0.3434365689754486, valid_spearman = 0.3058311859975215\n",
      "epoch = 358, train_loss = 0.3433533012866974, valid_spearman = 0.3059113055813714\n",
      "epoch = 359, train_loss = 0.34326761960983276, valid_spearman = 0.3059348628714604\n",
      "epoch = 360, train_loss = 0.34318414330482483, valid_spearman = 0.3060234799938606\n",
      "epoch = 361, train_loss = 0.3430998921394348, valid_spearman = 0.30607874916249955\n",
      "epoch = 362, train_loss = 0.343016117811203, valid_spearman = 0.30610721360579274\n",
      "epoch = 363, train_loss = 0.34293147921562195, valid_spearman = 0.3061351188542234\n",
      "epoch = 364, train_loss = 0.34284713864326477, valid_spearman = 0.3061357599773773\n",
      "epoch = 365, train_loss = 0.3427640199661255, valid_spearman = 0.30615858660191375\n",
      "epoch = 366, train_loss = 0.34268108010292053, valid_spearman = 0.30618936376655387\n",
      "epoch = 367, train_loss = 0.34259968996047974, valid_spearman = 0.3062489391668163\n",
      "epoch = 368, train_loss = 0.3425179123878479, valid_spearman = 0.3062654460081578\n",
      "epoch = 369, train_loss = 0.3424344062805176, valid_spearman = 0.30632332302920673\n",
      "epoch = 370, train_loss = 0.34235048294067383, valid_spearman = 0.3063657824626275\n",
      "epoch = 371, train_loss = 0.34226951003074646, valid_spearman = 0.30644056726401064\n",
      "epoch = 372, train_loss = 0.3421911597251892, valid_spearman = 0.30647831498686084\n",
      "epoch = 373, train_loss = 0.34211134910583496, valid_spearman = 0.3065187425463275\n",
      "epoch = 374, train_loss = 0.3420296907424927, valid_spearman = 0.306553431754953\n",
      "epoch = 375, train_loss = 0.34194833040237427, valid_spearman = 0.30659078034529313\n",
      "epoch = 376, train_loss = 0.34186771512031555, valid_spearman = 0.3066308702997983\n",
      "epoch = 377, train_loss = 0.3417857587337494, valid_spearman = 0.30669013496390457\n",
      "epoch = 378, train_loss = 0.3417055308818817, valid_spearman = 0.3067046202715289\n",
      "epoch = 379, train_loss = 0.3416246771812439, valid_spearman = 0.3067531471173893\n",
      "epoch = 380, train_loss = 0.341548889875412, valid_spearman = 0.30675725194097764\n",
      "epoch = 381, train_loss = 0.3414700925350189, valid_spearman = 0.3067975239981967\n",
      "epoch = 382, train_loss = 0.3413938283920288, valid_spearman = 0.3068656062098611\n",
      "epoch = 383, train_loss = 0.3413145840167999, valid_spearman = 0.3068921366342911\n",
      "epoch = 384, train_loss = 0.3412412405014038, valid_spearman = 0.3069162330255518\n",
      "epoch = 385, train_loss = 0.3411593735218048, valid_spearman = 0.3069604217323804\n",
      "epoch = 386, train_loss = 0.3410801589488983, valid_spearman = 0.30700725781347693\n",
      "epoch = 387, train_loss = 0.3410016596317291, valid_spearman = 0.30706657445831703\n",
      "epoch = 388, train_loss = 0.34092259407043457, valid_spearman = 0.30710476377032736\n",
      "epoch = 389, train_loss = 0.3408437967300415, valid_spearman = 0.30716709042367174\n",
      "epoch = 390, train_loss = 0.3407672047615051, valid_spearman = 0.3071420919164011\n",
      "epoch = 391, train_loss = 0.3406909704208374, valid_spearman = 0.307184353660188\n",
      "epoch = 392, train_loss = 0.34061330556869507, valid_spearman = 0.30720190806699843\n",
      "epoch = 393, train_loss = 0.34053710103034973, valid_spearman = 0.30721746064053984\n",
      "epoch = 394, train_loss = 0.3404587209224701, valid_spearman = 0.30728847721815616\n",
      "epoch = 395, train_loss = 0.34038254618644714, valid_spearman = 0.30729265677710765\n",
      "epoch = 396, train_loss = 0.3403063714504242, valid_spearman = 0.3073564126644432\n",
      "epoch = 397, train_loss = 0.3402314782142639, valid_spearman = 0.30739531852125784\n",
      "epoch = 398, train_loss = 0.34015437960624695, valid_spearman = 0.3074310317566752\n",
      "epoch = 399, train_loss = 0.3400774896144867, valid_spearman = 0.307522676256065\n",
      "epoch = 400, train_loss = 0.3400023579597473, valid_spearman = 0.3075813602110237\n",
      "epoch = 401, train_loss = 0.33992791175842285, valid_spearman = 0.3076185506653132\n",
      "epoch = 402, train_loss = 0.3398524224758148, valid_spearman = 0.3076257220023403\n",
      "epoch = 403, train_loss = 0.3397792875766754, valid_spearman = 0.3076810768008493\n",
      "epoch = 404, train_loss = 0.33970603346824646, valid_spearman = 0.3077340789357832\n",
      "epoch = 405, train_loss = 0.33962923288345337, valid_spearman = 0.3077844450199815\n",
      "epoch = 406, train_loss = 0.33955174684524536, valid_spearman = 0.30778558852969157\n",
      "epoch = 407, train_loss = 0.33948028087615967, valid_spearman = 0.3077822856982207\n",
      "epoch = 408, train_loss = 0.33940526843070984, valid_spearman = 0.30778479259908187\n",
      "question_asker_intent_understanding rho: 0.257380992132594\n",
      "question_body_critical rho: 0.5703112633718199\n",
      "question_conversational rho: 0.35863662380763517\n",
      "question_expect_short_answer rho: 0.13724208652334913\n",
      "question_fact_seeking rho: 0.2162401228726253\n",
      "question_has_commonly_accepted_answer rho: 0.38319710337748025\n",
      "question_interestingness_others rho: 0.32089074023805486\n",
      "question_interestingness_self rho: 0.39525512614250075\n",
      "question_multi_intent rho: 0.3735952406367539\n",
      "question_not_really_a_question rho: -0.018411449959511463\n",
      "question_opinion_seeking rho: 0.28788630772587176\n",
      "question_type_choice rho: 0.5237494690043999\n",
      "question_type_compare rho: 0.2362360698032014\n",
      "question_type_consequence rho: 0.10158873999535084\n",
      "question_type_definition rho: 0.30712432437515047\n",
      "question_type_entity rho: 0.3400277041935995\n",
      "question_type_instructions rho: 0.7084387787565983\n",
      "question_type_procedure rho: 0.280298233285891\n",
      "question_type_reason_explanation rho: 0.49900233908614167\n",
      "question_type_spelling rho: 0.043187041653938836\n",
      "question_well_written rho: 0.48262099305348294\n",
      "answer_helpful rho: 0.15003532299798855\n",
      "answer_level_of_information rho: 0.3615949370712227\n",
      "answer_plausible rho: 0.0880777154040319\n",
      "answer_relevance rho: 0.10374508857990136\n",
      "answer_satisfaction rho: 0.19830372177566946\n",
      "answer_type_instructions rho: 0.6919858056573625\n",
      "answer_type_procedure rho: 0.19308095422273094\n",
      "answer_type_reason_explanation rho: 0.5630485387234826\n",
      "answer_well_written rho: 0.07917384346313608\n",
      "fold = 3\n",
      "epoch = 0, train_loss = 0.6936793327331543, valid_spearman = 0.007626113324648476\n",
      "epoch = 1, train_loss = 0.6919727921485901, valid_spearman = 0.01554882776402979\n",
      "epoch = 2, train_loss = 0.6902632713317871, valid_spearman = 0.02307874864111614\n",
      "epoch = 3, train_loss = 0.6885063052177429, valid_spearman = 0.029826846465335337\n",
      "epoch = 4, train_loss = 0.6866356134414673, valid_spearman = 0.035387189496014285\n",
      "epoch = 5, train_loss = 0.6847109794616699, valid_spearman = 0.04009363770288214\n",
      "epoch = 6, train_loss = 0.6826751828193665, valid_spearman = 0.04411394343125853\n",
      "epoch = 7, train_loss = 0.6805328130722046, valid_spearman = 0.04860136002412112\n",
      "epoch = 8, train_loss = 0.6782224774360657, valid_spearman = 0.051987831211165896\n",
      "epoch = 9, train_loss = 0.6757872700691223, valid_spearman = 0.054860161398215763\n",
      "epoch = 10, train_loss = 0.6731746196746826, valid_spearman = 0.05768892716905201\n",
      "epoch = 11, train_loss = 0.6703933477401733, valid_spearman = 0.06047917272346115\n",
      "epoch = 12, train_loss = 0.6674492955207825, valid_spearman = 0.063220129531671\n",
      "epoch = 13, train_loss = 0.6642888188362122, valid_spearman = 0.06601715845579299\n",
      "epoch = 14, train_loss = 0.6609395146369934, valid_spearman = 0.06873335234729284\n",
      "epoch = 15, train_loss = 0.6573646068572998, valid_spearman = 0.07130978604833166\n",
      "epoch = 16, train_loss = 0.6535987854003906, valid_spearman = 0.07400923870823657\n",
      "epoch = 17, train_loss = 0.6496002078056335, valid_spearman = 0.07644666152175637\n",
      "epoch = 18, train_loss = 0.6453627943992615, valid_spearman = 0.07876839791247522\n",
      "epoch = 19, train_loss = 0.6409080624580383, valid_spearman = 0.08091775042948764\n",
      "epoch = 20, train_loss = 0.6362412571907043, valid_spearman = 0.08302152086215277\n",
      "epoch = 21, train_loss = 0.631367564201355, valid_spearman = 0.08478307017018823\n",
      "epoch = 22, train_loss = 0.6262764930725098, valid_spearman = 0.08662018460362945\n",
      "epoch = 23, train_loss = 0.6210022568702698, valid_spearman = 0.08831592214048635\n",
      "epoch = 24, train_loss = 0.6155368685722351, valid_spearman = 0.08983191277503412\n",
      "epoch = 25, train_loss = 0.6099045872688293, valid_spearman = 0.091285567512513\n",
      "epoch = 26, train_loss = 0.6041141748428345, valid_spearman = 0.09247076710034573\n",
      "epoch = 27, train_loss = 0.5982002019882202, valid_spearman = 0.09357096182359807\n",
      "epoch = 28, train_loss = 0.5921745896339417, valid_spearman = 0.09464874530672866\n",
      "epoch = 29, train_loss = 0.5860990881919861, valid_spearman = 0.09566007257224199\n",
      "epoch = 30, train_loss = 0.5799679756164551, valid_spearman = 0.09674122586555287\n",
      "epoch = 31, train_loss = 0.5738599300384521, valid_spearman = 0.09777050252371229\n",
      "epoch = 32, train_loss = 0.5677921175956726, valid_spearman = 0.09876313247910996\n",
      "epoch = 33, train_loss = 0.5617884993553162, valid_spearman = 0.0997573177367174\n",
      "epoch = 34, train_loss = 0.5558971762657166, valid_spearman = 0.10068163665846354\n",
      "epoch = 35, train_loss = 0.5501364469528198, valid_spearman = 0.1017633797356011\n",
      "epoch = 36, train_loss = 0.5445285439491272, valid_spearman = 0.10285622227243306\n",
      "epoch = 37, train_loss = 0.539089560508728, valid_spearman = 0.10403900671274927\n",
      "epoch = 38, train_loss = 0.5338419079780579, valid_spearman = 0.10545213669616986\n",
      "epoch = 39, train_loss = 0.5287891626358032, valid_spearman = 0.10691449982088833\n",
      "epoch = 40, train_loss = 0.5239356160163879, valid_spearman = 0.10860124108881337\n",
      "epoch = 41, train_loss = 0.5192800164222717, valid_spearman = 0.11043892751632704\n",
      "epoch = 42, train_loss = 0.5148229002952576, valid_spearman = 0.11252359012463217\n",
      "epoch = 43, train_loss = 0.5105464458465576, valid_spearman = 0.11465030119291565\n",
      "epoch = 44, train_loss = 0.5064442753791809, valid_spearman = 0.11696850705936934\n",
      "epoch = 45, train_loss = 0.5025113224983215, valid_spearman = 0.11927398685708908\n",
      "epoch = 46, train_loss = 0.4987313747406006, valid_spearman = 0.1216312543635871\n",
      "epoch = 47, train_loss = 0.4950892925262451, valid_spearman = 0.12420832968203398\n",
      "epoch = 48, train_loss = 0.4915717840194702, valid_spearman = 0.1268497199816424\n",
      "epoch = 49, train_loss = 0.48816990852355957, valid_spearman = 0.12953560557451163\n",
      "epoch = 50, train_loss = 0.4848749339580536, valid_spearman = 0.1321558620068699\n",
      "epoch = 51, train_loss = 0.48166534304618835, valid_spearman = 0.13496558329103844\n",
      "epoch = 52, train_loss = 0.4785565733909607, valid_spearman = 0.13783910474727099\n",
      "epoch = 53, train_loss = 0.47553396224975586, valid_spearman = 0.14076414097137216\n",
      "epoch = 54, train_loss = 0.47259020805358887, valid_spearman = 0.1435963499711444\n",
      "epoch = 55, train_loss = 0.46974581480026245, valid_spearman = 0.14653556596557837\n",
      "epoch = 56, train_loss = 0.46698620915412903, valid_spearman = 0.14947428534795926\n",
      "epoch = 57, train_loss = 0.4643348455429077, valid_spearman = 0.15241049161882753\n",
      "epoch = 58, train_loss = 0.4617839753627777, valid_spearman = 0.15532974159894222\n",
      "epoch = 59, train_loss = 0.45934057235717773, valid_spearman = 0.1582248075299687\n",
      "epoch = 60, train_loss = 0.4570057690143585, valid_spearman = 0.1611389300871175\n",
      "epoch = 61, train_loss = 0.4547790586948395, valid_spearman = 0.16403325168742425\n",
      "epoch = 62, train_loss = 0.4526519775390625, valid_spearman = 0.16692116036092935\n",
      "epoch = 63, train_loss = 0.450625479221344, valid_spearman = 0.16972622161012313\n",
      "epoch = 64, train_loss = 0.4486958682537079, valid_spearman = 0.17241164813959226\n",
      "epoch = 65, train_loss = 0.44684556126594543, valid_spearman = 0.17510933005243556\n",
      "epoch = 66, train_loss = 0.4450730085372925, valid_spearman = 0.1777854821579586\n",
      "epoch = 67, train_loss = 0.4433758556842804, valid_spearman = 0.1804664006408071\n",
      "epoch = 68, train_loss = 0.44174352288246155, valid_spearman = 0.18310326310452404\n",
      "epoch = 69, train_loss = 0.44016656279563904, valid_spearman = 0.18566387550644484\n",
      "epoch = 70, train_loss = 0.4386392831802368, valid_spearman = 0.18820297905043792\n",
      "epoch = 71, train_loss = 0.4371524155139923, valid_spearman = 0.1906509414072667\n",
      "epoch = 72, train_loss = 0.435696005821228, valid_spearman = 0.19303514866866622\n",
      "epoch = 73, train_loss = 0.4342727065086365, valid_spearman = 0.1953441381321741\n",
      "epoch = 74, train_loss = 0.4328814148902893, valid_spearman = 0.19761287891153603\n",
      "epoch = 75, train_loss = 0.4315226674079895, valid_spearman = 0.199726456255978\n",
      "epoch = 76, train_loss = 0.43019452691078186, valid_spearman = 0.20187160482611535\n",
      "epoch = 77, train_loss = 0.42890802025794983, valid_spearman = 0.20401791281980236\n",
      "epoch = 78, train_loss = 0.42765918374061584, valid_spearman = 0.20609888908217489\n",
      "epoch = 79, train_loss = 0.42644202709198, valid_spearman = 0.20815804637230506\n",
      "epoch = 80, train_loss = 0.42525747418403625, valid_spearman = 0.21015884816023755\n",
      "epoch = 81, train_loss = 0.42409855127334595, valid_spearman = 0.21212787825487517\n",
      "epoch = 82, train_loss = 0.42296314239501953, valid_spearman = 0.21409823881974113\n",
      "epoch = 83, train_loss = 0.42184194922447205, valid_spearman = 0.2160121226849178\n",
      "epoch = 84, train_loss = 0.4207356572151184, valid_spearman = 0.21790979486639223\n",
      "epoch = 85, train_loss = 0.4196486175060272, valid_spearman = 0.21973810342153893\n",
      "epoch = 86, train_loss = 0.41857147216796875, valid_spearman = 0.2215502026926724\n",
      "epoch = 87, train_loss = 0.41750720143318176, valid_spearman = 0.22335173827326613\n",
      "epoch = 88, train_loss = 0.4164586365222931, valid_spearman = 0.225171506368285\n",
      "epoch = 89, train_loss = 0.41542503237724304, valid_spearman = 0.22691598776453625\n",
      "epoch = 90, train_loss = 0.41440826654434204, valid_spearman = 0.22874195870616296\n",
      "epoch = 91, train_loss = 0.41340360045433044, valid_spearman = 0.230413414747222\n",
      "epoch = 92, train_loss = 0.4124244451522827, valid_spearman = 0.23198024629133346\n",
      "epoch = 93, train_loss = 0.41145458817481995, valid_spearman = 0.23361742113737216\n",
      "epoch = 94, train_loss = 0.41050004959106445, valid_spearman = 0.23520247411527442\n",
      "epoch = 95, train_loss = 0.40956825017929077, valid_spearman = 0.23677632393893475\n",
      "epoch = 96, train_loss = 0.40864771604537964, valid_spearman = 0.2382467532567419\n",
      "epoch = 97, train_loss = 0.40774405002593994, valid_spearman = 0.23965586187726384\n",
      "epoch = 98, train_loss = 0.40684911608695984, valid_spearman = 0.2410585829454988\n",
      "epoch = 99, train_loss = 0.4059711694717407, valid_spearman = 0.2424526466725903\n",
      "epoch = 100, train_loss = 0.4051104784011841, valid_spearman = 0.24378335271854362\n",
      "epoch = 101, train_loss = 0.4042573869228363, valid_spearman = 0.24509671180548973\n",
      "epoch = 102, train_loss = 0.40341925621032715, valid_spearman = 0.24630757880387985\n",
      "epoch = 103, train_loss = 0.40259262919425964, valid_spearman = 0.24757390105070895\n",
      "epoch = 104, train_loss = 0.4017869830131531, valid_spearman = 0.24877830320585456\n",
      "epoch = 105, train_loss = 0.40099480748176575, valid_spearman = 0.24996151402676162\n",
      "epoch = 106, train_loss = 0.4002075791358948, valid_spearman = 0.2511454167521615\n",
      "epoch = 107, train_loss = 0.39944180846214294, valid_spearman = 0.25220026430330883\n",
      "epoch = 108, train_loss = 0.3986847698688507, valid_spearman = 0.25321972597960124\n",
      "epoch = 109, train_loss = 0.3979370594024658, valid_spearman = 0.254263902996772\n",
      "epoch = 110, train_loss = 0.39720526337623596, valid_spearman = 0.25528589716276084\n",
      "epoch = 111, train_loss = 0.39648234844207764, valid_spearman = 0.2562390589818745\n",
      "epoch = 112, train_loss = 0.39576923847198486, valid_spearman = 0.25713615197141565\n",
      "epoch = 113, train_loss = 0.395067036151886, valid_spearman = 0.2580608727216566\n",
      "epoch = 114, train_loss = 0.39438092708587646, valid_spearman = 0.25886837449325206\n",
      "epoch = 115, train_loss = 0.3937031030654907, valid_spearman = 0.2596635719181631\n",
      "epoch = 116, train_loss = 0.3930417001247406, valid_spearman = 0.2604516632454881\n",
      "epoch = 117, train_loss = 0.3923834264278412, valid_spearman = 0.2611891720234859\n",
      "epoch = 118, train_loss = 0.3917473554611206, valid_spearman = 0.2619024753654387\n",
      "epoch = 119, train_loss = 0.39111971855163574, valid_spearman = 0.26257761126121526\n",
      "epoch = 120, train_loss = 0.3904998004436493, valid_spearman = 0.2632911485534219\n",
      "epoch = 121, train_loss = 0.3898905813694, valid_spearman = 0.2639556962377111\n",
      "epoch = 122, train_loss = 0.3892931342124939, valid_spearman = 0.264653176447491\n",
      "epoch = 123, train_loss = 0.38870325684547424, valid_spearman = 0.26531857594190184\n",
      "epoch = 124, train_loss = 0.38813135027885437, valid_spearman = 0.26594071591130874\n",
      "epoch = 125, train_loss = 0.38756582140922546, valid_spearman = 0.2665467175329922\n",
      "epoch = 126, train_loss = 0.3870163559913635, valid_spearman = 0.2671426024832787\n",
      "epoch = 127, train_loss = 0.38647329807281494, valid_spearman = 0.26768307746298414\n",
      "epoch = 128, train_loss = 0.38594329357147217, valid_spearman = 0.2682076502650018\n",
      "epoch = 129, train_loss = 0.38542476296424866, valid_spearman = 0.26872634385054905\n",
      "epoch = 130, train_loss = 0.38492169976234436, valid_spearman = 0.2692296019871422\n",
      "epoch = 131, train_loss = 0.3844180405139923, valid_spearman = 0.2697351464575471\n",
      "epoch = 132, train_loss = 0.38393184542655945, valid_spearman = 0.2702179808647553\n",
      "epoch = 133, train_loss = 0.38345402479171753, valid_spearman = 0.2707026819393182\n",
      "epoch = 134, train_loss = 0.3829869329929352, valid_spearman = 0.2711743349389874\n",
      "epoch = 135, train_loss = 0.38253217935562134, valid_spearman = 0.2716874678854939\n",
      "epoch = 136, train_loss = 0.382085919380188, valid_spearman = 0.2721504561318176\n",
      "epoch = 137, train_loss = 0.38164544105529785, valid_spearman = 0.2726191415857457\n",
      "epoch = 138, train_loss = 0.38121771812438965, valid_spearman = 0.2731011426068745\n",
      "epoch = 139, train_loss = 0.3807999789714813, valid_spearman = 0.2735510281532331\n",
      "epoch = 140, train_loss = 0.38039228320121765, valid_spearman = 0.2740169618859971\n",
      "epoch = 141, train_loss = 0.3799910843372345, valid_spearman = 0.2745033798400827\n",
      "epoch = 142, train_loss = 0.37959811091423035, valid_spearman = 0.27490494573460855\n",
      "epoch = 143, train_loss = 0.3792128562927246, valid_spearman = 0.2753109054679016\n",
      "epoch = 144, train_loss = 0.3788376450538635, valid_spearman = 0.27572729795701384\n",
      "epoch = 145, train_loss = 0.37847182154655457, valid_spearman = 0.2761778100153029\n",
      "epoch = 146, train_loss = 0.37811100482940674, valid_spearman = 0.2765979021410466\n",
      "epoch = 147, train_loss = 0.37775787711143494, valid_spearman = 0.2769873100076131\n",
      "epoch = 148, train_loss = 0.37740886211395264, valid_spearman = 0.27740515504141006\n",
      "epoch = 149, train_loss = 0.3770672380924225, valid_spearman = 0.277811281083514\n",
      "epoch = 150, train_loss = 0.376735657453537, valid_spearman = 0.2782246781590436\n",
      "epoch = 151, train_loss = 0.3764086067676544, valid_spearman = 0.2786445146738329\n",
      "epoch = 152, train_loss = 0.3760906457901001, valid_spearman = 0.27903915272994\n",
      "epoch = 153, train_loss = 0.37577253580093384, valid_spearman = 0.2794303652160302\n",
      "epoch = 154, train_loss = 0.3754643499851227, valid_spearman = 0.27981112151287685\n",
      "epoch = 155, train_loss = 0.37516123056411743, valid_spearman = 0.28018479669416013\n",
      "epoch = 156, train_loss = 0.37486547231674194, valid_spearman = 0.28055938480990955\n",
      "epoch = 157, train_loss = 0.37457311153411865, valid_spearman = 0.2809394208143831\n",
      "epoch = 158, train_loss = 0.3742850124835968, valid_spearman = 0.28125188605487816\n",
      "epoch = 159, train_loss = 0.3740016222000122, valid_spearman = 0.28160239881889576\n",
      "epoch = 160, train_loss = 0.3737247586250305, valid_spearman = 0.28196497524631997\n",
      "epoch = 161, train_loss = 0.3734499216079712, valid_spearman = 0.2823512850830024\n",
      "epoch = 162, train_loss = 0.3731807470321655, valid_spearman = 0.2826982089300267\n",
      "epoch = 163, train_loss = 0.37291762232780457, valid_spearman = 0.2830558006454115\n",
      "epoch = 164, train_loss = 0.37265557050704956, valid_spearman = 0.2834034918009715\n",
      "epoch = 165, train_loss = 0.3723985254764557, valid_spearman = 0.28371451341896836\n",
      "epoch = 166, train_loss = 0.3721458613872528, valid_spearman = 0.28407724390164746\n",
      "epoch = 167, train_loss = 0.37189552187919617, valid_spearman = 0.28440846846387413\n",
      "epoch = 168, train_loss = 0.3716469407081604, valid_spearman = 0.28472963825883274\n",
      "epoch = 169, train_loss = 0.37140539288520813, valid_spearman = 0.28505554519314974\n",
      "epoch = 170, train_loss = 0.3711663782596588, valid_spearman = 0.2853677432495582\n",
      "epoch = 171, train_loss = 0.37092918157577515, valid_spearman = 0.2857008206651376\n",
      "epoch = 172, train_loss = 0.37069347500801086, valid_spearman = 0.2860551065764069\n",
      "epoch = 173, train_loss = 0.37046360969543457, valid_spearman = 0.2863815632474524\n",
      "epoch = 174, train_loss = 0.37023529410362244, valid_spearman = 0.2866876171792507\n",
      "epoch = 175, train_loss = 0.3700110614299774, valid_spearman = 0.28698503130486913\n",
      "epoch = 176, train_loss = 0.36978673934936523, valid_spearman = 0.2873012025418154\n",
      "epoch = 177, train_loss = 0.3695683181285858, valid_spearman = 0.28757105493775476\n",
      "epoch = 178, train_loss = 0.369350403547287, valid_spearman = 0.287861380677265\n",
      "epoch = 179, train_loss = 0.3691375255584717, valid_spearman = 0.2881550504593505\n",
      "epoch = 180, train_loss = 0.36892420053482056, valid_spearman = 0.2884408193539643\n",
      "epoch = 181, train_loss = 0.36871200799942017, valid_spearman = 0.2887083571257646\n",
      "epoch = 182, train_loss = 0.3685072362422943, valid_spearman = 0.2889791257520207\n",
      "epoch = 183, train_loss = 0.3682987689971924, valid_spearman = 0.2892479850288854\n",
      "epoch = 184, train_loss = 0.36809584498405457, valid_spearman = 0.28952742545613586\n",
      "epoch = 185, train_loss = 0.3678893744945526, valid_spearman = 0.28978838181905114\n",
      "epoch = 186, train_loss = 0.3676890432834625, valid_spearman = 0.290089506095379\n",
      "epoch = 187, train_loss = 0.36749136447906494, valid_spearman = 0.29036890198905324\n",
      "epoch = 188, train_loss = 0.36729562282562256, valid_spearman = 0.29062980299683344\n",
      "epoch = 189, train_loss = 0.3671001195907593, valid_spearman = 0.2908604299958079\n",
      "epoch = 190, train_loss = 0.36690834164619446, valid_spearman = 0.2911114351535988\n",
      "epoch = 191, train_loss = 0.36671721935272217, valid_spearman = 0.29136660234939105\n",
      "epoch = 192, train_loss = 0.36653071641921997, valid_spearman = 0.29163140257625464\n",
      "epoch = 193, train_loss = 0.3663440942764282, valid_spearman = 0.2919065841809642\n",
      "epoch = 194, train_loss = 0.36615583300590515, valid_spearman = 0.292134522835095\n",
      "epoch = 195, train_loss = 0.365972638130188, valid_spearman = 0.292366185832393\n",
      "epoch = 196, train_loss = 0.3657912015914917, valid_spearman = 0.29261173147725655\n",
      "epoch = 197, train_loss = 0.3656099736690521, valid_spearman = 0.29286758200318913\n",
      "epoch = 198, train_loss = 0.36543241143226624, valid_spearman = 0.2931266501943025\n",
      "epoch = 199, train_loss = 0.3652550280094147, valid_spearman = 0.2933646483556781\n",
      "epoch = 200, train_loss = 0.36507976055145264, valid_spearman = 0.29360164339429057\n",
      "epoch = 201, train_loss = 0.36490491032600403, valid_spearman = 0.2938168462085122\n",
      "epoch = 202, train_loss = 0.3647303581237793, valid_spearman = 0.2940223533121381\n",
      "epoch = 203, train_loss = 0.36455702781677246, valid_spearman = 0.2942370372728106\n",
      "epoch = 204, train_loss = 0.3643859326839447, valid_spearman = 0.29444063490057787\n",
      "epoch = 205, train_loss = 0.36421647667884827, valid_spearman = 0.29465930245974603\n",
      "epoch = 206, train_loss = 0.36404871940612793, valid_spearman = 0.29485954114895363\n",
      "epoch = 207, train_loss = 0.363880455493927, valid_spearman = 0.2950791430485567\n",
      "epoch = 208, train_loss = 0.36371535062789917, valid_spearman = 0.29526529571014254\n",
      "epoch = 209, train_loss = 0.36355122923851013, valid_spearman = 0.2954651392037013\n",
      "epoch = 210, train_loss = 0.36338910460472107, valid_spearman = 0.2956629710571383\n",
      "epoch = 211, train_loss = 0.36322733759880066, valid_spearman = 0.2958544734745434\n",
      "epoch = 212, train_loss = 0.36306509375572205, valid_spearman = 0.2960615733445989\n",
      "epoch = 213, train_loss = 0.36290428042411804, valid_spearman = 0.29624894283064296\n",
      "epoch = 214, train_loss = 0.3627447783946991, valid_spearman = 0.2964591127021649\n",
      "epoch = 215, train_loss = 0.36258819699287415, valid_spearman = 0.2966314541018931\n",
      "epoch = 216, train_loss = 0.3624296486377716, valid_spearman = 0.29681941545185764\n",
      "epoch = 217, train_loss = 0.36227452754974365, valid_spearman = 0.29696761515526027\n",
      "epoch = 218, train_loss = 0.36211803555488586, valid_spearman = 0.297137878731332\n",
      "epoch = 219, train_loss = 0.361965149641037, valid_spearman = 0.29732940655070045\n",
      "epoch = 220, train_loss = 0.36181074380874634, valid_spearman = 0.29751738836737474\n",
      "epoch = 221, train_loss = 0.36165934801101685, valid_spearman = 0.2976927007319155\n",
      "epoch = 222, train_loss = 0.3615061342716217, valid_spearman = 0.2978265830571301\n",
      "epoch = 223, train_loss = 0.36135825514793396, valid_spearman = 0.29798393416134217\n",
      "epoch = 224, train_loss = 0.3612096309661865, valid_spearman = 0.2981539991313264\n",
      "epoch = 225, train_loss = 0.3610581159591675, valid_spearman = 0.29833176940497247\n",
      "epoch = 226, train_loss = 0.3609101474285126, valid_spearman = 0.2984892569616129\n",
      "epoch = 227, train_loss = 0.3607637882232666, valid_spearman = 0.2986334810497559\n",
      "epoch = 228, train_loss = 0.36061781644821167, valid_spearman = 0.29879482406685187\n",
      "epoch = 229, train_loss = 0.36047235131263733, valid_spearman = 0.298950584897528\n",
      "epoch = 230, train_loss = 0.3603273928165436, valid_spearman = 0.2990862544675864\n",
      "epoch = 231, train_loss = 0.36017751693725586, valid_spearman = 0.2991892777271544\n",
      "epoch = 232, train_loss = 0.3600383400917053, valid_spearman = 0.29933436714699885\n",
      "epoch = 233, train_loss = 0.35989561676979065, valid_spearman = 0.299467790791919\n",
      "epoch = 234, train_loss = 0.3597554564476013, valid_spearman = 0.29960293609576755\n",
      "epoch = 235, train_loss = 0.3596131205558777, valid_spearman = 0.29972907610173566\n",
      "epoch = 236, train_loss = 0.3594726622104645, valid_spearman = 0.29983700124543616\n",
      "epoch = 237, train_loss = 0.35933592915534973, valid_spearman = 0.29997108632730635\n",
      "epoch = 238, train_loss = 0.3591977059841156, valid_spearman = 0.3001096508858225\n",
      "epoch = 239, train_loss = 0.3590582013130188, valid_spearman = 0.30026643251426716\n",
      "epoch = 240, train_loss = 0.35892045497894287, valid_spearman = 0.30040185694825455\n",
      "epoch = 241, train_loss = 0.3587861955165863, valid_spearman = 0.30051799699753406\n",
      "epoch = 242, train_loss = 0.35865119099617004, valid_spearman = 0.30060879705386667\n",
      "epoch = 243, train_loss = 0.3585149645805359, valid_spearman = 0.300743527174313\n",
      "epoch = 244, train_loss = 0.35837945342063904, valid_spearman = 0.30086758413192033\n",
      "epoch = 245, train_loss = 0.3582457900047302, valid_spearman = 0.30100136142781936\n",
      "epoch = 246, train_loss = 0.3581134080886841, valid_spearman = 0.30112207133027913\n",
      "epoch = 247, train_loss = 0.35797980427742004, valid_spearman = 0.30124901157190076\n",
      "epoch = 248, train_loss = 0.3578472137451172, valid_spearman = 0.30138429128825694\n",
      "epoch = 249, train_loss = 0.35771459341049194, valid_spearman = 0.30149385655165123\n",
      "epoch = 250, train_loss = 0.3575837016105652, valid_spearman = 0.30160850249121357\n",
      "epoch = 251, train_loss = 0.35745495557785034, valid_spearman = 0.3017537865752543\n",
      "epoch = 252, train_loss = 0.3573274612426758, valid_spearman = 0.3018621271267322\n",
      "epoch = 253, train_loss = 0.3571981191635132, valid_spearman = 0.3019969093681635\n",
      "epoch = 254, train_loss = 0.3570704758167267, valid_spearman = 0.3021182712726483\n",
      "epoch = 255, train_loss = 0.35694319009780884, valid_spearman = 0.3022311739549394\n",
      "epoch = 256, train_loss = 0.35681480169296265, valid_spearman = 0.30235651238122313\n",
      "epoch = 257, train_loss = 0.3566890358924866, valid_spearman = 0.3024568977166552\n",
      "epoch = 258, train_loss = 0.3565653860569, valid_spearman = 0.3025414370608217\n",
      "epoch = 259, train_loss = 0.356437087059021, valid_spearman = 0.30264838352884765\n",
      "epoch = 260, train_loss = 0.356312096118927, valid_spearman = 0.30275986510577635\n",
      "epoch = 261, train_loss = 0.3561875522136688, valid_spearman = 0.3028602682969802\n",
      "epoch = 262, train_loss = 0.35606732964515686, valid_spearman = 0.30296117513578313\n",
      "epoch = 263, train_loss = 0.35594412684440613, valid_spearman = 0.30308453717454775\n",
      "epoch = 264, train_loss = 0.35582053661346436, valid_spearman = 0.30317321861644686\n",
      "epoch = 265, train_loss = 0.35569825768470764, valid_spearman = 0.3032526057530679\n",
      "epoch = 266, train_loss = 0.3555780053138733, valid_spearman = 0.30333286346315397\n",
      "epoch = 267, train_loss = 0.35545822978019714, valid_spearman = 0.30340917168427206\n",
      "epoch = 268, train_loss = 0.35533902049064636, valid_spearman = 0.30352401246098404\n",
      "epoch = 269, train_loss = 0.3552228808403015, valid_spearman = 0.3036295672381894\n",
      "epoch = 270, train_loss = 0.3550996482372284, valid_spearman = 0.3037187838088682\n",
      "epoch = 271, train_loss = 0.35498201847076416, valid_spearman = 0.30381767311245045\n",
      "epoch = 272, train_loss = 0.35486331582069397, valid_spearman = 0.30390231109469706\n",
      "epoch = 273, train_loss = 0.35474711656570435, valid_spearman = 0.3039992261643138\n",
      "epoch = 274, train_loss = 0.35463133454322815, valid_spearman = 0.30403834085492437\n",
      "epoch = 275, train_loss = 0.3545161485671997, valid_spearman = 0.3040941783632149\n",
      "epoch = 276, train_loss = 0.3543986976146698, valid_spearman = 0.30419301609351523\n",
      "epoch = 277, train_loss = 0.354282408952713, valid_spearman = 0.30429434885678214\n",
      "epoch = 278, train_loss = 0.35416698455810547, valid_spearman = 0.30432723669825607\n",
      "epoch = 279, train_loss = 0.35405436158180237, valid_spearman = 0.30439774348715043\n",
      "epoch = 280, train_loss = 0.3539421260356903, valid_spearman = 0.3044540932272757\n",
      "epoch = 281, train_loss = 0.3538289964199066, valid_spearman = 0.3044963657207844\n",
      "epoch = 282, train_loss = 0.35371536016464233, valid_spearman = 0.30455912370565\n",
      "epoch = 283, train_loss = 0.35360369086265564, valid_spearman = 0.30462305868529593\n",
      "epoch = 284, train_loss = 0.3534930646419525, valid_spearman = 0.30468939369375353\n",
      "epoch = 285, train_loss = 0.353384792804718, valid_spearman = 0.3047367834070234\n",
      "epoch = 286, train_loss = 0.3532745838165283, valid_spearman = 0.304804852428262\n",
      "epoch = 287, train_loss = 0.3531650900840759, valid_spearman = 0.30486992027008836\n",
      "epoch = 288, train_loss = 0.3530540466308594, valid_spearman = 0.3049539333318673\n",
      "epoch = 289, train_loss = 0.35294869542121887, valid_spearman = 0.3050412411048525\n",
      "epoch = 290, train_loss = 0.3528401553630829, valid_spearman = 0.30509616054106664\n",
      "epoch = 291, train_loss = 0.3527316153049469, valid_spearman = 0.30516051647670533\n",
      "epoch = 292, train_loss = 0.3526240587234497, valid_spearman = 0.3052227722382811\n",
      "epoch = 293, train_loss = 0.3525179922580719, valid_spearman = 0.3052830027612215\n",
      "epoch = 294, train_loss = 0.3524087071418762, valid_spearman = 0.3053709213262263\n",
      "epoch = 295, train_loss = 0.35230347514152527, valid_spearman = 0.3054329000526644\n",
      "epoch = 296, train_loss = 0.35219940543174744, valid_spearman = 0.3054959385973465\n",
      "epoch = 297, train_loss = 0.352094441652298, valid_spearman = 0.3055651150986416\n",
      "epoch = 298, train_loss = 0.3519895076751709, valid_spearman = 0.3056066142689574\n",
      "epoch = 299, train_loss = 0.35188767313957214, valid_spearman = 0.30565544695572927\n",
      "epoch = 300, train_loss = 0.3517846465110779, valid_spearman = 0.30572594031691125\n",
      "epoch = 301, train_loss = 0.35168197751045227, valid_spearman = 0.30577593775512385\n",
      "epoch = 302, train_loss = 0.35158178210258484, valid_spearman = 0.3058267844816426\n",
      "epoch = 303, train_loss = 0.35148105025291443, valid_spearman = 0.3058599741773465\n",
      "epoch = 304, train_loss = 0.35137978196144104, valid_spearman = 0.3058918486686739\n",
      "epoch = 305, train_loss = 0.35127848386764526, valid_spearman = 0.30592580407288583\n",
      "epoch = 306, train_loss = 0.35117849707603455, valid_spearman = 0.30593470075009593\n",
      "epoch = 307, train_loss = 0.3510780334472656, valid_spearman = 0.30596746261287416\n",
      "epoch = 308, train_loss = 0.35097846388816833, valid_spearman = 0.30600328694927054\n",
      "epoch = 309, train_loss = 0.35087862610816956, valid_spearman = 0.30603049967799856\n",
      "epoch = 310, train_loss = 0.3507803976535797, valid_spearman = 0.30604948847421043\n",
      "epoch = 311, train_loss = 0.3506848216056824, valid_spearman = 0.3060634170873462\n",
      "epoch = 312, train_loss = 0.3505876958370209, valid_spearman = 0.3060766198528615\n",
      "epoch = 313, train_loss = 0.35048985481262207, valid_spearman = 0.30609186130458677\n",
      "epoch = 314, train_loss = 0.3503933548927307, valid_spearman = 0.3061151283748714\n",
      "epoch = 315, train_loss = 0.35029587149620056, valid_spearman = 0.3061256094509124\n",
      "epoch = 316, train_loss = 0.3502018451690674, valid_spearman = 0.30619099059336247\n",
      "epoch = 317, train_loss = 0.350106418132782, valid_spearman = 0.30623071174151034\n",
      "epoch = 318, train_loss = 0.35001176595687866, valid_spearman = 0.3062567078090474\n",
      "epoch = 319, train_loss = 0.3499172031879425, valid_spearman = 0.30628299939706705\n",
      "epoch = 320, train_loss = 0.34982410073280334, valid_spearman = 0.3063173553605551\n",
      "epoch = 321, train_loss = 0.3497317135334015, valid_spearman = 0.30634582795992166\n",
      "epoch = 322, train_loss = 0.34963855147361755, valid_spearman = 0.30635108183741255\n",
      "epoch = 323, train_loss = 0.3495434820652008, valid_spearman = 0.30637737336070026\n",
      "epoch = 324, train_loss = 0.3494497537612915, valid_spearman = 0.3063790116258174\n",
      "epoch = 325, train_loss = 0.3493609130382538, valid_spearman = 0.30643021127755393\n",
      "epoch = 326, train_loss = 0.34926837682724, valid_spearman = 0.3064638175805273\n",
      "epoch = 327, train_loss = 0.3491779863834381, valid_spearman = 0.3065121267412578\n",
      "epoch = 328, train_loss = 0.3490881621837616, valid_spearman = 0.3065465340137138\n",
      "epoch = 329, train_loss = 0.34899720549583435, valid_spearman = 0.30658716436908795\n",
      "epoch = 330, train_loss = 0.3489071726799011, valid_spearman = 0.30663948498331656\n",
      "epoch = 331, train_loss = 0.34881827235221863, valid_spearman = 0.3066471832958459\n",
      "epoch = 332, train_loss = 0.3487265408039093, valid_spearman = 0.3066727687676446\n",
      "epoch = 333, train_loss = 0.3486373722553253, valid_spearman = 0.30670711676339224\n",
      "epoch = 334, train_loss = 0.3485485315322876, valid_spearman = 0.3067278465070697\n",
      "epoch = 335, train_loss = 0.3484628200531006, valid_spearman = 0.3067549706786072\n",
      "epoch = 336, train_loss = 0.34837397933006287, valid_spearman = 0.3067905867538758\n",
      "epoch = 337, train_loss = 0.34828564524650574, valid_spearman = 0.30683215955894677\n",
      "epoch = 338, train_loss = 0.34820082783699036, valid_spearman = 0.3068431334549874\n",
      "epoch = 339, train_loss = 0.348113089799881, valid_spearman = 0.30689751279495836\n",
      "epoch = 340, train_loss = 0.34802570939064026, valid_spearman = 0.30692254619306125\n",
      "epoch = 341, train_loss = 0.3479403853416443, valid_spearman = 0.3069234430428248\n",
      "epoch = 342, train_loss = 0.3478533923625946, valid_spearman = 0.30693776001053374\n",
      "epoch = 343, train_loss = 0.34776604175567627, valid_spearman = 0.3069511406855481\n",
      "epoch = 344, train_loss = 0.3476793169975281, valid_spearman = 0.3069547927808175\n",
      "epoch = 345, train_loss = 0.34759339690208435, valid_spearman = 0.30700181571205787\n",
      "epoch = 346, train_loss = 0.34750816226005554, valid_spearman = 0.30705233690434214\n",
      "epoch = 347, train_loss = 0.3474251925945282, valid_spearman = 0.30709879472275997\n",
      "epoch = 348, train_loss = 0.3473401665687561, valid_spearman = 0.3071409088630728\n",
      "epoch = 349, train_loss = 0.3472561240196228, valid_spearman = 0.3071644644033868\n",
      "epoch = 350, train_loss = 0.34717318415641785, valid_spearman = 0.30718990140539043\n",
      "epoch = 351, train_loss = 0.34708860516548157, valid_spearman = 0.30718960345937696\n",
      "epoch = 352, train_loss = 0.34700727462768555, valid_spearman = 0.30721788680183326\n",
      "epoch = 353, train_loss = 0.34692060947418213, valid_spearman = 0.3072236596224686\n",
      "epoch = 354, train_loss = 0.3468379080295563, valid_spearman = 0.30726145314134345\n",
      "epoch = 355, train_loss = 0.3467562198638916, valid_spearman = 0.3072926947537982\n",
      "epoch = 356, train_loss = 0.3466741740703583, valid_spearman = 0.30734994037820323\n",
      "epoch = 357, train_loss = 0.34659120440483093, valid_spearman = 0.3074011430928588\n",
      "epoch = 358, train_loss = 0.34650900959968567, valid_spearman = 0.30741694324218943\n",
      "epoch = 359, train_loss = 0.34642651677131653, valid_spearman = 0.30738352513876427\n",
      "epoch = 360, train_loss = 0.34634605050086975, valid_spearman = 0.30736050588092856\n",
      "question_asker_intent_understanding rho: 0.15915749578424127\n",
      "question_body_critical rho: 0.5260387523182934\n",
      "question_conversational rho: 0.36622096908259005\n",
      "question_expect_short_answer rho: 0.20217994753871885\n",
      "question_fact_seeking rho: 0.24953556362565915\n",
      "question_has_commonly_accepted_answer rho: 0.30442199313617047\n",
      "question_interestingness_others rho: 0.31212549753717617\n",
      "question_interestingness_self rho: 0.43092131173239057\n",
      "question_multi_intent rho: 0.3662176711966219\n",
      "question_not_really_a_question rho: -0.025187982718473303\n",
      "question_opinion_seeking rho: 0.28444268898768693\n",
      "question_type_choice rho: 0.5434937134626167\n",
      "question_type_compare rho: 0.26690806837597686\n",
      "question_type_consequence rho: 0.12989299437579296\n",
      "question_type_definition rho: 0.32330538403701986\n",
      "question_type_entity rho: 0.2975383027967337\n",
      "question_type_instructions rho: 0.7045770453471182\n",
      "question_type_procedure rho: 0.2996120481036146\n",
      "question_type_reason_explanation rho: 0.5534908282220781\n",
      "question_type_spelling rho: 0.054518277633227315\n",
      "question_well_written rho: 0.3986044447374331\n",
      "answer_helpful rho: 0.1333783490457943\n",
      "answer_level_of_information rho: 0.34481163511866897\n",
      "answer_plausible rho: 0.04511912326935932\n",
      "answer_relevance rho: 0.08308759495109592\n",
      "answer_satisfaction rho: 0.21672908353370474\n",
      "answer_type_instructions rho: 0.6864814961387258\n",
      "answer_type_procedure rho: 0.25521159663678866\n",
      "answer_type_reason_explanation rho: 0.6188454564314965\n",
      "answer_well_written rho: 0.08913582598953466\n",
      "fold = 4\n",
      "epoch = 0, train_loss = 0.694095253944397, valid_spearman = 0.0110712128192845\n",
      "epoch = 1, train_loss = 0.6919141411781311, valid_spearman = 0.022059769189627567\n",
      "epoch = 2, train_loss = 0.6898250579833984, valid_spearman = 0.03195902754627415\n",
      "epoch = 3, train_loss = 0.6877732872962952, valid_spearman = 0.040435649929505546\n",
      "epoch = 4, train_loss = 0.6857280731201172, valid_spearman = 0.04785618634062317\n",
      "epoch = 5, train_loss = 0.6836367249488831, valid_spearman = 0.054029997678686964\n",
      "epoch = 6, train_loss = 0.6814693212509155, valid_spearman = 0.059467603398791216\n",
      "epoch = 7, train_loss = 0.6791824102401733, valid_spearman = 0.06418352937347722\n",
      "epoch = 8, train_loss = 0.6767320036888123, valid_spearman = 0.06869037184899293\n",
      "epoch = 9, train_loss = 0.6741287112236023, valid_spearman = 0.07269348742819613\n",
      "epoch = 10, train_loss = 0.6713342666625977, valid_spearman = 0.07633216103596552\n",
      "epoch = 11, train_loss = 0.668340265750885, valid_spearman = 0.07973607245147414\n",
      "epoch = 12, train_loss = 0.6651270389556885, valid_spearman = 0.08289728771945362\n",
      "epoch = 13, train_loss = 0.6616700291633606, valid_spearman = 0.0859262733977939\n",
      "epoch = 14, train_loss = 0.6579811573028564, valid_spearman = 0.08861902402870611\n",
      "epoch = 15, train_loss = 0.6540305018424988, valid_spearman = 0.0912533865931585\n",
      "epoch = 16, train_loss = 0.6498018503189087, valid_spearman = 0.0936688126866238\n",
      "epoch = 17, train_loss = 0.6453055143356323, valid_spearman = 0.09607177686859215\n",
      "epoch = 18, train_loss = 0.6405199766159058, valid_spearman = 0.09853572863982629\n",
      "epoch = 19, train_loss = 0.6354479789733887, valid_spearman = 0.10067203202847655\n",
      "epoch = 20, train_loss = 0.6300978660583496, valid_spearman = 0.10277327284475418\n",
      "epoch = 21, train_loss = 0.6244543790817261, valid_spearman = 0.10484208406677174\n",
      "epoch = 22, train_loss = 0.6185540556907654, valid_spearman = 0.10681589467571845\n",
      "epoch = 23, train_loss = 0.6123797297477722, valid_spearman = 0.10858102758839304\n",
      "epoch = 24, train_loss = 0.6059654355049133, valid_spearman = 0.1103252775394354\n",
      "epoch = 25, train_loss = 0.5993520021438599, valid_spearman = 0.11201902800306365\n",
      "epoch = 26, train_loss = 0.5925391912460327, valid_spearman = 0.11372458649280645\n",
      "epoch = 27, train_loss = 0.5855714678764343, valid_spearman = 0.1153346917455776\n",
      "epoch = 28, train_loss = 0.5784862041473389, valid_spearman = 0.11696047780247672\n",
      "epoch = 29, train_loss = 0.5713459253311157, valid_spearman = 0.11847216208640184\n",
      "epoch = 30, train_loss = 0.5641778707504272, valid_spearman = 0.11980464542544057\n",
      "epoch = 31, train_loss = 0.5570282340049744, valid_spearman = 0.12099119114507663\n",
      "epoch = 32, train_loss = 0.5499511361122131, valid_spearman = 0.12206965777247612\n",
      "epoch = 33, train_loss = 0.5429915189743042, valid_spearman = 0.12303501405171963\n",
      "epoch = 34, train_loss = 0.5361928343772888, valid_spearman = 0.12400357394586023\n",
      "epoch = 35, train_loss = 0.5295944809913635, valid_spearman = 0.12484364040169292\n",
      "epoch = 36, train_loss = 0.523219645023346, valid_spearman = 0.1257664261542901\n",
      "epoch = 37, train_loss = 0.5171038508415222, valid_spearman = 0.1266508050592863\n",
      "epoch = 38, train_loss = 0.5112615823745728, valid_spearman = 0.1276922037447129\n",
      "epoch = 39, train_loss = 0.5057135224342346, valid_spearman = 0.12879771859945072\n",
      "epoch = 40, train_loss = 0.5004481673240662, valid_spearman = 0.1300375132532029\n",
      "epoch = 41, train_loss = 0.49548226594924927, valid_spearman = 0.13121186039764884\n",
      "epoch = 42, train_loss = 0.4908057451248169, valid_spearman = 0.13260744152484713\n",
      "epoch = 43, train_loss = 0.4863964915275574, valid_spearman = 0.13413837044530802\n",
      "epoch = 44, train_loss = 0.4822404384613037, valid_spearman = 0.13572939580164353\n",
      "epoch = 45, train_loss = 0.4783163368701935, valid_spearman = 0.13740466980999885\n",
      "epoch = 46, train_loss = 0.4745963215827942, valid_spearman = 0.13923032672374408\n",
      "epoch = 47, train_loss = 0.47107550501823425, valid_spearman = 0.14112408332848453\n",
      "epoch = 48, train_loss = 0.46770983934402466, valid_spearman = 0.1431854613249458\n",
      "epoch = 49, train_loss = 0.46450522541999817, valid_spearman = 0.1452242380084239\n",
      "epoch = 50, train_loss = 0.46143296360969543, valid_spearman = 0.14739877199876636\n",
      "epoch = 51, train_loss = 0.4584868848323822, valid_spearman = 0.14959270439662414\n",
      "epoch = 52, train_loss = 0.4556715488433838, valid_spearman = 0.15178287841010904\n",
      "epoch = 53, train_loss = 0.4529663026332855, valid_spearman = 0.15408039969135465\n",
      "epoch = 54, train_loss = 0.45036813616752625, valid_spearman = 0.15652190856142273\n",
      "epoch = 55, train_loss = 0.44786936044692993, valid_spearman = 0.15903493992751738\n",
      "epoch = 56, train_loss = 0.44546863436698914, valid_spearman = 0.161421326676567\n",
      "epoch = 57, train_loss = 0.4431546628475189, valid_spearman = 0.16396244917703917\n",
      "epoch = 58, train_loss = 0.44092628359794617, valid_spearman = 0.1665796493129365\n",
      "epoch = 59, train_loss = 0.4387650489807129, valid_spearman = 0.16912420702533876\n",
      "epoch = 60, train_loss = 0.436677485704422, valid_spearman = 0.17170355277748994\n",
      "epoch = 61, train_loss = 0.4346459209918976, valid_spearman = 0.17417621860101937\n",
      "epoch = 62, train_loss = 0.4326712191104889, valid_spearman = 0.1767047888445605\n",
      "epoch = 63, train_loss = 0.430770605802536, valid_spearman = 0.1792147475304794\n",
      "epoch = 64, train_loss = 0.42892545461654663, valid_spearman = 0.1815481917335677\n",
      "epoch = 65, train_loss = 0.427142471075058, valid_spearman = 0.18384185171006237\n",
      "epoch = 66, train_loss = 0.4254304766654968, valid_spearman = 0.1859954068519315\n",
      "epoch = 67, train_loss = 0.4237877428531647, valid_spearman = 0.1880593574140407\n",
      "epoch = 68, train_loss = 0.42221924662590027, valid_spearman = 0.19008041048561308\n",
      "epoch = 69, train_loss = 0.4207145571708679, valid_spearman = 0.19202315834623684\n",
      "epoch = 70, train_loss = 0.41927945613861084, valid_spearman = 0.19388060955094932\n",
      "epoch = 71, train_loss = 0.4179040491580963, valid_spearman = 0.19575200129277037\n",
      "epoch = 72, train_loss = 0.41658806800842285, valid_spearman = 0.1975669150422638\n",
      "epoch = 73, train_loss = 0.4153136610984802, valid_spearman = 0.1993418496928792\n",
      "epoch = 74, train_loss = 0.4140871465206146, valid_spearman = 0.2010722821039716\n",
      "epoch = 75, train_loss = 0.41289401054382324, valid_spearman = 0.20286581188953295\n",
      "epoch = 76, train_loss = 0.41174232959747314, valid_spearman = 0.20454744033487327\n",
      "epoch = 77, train_loss = 0.4106258451938629, valid_spearman = 0.206161964466464\n",
      "epoch = 78, train_loss = 0.4095509946346283, valid_spearman = 0.20784599648780233\n",
      "epoch = 79, train_loss = 0.40851154923439026, valid_spearman = 0.20946558989278075\n",
      "epoch = 80, train_loss = 0.4075092077255249, valid_spearman = 0.21108025101613898\n",
      "epoch = 81, train_loss = 0.406543105840683, valid_spearman = 0.212632965119767\n",
      "epoch = 82, train_loss = 0.4056142568588257, valid_spearman = 0.2141199936961517\n",
      "epoch = 83, train_loss = 0.40472057461738586, valid_spearman = 0.21556438625303234\n",
      "epoch = 84, train_loss = 0.4038638770580292, valid_spearman = 0.21697504971664264\n",
      "epoch = 85, train_loss = 0.4030342996120453, valid_spearman = 0.21838915829948732\n",
      "epoch = 86, train_loss = 0.4022286534309387, valid_spearman = 0.21969533165687471\n",
      "epoch = 87, train_loss = 0.40145549178123474, valid_spearman = 0.22092235886499503\n",
      "epoch = 88, train_loss = 0.4007028341293335, valid_spearman = 0.2221749495639953\n",
      "epoch = 89, train_loss = 0.3999693989753723, valid_spearman = 0.223396420619262\n",
      "epoch = 90, train_loss = 0.3992662727832794, valid_spearman = 0.2245638753929468\n",
      "epoch = 91, train_loss = 0.39857929944992065, valid_spearman = 0.2257584175594878\n",
      "epoch = 92, train_loss = 0.3979085087776184, valid_spearman = 0.22698565901649664\n",
      "epoch = 93, train_loss = 0.39725664258003235, valid_spearman = 0.22818287268218954\n",
      "epoch = 94, train_loss = 0.39662593603134155, valid_spearman = 0.22942902174707475\n",
      "epoch = 95, train_loss = 0.3960028290748596, valid_spearman = 0.23068309303399406\n",
      "epoch = 96, train_loss = 0.39539745450019836, valid_spearman = 0.23189033918990873\n",
      "epoch = 97, train_loss = 0.3948051631450653, valid_spearman = 0.23314745355993016\n",
      "epoch = 98, train_loss = 0.3942277133464813, valid_spearman = 0.23433056194774735\n",
      "epoch = 99, train_loss = 0.3936621844768524, valid_spearman = 0.23551427747172418\n",
      "epoch = 100, train_loss = 0.393111914396286, valid_spearman = 0.2366233793752336\n",
      "epoch = 101, train_loss = 0.39257490634918213, valid_spearman = 0.23778825975555\n",
      "epoch = 102, train_loss = 0.39204710721969604, valid_spearman = 0.2388701275489246\n",
      "epoch = 103, train_loss = 0.39153048396110535, valid_spearman = 0.23996308134556807\n",
      "epoch = 104, train_loss = 0.3910268545150757, valid_spearman = 0.24099332165401746\n",
      "epoch = 105, train_loss = 0.39053094387054443, valid_spearman = 0.24197294906589326\n",
      "epoch = 106, train_loss = 0.39005133509635925, valid_spearman = 0.24292833728597826\n",
      "epoch = 107, train_loss = 0.38957205414772034, valid_spearman = 0.24384290561998384\n",
      "epoch = 108, train_loss = 0.389104962348938, valid_spearman = 0.24482789034188285\n",
      "epoch = 109, train_loss = 0.3886480927467346, valid_spearman = 0.24581946401999286\n",
      "epoch = 110, train_loss = 0.388205349445343, valid_spearman = 0.24674608253796276\n",
      "epoch = 111, train_loss = 0.38776516914367676, valid_spearman = 0.24771397684361113\n",
      "epoch = 112, train_loss = 0.38733530044555664, valid_spearman = 0.2486876071756698\n",
      "epoch = 113, train_loss = 0.3869139552116394, valid_spearman = 0.24962811613403438\n",
      "epoch = 114, train_loss = 0.38649702072143555, valid_spearman = 0.2505752361444124\n",
      "epoch = 115, train_loss = 0.38609078526496887, valid_spearman = 0.25159641942896865\n",
      "epoch = 116, train_loss = 0.38568758964538574, valid_spearman = 0.2525809045660937\n",
      "epoch = 117, train_loss = 0.38529637455940247, valid_spearman = 0.2535137238140613\n",
      "epoch = 118, train_loss = 0.3849063217639923, valid_spearman = 0.2544284137263461\n",
      "epoch = 119, train_loss = 0.384529709815979, valid_spearman = 0.2553595551195179\n",
      "epoch = 120, train_loss = 0.3841598927974701, valid_spearman = 0.25631919979632206\n",
      "epoch = 121, train_loss = 0.38379350304603577, valid_spearman = 0.25724142395573407\n",
      "epoch = 122, train_loss = 0.38343122601509094, valid_spearman = 0.25812072242272605\n",
      "epoch = 123, train_loss = 0.38307690620422363, valid_spearman = 0.25895364245375474\n",
      "epoch = 124, train_loss = 0.38272759318351746, valid_spearman = 0.2597558473051302\n",
      "epoch = 125, train_loss = 0.3823825418949127, valid_spearman = 0.2605900652960439\n",
      "epoch = 126, train_loss = 0.3820410966873169, valid_spearman = 0.26137147972865354\n",
      "epoch = 127, train_loss = 0.381707102060318, valid_spearman = 0.26214815533399705\n",
      "epoch = 128, train_loss = 0.3813737630844116, valid_spearman = 0.26291076325059565\n",
      "epoch = 129, train_loss = 0.3810521960258484, valid_spearman = 0.2636703351112007\n",
      "epoch = 130, train_loss = 0.3807302713394165, valid_spearman = 0.2644083766230534\n",
      "epoch = 131, train_loss = 0.3804168403148651, valid_spearman = 0.26513456531270385\n",
      "epoch = 132, train_loss = 0.38010337948799133, valid_spearman = 0.26590681065644023\n",
      "epoch = 133, train_loss = 0.3797931969165802, valid_spearman = 0.2666549501058721\n",
      "epoch = 134, train_loss = 0.379489928483963, valid_spearman = 0.26739756651886126\n",
      "epoch = 135, train_loss = 0.3791921138763428, valid_spearman = 0.2681230076196854\n",
      "epoch = 136, train_loss = 0.3788946270942688, valid_spearman = 0.26879974946143875\n",
      "epoch = 137, train_loss = 0.3785995543003082, valid_spearman = 0.26948889794482367\n",
      "epoch = 138, train_loss = 0.37831196188926697, valid_spearman = 0.27018282623171336\n",
      "epoch = 139, train_loss = 0.3780234754085541, valid_spearman = 0.27087949439080394\n",
      "epoch = 140, train_loss = 0.3777390718460083, valid_spearman = 0.27156154412849914\n",
      "epoch = 141, train_loss = 0.3774591088294983, valid_spearman = 0.272191845043166\n",
      "epoch = 142, train_loss = 0.3771786093711853, valid_spearman = 0.27282182568255187\n",
      "epoch = 143, train_loss = 0.3769044578075409, valid_spearman = 0.27340048167690617\n",
      "epoch = 144, train_loss = 0.3766341507434845, valid_spearman = 0.2740032049880564\n",
      "epoch = 145, train_loss = 0.37636280059814453, valid_spearman = 0.2746198772709992\n",
      "epoch = 146, train_loss = 0.3760942220687866, valid_spearman = 0.27515014995585746\n",
      "epoch = 147, train_loss = 0.3758333623409271, valid_spearman = 0.27565988114126055\n",
      "epoch = 148, train_loss = 0.3755672574043274, valid_spearman = 0.2762039103800442\n",
      "epoch = 149, train_loss = 0.3753061294555664, valid_spearman = 0.27670732096698747\n",
      "epoch = 150, train_loss = 0.37504830956459045, valid_spearman = 0.2772385276964379\n",
      "epoch = 151, train_loss = 0.3747914433479309, valid_spearman = 0.27769526145958956\n",
      "epoch = 152, train_loss = 0.3745376169681549, valid_spearman = 0.27816204198609235\n",
      "epoch = 153, train_loss = 0.37428784370422363, valid_spearman = 0.27862344098585395\n",
      "epoch = 154, train_loss = 0.3740350604057312, valid_spearman = 0.2790992168398904\n",
      "epoch = 155, train_loss = 0.3737852871417999, valid_spearman = 0.2795149860330154\n",
      "epoch = 156, train_loss = 0.37353837490081787, valid_spearman = 0.2799531045761314\n",
      "epoch = 157, train_loss = 0.37329038977622986, valid_spearman = 0.2803425903301199\n",
      "epoch = 158, train_loss = 0.37304168939590454, valid_spearman = 0.28075639370912614\n",
      "epoch = 159, train_loss = 0.3728008270263672, valid_spearman = 0.2811883812117933\n",
      "epoch = 160, train_loss = 0.3725629448890686, valid_spearman = 0.2815978047456894\n",
      "epoch = 161, train_loss = 0.3723231554031372, valid_spearman = 0.28203859164185135\n",
      "epoch = 162, train_loss = 0.37208443880081177, valid_spearman = 0.28242943831353184\n",
      "epoch = 163, train_loss = 0.3718465566635132, valid_spearman = 0.2828529455987081\n",
      "epoch = 164, train_loss = 0.37160876393318176, valid_spearman = 0.2832647703824374\n",
      "epoch = 165, train_loss = 0.3713756799697876, valid_spearman = 0.2836457311624128\n",
      "epoch = 166, train_loss = 0.3711438775062561, valid_spearman = 0.2840069634285905\n",
      "epoch = 167, train_loss = 0.37091121077537537, valid_spearman = 0.28439515877153115\n",
      "epoch = 168, train_loss = 0.37068358063697815, valid_spearman = 0.2847479305515064\n",
      "epoch = 169, train_loss = 0.37045446038246155, valid_spearman = 0.2851356670731208\n",
      "epoch = 170, train_loss = 0.3702254593372345, valid_spearman = 0.28551124627523733\n",
      "epoch = 171, train_loss = 0.3699979782104492, valid_spearman = 0.2858821812445213\n",
      "epoch = 172, train_loss = 0.36977115273475647, valid_spearman = 0.2863042159666265\n",
      "epoch = 173, train_loss = 0.36954864859580994, valid_spearman = 0.286670815607095\n",
      "epoch = 174, train_loss = 0.36932697892189026, valid_spearman = 0.2870419441118681\n",
      "epoch = 175, train_loss = 0.36910611391067505, valid_spearman = 0.2873919026648263\n",
      "epoch = 176, train_loss = 0.3688841760158539, valid_spearman = 0.28773300475944547\n",
      "epoch = 177, train_loss = 0.36866965889930725, valid_spearman = 0.28809257797634913\n",
      "epoch = 178, train_loss = 0.36845076084136963, valid_spearman = 0.2884125026368557\n",
      "epoch = 179, train_loss = 0.36823126673698425, valid_spearman = 0.28874259405838704\n",
      "epoch = 180, train_loss = 0.3680172264575958, valid_spearman = 0.28907388424945507\n",
      "epoch = 181, train_loss = 0.3678027391433716, valid_spearman = 0.28940886604314164\n",
      "epoch = 182, train_loss = 0.3675893545150757, valid_spearman = 0.2897757045284565\n",
      "epoch = 183, train_loss = 0.3673788607120514, valid_spearman = 0.2901342535571602\n",
      "epoch = 184, train_loss = 0.3671688139438629, valid_spearman = 0.29045575654009187\n",
      "epoch = 185, train_loss = 0.3669617176055908, valid_spearman = 0.2907948165910834\n",
      "epoch = 186, train_loss = 0.3667519688606262, valid_spearman = 0.2911441297656481\n",
      "epoch = 187, train_loss = 0.3665432929992676, valid_spearman = 0.29145236588530105\n",
      "epoch = 188, train_loss = 0.3663412630558014, valid_spearman = 0.29173042822044054\n",
      "epoch = 189, train_loss = 0.366136759519577, valid_spearman = 0.2920115436895207\n",
      "epoch = 190, train_loss = 0.36593353748321533, valid_spearman = 0.29230333884196574\n",
      "epoch = 191, train_loss = 0.365732878446579, valid_spearman = 0.29260720586826494\n",
      "epoch = 192, train_loss = 0.3655310869216919, valid_spearman = 0.2928977960071083\n",
      "epoch = 193, train_loss = 0.3653285801410675, valid_spearman = 0.29317315394968585\n",
      "epoch = 194, train_loss = 0.36513233184814453, valid_spearman = 0.2935114773014119\n",
      "epoch = 195, train_loss = 0.3649337887763977, valid_spearman = 0.2937960209461047\n",
      "epoch = 196, train_loss = 0.3647383451461792, valid_spearman = 0.2940592440734272\n",
      "epoch = 197, train_loss = 0.364544153213501, valid_spearman = 0.2943330699158162\n",
      "epoch = 198, train_loss = 0.364347368478775, valid_spearman = 0.2946241642926602\n",
      "epoch = 199, train_loss = 0.3641561269760132, valid_spearman = 0.2948884128507435\n",
      "epoch = 200, train_loss = 0.3639669716358185, valid_spearman = 0.29513893039503997\n",
      "epoch = 201, train_loss = 0.3637791872024536, valid_spearman = 0.29539566041965054\n",
      "epoch = 202, train_loss = 0.36359140276908875, valid_spearman = 0.295685525895418\n",
      "epoch = 203, train_loss = 0.36340680718421936, valid_spearman = 0.2959750861088487\n",
      "epoch = 204, train_loss = 0.3632211685180664, valid_spearman = 0.2962435176347998\n",
      "epoch = 205, train_loss = 0.3630371391773224, valid_spearman = 0.29650316585213665\n",
      "epoch = 206, train_loss = 0.362852543592453, valid_spearman = 0.296754975170426\n",
      "epoch = 207, train_loss = 0.36266905069351196, valid_spearman = 0.29698910393973116\n",
      "epoch = 208, train_loss = 0.3624895215034485, valid_spearman = 0.29725775245545216\n",
      "epoch = 209, train_loss = 0.36230960488319397, valid_spearman = 0.29748070539955085\n",
      "epoch = 210, train_loss = 0.36213192343711853, valid_spearman = 0.297734666650211\n",
      "epoch = 211, train_loss = 0.36195749044418335, valid_spearman = 0.29798135050356245\n",
      "epoch = 212, train_loss = 0.361777663230896, valid_spearman = 0.29820173366296715\n",
      "epoch = 213, train_loss = 0.3616052269935608, valid_spearman = 0.2984484661012896\n",
      "epoch = 214, train_loss = 0.36143213510513306, valid_spearman = 0.29865090298249086\n",
      "epoch = 215, train_loss = 0.3612598180770874, valid_spearman = 0.2988390852031214\n",
      "epoch = 216, train_loss = 0.3610883355140686, valid_spearman = 0.299055543070945\n",
      "epoch = 217, train_loss = 0.36091843247413635, valid_spearman = 0.2992645396168138\n",
      "epoch = 218, train_loss = 0.36074551939964294, valid_spearman = 0.2994858992314106\n",
      "epoch = 219, train_loss = 0.36057886481285095, valid_spearman = 0.299690087329302\n",
      "epoch = 220, train_loss = 0.36041298508644104, valid_spearman = 0.2999090350757306\n",
      "epoch = 221, train_loss = 0.3602469265460968, valid_spearman = 0.3000826347822326\n",
      "epoch = 222, train_loss = 0.36008355021476746, valid_spearman = 0.30027240761896223\n",
      "epoch = 223, train_loss = 0.3599213659763336, valid_spearman = 0.30045971781261843\n",
      "epoch = 224, train_loss = 0.3597550094127655, valid_spearman = 0.30066151888830617\n",
      "epoch = 225, train_loss = 0.35959506034851074, valid_spearman = 0.30085247883126703\n",
      "epoch = 226, train_loss = 0.3594364523887634, valid_spearman = 0.30106271965327824\n",
      "epoch = 227, train_loss = 0.3592764735221863, valid_spearman = 0.30121903315498955\n",
      "epoch = 228, train_loss = 0.35911881923675537, valid_spearman = 0.30139043624736866\n",
      "epoch = 229, train_loss = 0.35896167159080505, valid_spearman = 0.3015404714005384\n",
      "epoch = 230, train_loss = 0.3588075041770935, valid_spearman = 0.30170054167842547\n",
      "epoch = 231, train_loss = 0.3586529791355133, valid_spearman = 0.30188660084810626\n",
      "epoch = 232, train_loss = 0.3584979772567749, valid_spearman = 0.30204358864199626\n",
      "epoch = 233, train_loss = 0.35834360122680664, valid_spearman = 0.3021806733473936\n",
      "epoch = 234, train_loss = 0.3581918776035309, valid_spearman = 0.3023076622451052\n",
      "epoch = 235, train_loss = 0.3580375909805298, valid_spearman = 0.3024238077938604\n",
      "epoch = 236, train_loss = 0.35788679122924805, valid_spearman = 0.30252883144077986\n",
      "epoch = 237, train_loss = 0.3577372133731842, valid_spearman = 0.302651383238439\n",
      "epoch = 238, train_loss = 0.35758793354034424, valid_spearman = 0.302803902193812\n",
      "epoch = 239, train_loss = 0.3574410676956177, valid_spearman = 0.30295135936567524\n",
      "epoch = 240, train_loss = 0.3572919964790344, valid_spearman = 0.30307180199679296\n",
      "epoch = 241, train_loss = 0.3571455180644989, valid_spearman = 0.3031907001271392\n",
      "epoch = 242, train_loss = 0.3569997251033783, valid_spearman = 0.3032826959911257\n",
      "epoch = 243, train_loss = 0.35685718059539795, valid_spearman = 0.3033915818211374\n",
      "epoch = 244, train_loss = 0.35671359300613403, valid_spearman = 0.30351519716003433\n",
      "epoch = 245, train_loss = 0.35656875371932983, valid_spearman = 0.30362980841858267\n",
      "epoch = 246, train_loss = 0.356428861618042, valid_spearman = 0.30371928762731526\n",
      "epoch = 247, train_loss = 0.35628777742385864, valid_spearman = 0.3038177450953273\n",
      "epoch = 248, train_loss = 0.3561471104621887, valid_spearman = 0.30392248224020124\n",
      "epoch = 249, train_loss = 0.3560061752796173, valid_spearman = 0.30397741399933714\n",
      "epoch = 250, train_loss = 0.3558652102947235, valid_spearman = 0.3040606762250208\n",
      "epoch = 251, train_loss = 0.3557313084602356, valid_spearman = 0.30411072690176716\n",
      "epoch = 252, train_loss = 0.3555939197540283, valid_spearman = 0.304178523876648\n",
      "epoch = 253, train_loss = 0.3554557263851166, valid_spearman = 0.3042631876968797\n",
      "epoch = 254, train_loss = 0.3553183674812317, valid_spearman = 0.3043529924957814\n",
      "epoch = 255, train_loss = 0.35518351197242737, valid_spearman = 0.3044491106654426\n",
      "epoch = 256, train_loss = 0.3550483286380768, valid_spearman = 0.304527737847611\n",
      "epoch = 257, train_loss = 0.35491612553596497, valid_spearman = 0.3046039092064365\n",
      "epoch = 258, train_loss = 0.3547857403755188, valid_spearman = 0.3046629309010764\n",
      "epoch = 259, train_loss = 0.35465511679649353, valid_spearman = 0.30474221361458403\n",
      "epoch = 260, train_loss = 0.3545258045196533, valid_spearman = 0.3048050758312141\n",
      "epoch = 261, train_loss = 0.35439592599868774, valid_spearman = 0.3048442493109577\n",
      "epoch = 262, train_loss = 0.35426753759384155, valid_spearman = 0.3048852046515133\n",
      "epoch = 263, train_loss = 0.35413768887519836, valid_spearman = 0.30492807046533094\n",
      "epoch = 264, train_loss = 0.354010671377182, valid_spearman = 0.3049528232644657\n",
      "epoch = 265, train_loss = 0.3538838028907776, valid_spearman = 0.30501203153915957\n",
      "epoch = 266, train_loss = 0.35376131534576416, valid_spearman = 0.30503311492024715\n",
      "epoch = 267, train_loss = 0.35363611578941345, valid_spearman = 0.3051091150954289\n",
      "epoch = 268, train_loss = 0.3535120487213135, valid_spearman = 0.30515580026235584\n",
      "epoch = 269, train_loss = 0.3533880412578583, valid_spearman = 0.30523154775264266\n",
      "epoch = 270, train_loss = 0.3532674312591553, valid_spearman = 0.3052481265969717\n",
      "epoch = 271, train_loss = 0.35314586758613586, valid_spearman = 0.3053076529367388\n",
      "epoch = 272, train_loss = 0.3530261516571045, valid_spearman = 0.30534514805609125\n",
      "epoch = 273, train_loss = 0.3529035449028015, valid_spearman = 0.30537862890693435\n",
      "epoch = 274, train_loss = 0.3527849018573761, valid_spearman = 0.3054125509025285\n",
      "epoch = 275, train_loss = 0.35266757011413574, valid_spearman = 0.30548551718215256\n",
      "epoch = 276, train_loss = 0.35254859924316406, valid_spearman = 0.30556773661023773\n",
      "epoch = 277, train_loss = 0.35243159532546997, valid_spearman = 0.3056122061794842\n",
      "epoch = 278, train_loss = 0.3523138463497162, valid_spearman = 0.30567111952317466\n",
      "epoch = 279, train_loss = 0.35220035910606384, valid_spearman = 0.3056994494067754\n",
      "epoch = 280, train_loss = 0.3520841896533966, valid_spearman = 0.3057121868431281\n",
      "epoch = 281, train_loss = 0.35196933150291443, valid_spearman = 0.3057289291936853\n",
      "epoch = 282, train_loss = 0.3518562614917755, valid_spearman = 0.30575257004194195\n",
      "epoch = 283, train_loss = 0.35173946619033813, valid_spearman = 0.3057848118129579\n",
      "epoch = 284, train_loss = 0.35162627696990967, valid_spearman = 0.3057998259229074\n",
      "epoch = 285, train_loss = 0.3515133857727051, valid_spearman = 0.30584590622034136\n",
      "epoch = 286, train_loss = 0.3513994812965393, valid_spearman = 0.3058531744384466\n",
      "epoch = 287, train_loss = 0.35129231214523315, valid_spearman = 0.3058756702203997\n",
      "epoch = 288, train_loss = 0.35118138790130615, valid_spearman = 0.3058872223290812\n",
      "epoch = 289, train_loss = 0.35107046365737915, valid_spearman = 0.30591868156108537\n",
      "epoch = 290, train_loss = 0.3509610891342163, valid_spearman = 0.3059536942672732\n",
      "epoch = 291, train_loss = 0.35085371136665344, valid_spearman = 0.3059561330089435\n",
      "epoch = 292, train_loss = 0.350745290517807, valid_spearman = 0.3059805166536761\n",
      "epoch = 293, train_loss = 0.35063907504081726, valid_spearman = 0.3060304073658765\n",
      "epoch = 294, train_loss = 0.3505324125289917, valid_spearman = 0.30608201715904737\n",
      "epoch = 295, train_loss = 0.3504241108894348, valid_spearman = 0.30608152432695135\n",
      "epoch = 296, train_loss = 0.35032013058662415, valid_spearman = 0.3061330807855356\n",
      "epoch = 297, train_loss = 0.3502143621444702, valid_spearman = 0.3061697366266403\n",
      "epoch = 298, train_loss = 0.3501092493534088, valid_spearman = 0.30620518283934006\n",
      "epoch = 299, train_loss = 0.35000526905059814, valid_spearman = 0.3062135438642658\n",
      "epoch = 300, train_loss = 0.34990057349205017, valid_spearman = 0.30625658254396065\n",
      "epoch = 301, train_loss = 0.3497994542121887, valid_spearman = 0.30628409524973893\n",
      "epoch = 302, train_loss = 0.3496960699558258, valid_spearman = 0.306345480821654\n",
      "epoch = 303, train_loss = 0.3495931029319763, valid_spearman = 0.30635422919692645\n",
      "epoch = 304, train_loss = 0.34949228167533875, valid_spearman = 0.30640163172273827\n",
      "epoch = 305, train_loss = 0.34939172863960266, valid_spearman = 0.30642264300593797\n",
      "epoch = 306, train_loss = 0.34929224848747253, valid_spearman = 0.30646547740620217\n",
      "epoch = 307, train_loss = 0.34919366240501404, valid_spearman = 0.3064896540805387\n",
      "epoch = 308, train_loss = 0.34909412264823914, valid_spearman = 0.30651907280698354\n",
      "epoch = 309, train_loss = 0.34899666905403137, valid_spearman = 0.306558521173477\n",
      "epoch = 310, train_loss = 0.34889698028564453, valid_spearman = 0.30655590474201605\n",
      "epoch = 311, train_loss = 0.34879884123802185, valid_spearman = 0.3065396670121609\n",
      "question_asker_intent_understanding rho: 0.23693753414050767\n",
      "question_body_critical rho: 0.574804890469906\n",
      "question_conversational rho: 0.2979807176107577\n",
      "question_expect_short_answer rho: 0.21562295315250563\n",
      "question_fact_seeking rho: 0.205781321204878\n",
      "question_has_commonly_accepted_answer rho: 0.31674439420686556\n",
      "question_interestingness_others rho: 0.33495381487047343\n",
      "question_interestingness_self rho: 0.4480093830216719\n",
      "question_multi_intent rho: 0.3936407038889184\n",
      "question_not_really_a_question rho: 0.047067875003321456\n",
      "question_opinion_seeking rho: 0.2889198971579979\n",
      "question_type_choice rho: 0.5345618513746615\n",
      "question_type_compare rho: 0.22312579339775787\n",
      "question_type_consequence rho: 0.07951504296999926\n",
      "question_type_definition rho: 0.3258593377801806\n",
      "question_type_entity rho: 0.31918070577904517\n",
      "question_type_instructions rho: 0.6723290475316626\n",
      "question_type_procedure rho: 0.2263026447928176\n",
      "question_type_reason_explanation rho: 0.517916873369814\n",
      "question_type_spelling rho: 0.06669376954542375\n",
      "question_well_written rho: 0.49236866658807477\n",
      "answer_helpful rho: 0.14218107566588364\n",
      "answer_level_of_information rho: 0.36867017887222875\n",
      "answer_plausible rho: 0.058195725853928126\n",
      "answer_relevance rho: 0.11047974412899605\n",
      "answer_satisfaction rho: 0.1756587265265463\n",
      "answer_type_instructions rho: 0.660432604385714\n",
      "answer_type_procedure rho: 0.2258304859396125\n",
      "answer_type_reason_explanation rho: 0.5589147013745076\n",
      "answer_well_written rho: 0.07750954976016979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "import math\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "scores = []\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_splits).split(X=train_dset.question_body, groups=train_dset.question_body)\n",
    "\n",
    "pytorch_params = {\n",
    "    'in_features': x_train.shape[1],\n",
    "    'out_features': y_train.shape[1],\n",
    "    'n_epochs': 2500,\n",
    "    'patience': 2\n",
    "}\n",
    "\n",
    "trained_estimators = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    x_train_train = x_train[train_idx]\n",
    "    y_train_train = y_train[train_idx]\n",
    "    x_train_valid = x_train[valid_idx]\n",
    "    y_train_valid = y_train[valid_idx]\n",
    "\n",
    "    print(f'fold = {fold}')\n",
    "    estimator = PyTorch(**pytorch_params)\n",
    "    estimator, rho_cols = estimator.fit(x_train_train, y_train_train, x_train_valid, y_train_valid)\n",
    "\n",
    "    trained_estimators.append(estimator)\n",
    "    rho_print = [print(target_columns[i] + \" rho: \" + str(rho_cols[i]) ) for i in range(0, len(target_columns))]\n",
    "\n",
    "y_pred = []\n",
    "for estimator in trained_estimators:\n",
    "    y_pred.append(estimator.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\", index_col='qa_id')\n",
    "\n",
    "out = pd.DataFrame(index=submission.index)\n",
    "\n",
    "for column_idx,column in enumerate(target_columns):\n",
    "    column_data = pd.DataFrame(index=submission.index)\n",
    "    for prediction_idx,prediction in enumerate(y_pred):\n",
    "        column_data[str(prediction_idx)] = prediction[:, column_idx]\n",
    "    \n",
    "    out[column] = np.average(column_data, axis=1)\n",
    "\n",
    "out.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
