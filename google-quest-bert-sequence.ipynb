{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple BERT test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing preprocessed dataset with BERT minimalistic model from: https://www.kaggle.com/khoongweihao/bert-base-tf2-0-minimalistic-iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def set_seeds(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "SEED = 21937\n",
    "set_seeds(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dset = pd.read_csv(\"../input/google-quest-challenge/train.csv\")   # index_col='qa_id'\n",
    "test_dset = pd.read_csv(\"../input/google-quest-challenge/test.csv\")   # index_col='qa_id'\n",
    "df_sub = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\n",
    "\n",
    "free_text_columns = ['question_title', 'question_body', 'answer']\n",
    "\n",
    "category_columns = ['host', 'category']\n",
    "\n",
    "discard_columns = ['question_user_name', 'question_user_page',  'answer_user_name', 'answer_user_page', 'url']\n",
    "\n",
    "target_columns = ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational',\n",
    "                  'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "                  'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent',\n",
    "                  'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "                  'question_type_compare', 'question_type_consequence', 'question_type_definition',\n",
    "                  'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "                  'question_type_reason_explanation', 'question_type_spelling', 'question_well_written',\n",
    "                  'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "                  'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure',\n",
    "                  'answer_type_reason_explanation', 'answer_well_written']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../input/google-quest-challenge/'\n",
    "BERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n",
    "tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "\n",
    "output_categories = target_columns\n",
    "input_categories = ['question_title', 'question_body', 'answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = q[:q_new_len]\n",
    "        a = a[:a_new_len]\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, prefix, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance[prefix+'question_title'], instance[prefix+'question_body'], instance[prefix+'answer']   # instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "def compute_spearmanr2(preds, trues):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.nanmean(rhos), rhos\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predicted = self.model.predict(self.valid_inputs, batch_size=self.batch_size)\n",
    "        self.valid_predictions.append(predicted)\n",
    "        \n",
    "        rho_val = compute_spearmanr(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(f'epoch = {epoch}, valid_spearman = {rho_val}') \n",
    "        self.test_predictions.append(\n",
    "            self.model.predict(self.test_inputs, batch_size=self.batch_size))\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        score, rho_cols = compute_spearmanr2(np.average(self.valid_predictions, axis=0), self.valid_outputs)\n",
    "        rho_print = [print(target_columns[i] + \" rho: \" + str(rho_cols[i]) ) for i in range(0, len(target_columns))]  \n",
    "       \n",
    "        \n",
    "        \n",
    "def bert_model():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n",
    "    \n",
    "    return model    \n",
    "        \n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold):\n",
    "        \n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=None)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38d175bb5204f3589222aecf2570df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581961b8cd0b44ff864958a6b6bb2005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=5).split(X=train_dset.question_body, groups=train_dset.question_body)\n",
    "\n",
    "prefix = '' # 'clean_'\n",
    "outputs = compute_output_arrays(train_dset, output_categories)\n",
    "inputs = compute_input_arays(train_dset, input_categories, prefix, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arays(test_dset, input_categories, prefix, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3958epoch = 0, valid_spearman = 0.36712222147544904\n",
      "4863/4863 [==============================] - 383s 79ms/sample - loss: 0.3959\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3654epoch = 1, valid_spearman = 0.3860540456941088\n",
      "4863/4863 [==============================] - 354s 73ms/sample - loss: 0.3654\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3482epoch = 2, valid_spearman = 0.39491118004336906\n",
      "4863/4863 [==============================] - 354s 73ms/sample - loss: 0.3481\n",
      "question_asker_intent_understanding rho: 0.3962614795833214\n",
      "question_body_critical rho: 0.6255129701076222\n",
      "question_conversational rho: 0.3860775318581291\n",
      "question_expect_short_answer rho: 0.30054662483066313\n",
      "question_fact_seeking rho: 0.3632949828196535\n",
      "question_has_commonly_accepted_answer rho: 0.4169553828292324\n",
      "question_interestingness_others rho: 0.3471705354634398\n",
      "question_interestingness_self rho: 0.4616583557582801\n",
      "question_multi_intent rho: 0.5425816918929964\n",
      "question_not_really_a_question rho: 0.060480286448173354\n",
      "question_opinion_seeking rho: 0.4325403176080822\n",
      "question_type_choice rho: 0.7172161615453545\n",
      "question_type_compare rho: 0.35719615202944327\n",
      "question_type_consequence rho: 0.14642165466807872\n",
      "question_type_definition rho: 0.37512403508421754\n",
      "question_type_entity rho: 0.5156850579565658\n",
      "question_type_instructions rho: 0.7890344331334717\n",
      "question_type_procedure rho: 0.3702830489013259\n",
      "question_type_reason_explanation rho: 0.6437904077280967\n",
      "question_type_spelling rho: 0.032486744210966124\n",
      "question_well_written rho: 0.4754230111470396\n",
      "answer_helpful rho: 0.2260778145950948\n",
      "answer_level_of_information rho: 0.36928579770092423\n",
      "answer_plausible rho: 0.11053099321764524\n",
      "answer_relevance rho: 0.16249053782709175\n",
      "answer_satisfaction rho: 0.3096700363497664\n",
      "answer_type_instructions rho: 0.7698632240788599\n",
      "answer_type_procedure rho: 0.307957376201967\n",
      "answer_type_reason_explanation rho: 0.657168021405389\n",
      "answer_well_written rho: 0.17855644030982482\n",
      "fold 1\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3968epoch = 0, valid_spearman = 0.35539136460338605\n",
      "4863/4863 [==============================] - 382s 79ms/sample - loss: 0.3969\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3659epoch = 1, valid_spearman = 0.37552831837179085\n",
      "4863/4863 [==============================] - 354s 73ms/sample - loss: 0.3660\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3470epoch = 2, valid_spearman = 0.3824410625550173\n",
      "4863/4863 [==============================] - 354s 73ms/sample - loss: 0.3469\n",
      "question_asker_intent_understanding rho: 0.3646284720227473\n",
      "question_body_critical rho: 0.6163833542703316\n",
      "question_conversational rho: 0.38334251645922657\n",
      "question_expect_short_answer rho: 0.29172741302865085\n",
      "question_fact_seeking rho: 0.35606884595346383\n",
      "question_has_commonly_accepted_answer rho: 0.4192821056452411\n",
      "question_interestingness_others rho: 0.3212990173545968\n",
      "question_interestingness_self rho: 0.4251198814506788\n",
      "question_multi_intent rho: 0.5398860295767891\n",
      "question_not_really_a_question rho: 0.10926319188244875\n",
      "question_opinion_seeking rho: 0.4698119891136406\n",
      "question_type_choice rho: 0.723695924508735\n",
      "question_type_compare rho: 0.34497904417650727\n",
      "question_type_consequence rho: 0.15919107739751756\n",
      "question_type_definition rho: 0.29680815312868947\n",
      "question_type_entity rho: 0.40509914768659117\n",
      "question_type_instructions rho: 0.7717295947956688\n",
      "question_type_procedure rho: 0.3389626528945427\n",
      "question_type_reason_explanation rho: 0.6394117665524162\n",
      "question_type_spelling rho: 0.05134664000166516\n",
      "question_well_written rho: 0.49500582793581077\n",
      "answer_helpful rho: 0.22529482470061218\n",
      "answer_level_of_information rho: 0.3878490019778246\n",
      "answer_plausible rho: 0.10486686622292354\n",
      "answer_relevance rho: 0.14830830342276358\n",
      "answer_satisfaction rho: 0.3224152601666782\n",
      "answer_type_instructions rho: 0.7290561687359961\n",
      "answer_type_procedure rho: 0.2670186265331392\n",
      "answer_type_reason_explanation rho: 0.6394335075579266\n",
      "answer_well_written rho: 0.12594773374954818\n",
      "fold 2\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.4006epoch = 0, valid_spearman = 0.37106856589554155\n",
      "4863/4863 [==============================] - 383s 79ms/sample - loss: 0.4006\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3689epoch = 1, valid_spearman = 0.39155292694612065\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3689\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3522epoch = 2, valid_spearman = 0.4019896490490128\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3522\n",
      "question_asker_intent_understanding rho: 0.3764196821446414\n",
      "question_body_critical rho: 0.5577723210679997\n",
      "question_conversational rho: 0.44261869909510587\n",
      "question_expect_short_answer rho: 0.31413741363932\n",
      "question_fact_seeking rho: 0.3758783982657218\n",
      "question_has_commonly_accepted_answer rho: 0.4737769389177462\n",
      "question_interestingness_others rho: 0.3206425646466709\n",
      "question_interestingness_self rho: 0.5363628968120704\n",
      "question_multi_intent rho: 0.5435895047092858\n",
      "question_not_really_a_question rho: 0.056733529970402215\n",
      "question_opinion_seeking rho: 0.5301807969391803\n",
      "question_type_choice rho: 0.7244844048725387\n",
      "question_type_compare rho: 0.37375103836015755\n",
      "question_type_consequence rho: 0.16707247963136906\n",
      "question_type_definition rho: 0.3631946781508335\n",
      "question_type_entity rho: 0.4241022910216875\n",
      "question_type_instructions rho: 0.7855911531999318\n",
      "question_type_procedure rho: 0.34198479052558495\n",
      "question_type_reason_explanation rho: 0.6630511898816654\n",
      "question_type_spelling rho: 0.03833066749205013\n",
      "question_well_written rho: 0.5103102413504442\n",
      "answer_helpful rho: 0.23040266096250564\n",
      "answer_level_of_information rho: 0.39518578995708503\n",
      "answer_plausible rho: 0.11772266271144893\n",
      "answer_relevance rho: 0.15690373409060848\n",
      "answer_satisfaction rho: 0.3265220810305295\n",
      "answer_type_instructions rho: 0.765426619674626\n",
      "answer_type_procedure rho: 0.31216721857690505\n",
      "answer_type_reason_explanation rho: 0.6720993822942924\n",
      "answer_well_written rho: 0.16327903678558264\n",
      "fold 3\n",
      "Train on 4863 samples\n",
      "Epoch 1/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3972epoch = 0, valid_spearman = 0.3649231069633961\n",
      "4863/4863 [==============================] - 381s 78ms/sample - loss: 0.3972\n",
      "Epoch 2/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3667epoch = 1, valid_spearman = 0.38335864214901527\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3668\n",
      "Epoch 3/3\n",
      "4856/4863 [============================>.] - ETA: 0s - loss: 0.3487epoch = 2, valid_spearman = 0.3911231976707479\n",
      "4863/4863 [==============================] - 353s 73ms/sample - loss: 0.3488\n",
      "question_asker_intent_understanding rho: 0.3219028441081729\n",
      "question_body_critical rho: 0.5736464407575376\n",
      "question_conversational rho: 0.4422276374246061\n",
      "question_expect_short_answer rho: 0.31437838354417824\n",
      "question_fact_seeking rho: 0.32980592681568\n",
      "question_has_commonly_accepted_answer rho: 0.40776552435624\n",
      "question_interestingness_others rho: 0.348918428475942\n",
      "question_interestingness_self rho: 0.49474779852288353\n",
      "question_multi_intent rho: 0.5973298594076034\n",
      "question_not_really_a_question rho: 0.06518682916420979\n",
      "question_opinion_seeking rho: 0.4246362505727392\n",
      "question_type_choice rho: 0.7336202935231515\n",
      "question_type_compare rho: 0.3352589531477141\n",
      "question_type_consequence rho: 0.20492150263161546\n",
      "question_type_definition rho: 0.37400039823240316\n",
      "question_type_entity rho: 0.3907352291049636\n",
      "question_type_instructions rho: 0.780689697998831\n",
      "question_type_procedure rho: 0.3788164782525436\n",
      "question_type_reason_explanation rho: 0.6876064757601736\n",
      "question_type_spelling rho: 0.06868264993017927\n",
      "question_well_written rho: 0.4546062128376715\n",
      "answer_helpful rho: 0.1953955551817111\n",
      "answer_level_of_information rho: 0.3802627799409509\n",
      "answer_plausible rho: 0.10684132204103537\n",
      "answer_relevance rho: 0.15611790808604745\n",
      "answer_satisfaction rho: 0.287758380961256\n",
      "answer_type_instructions rho: 0.7574839393283015\n",
      "answer_type_procedure rho: 0.31091824172456867\n",
      "answer_type_reason_explanation rho: 0.6898488060854491\n",
      "answer_well_written rho: 0.11957727073625189\n",
      "fold 4\n",
      "Train on 4864 samples\n",
      "Epoch 1/3\n",
      "4856/4864 [============================>.] - ETA: 0s - loss: 0.3970epoch = 0, valid_spearman = 0.360535087658801\n",
      "4864/4864 [==============================] - 376s 77ms/sample - loss: 0.3970\n",
      "Epoch 2/3\n",
      "4856/4864 [============================>.] - ETA: 0s - loss: 0.3657epoch = 1, valid_spearman = 0.3762973760351874\n",
      "4864/4864 [==============================] - 351s 72ms/sample - loss: 0.3657\n",
      "Epoch 3/3\n",
      "4856/4864 [============================>.] - ETA: 0s - loss: 0.3480epoch = 2, valid_spearman = 0.3841344512995931\n",
      "4864/4864 [==============================] - 351s 72ms/sample - loss: 0.3480\n",
      "question_asker_intent_understanding rho: 0.36571079263412176\n",
      "question_body_critical rho: 0.5720084375711895\n",
      "question_conversational rho: 0.36554329128026597\n",
      "question_expect_short_answer rho: 0.31327008830797254\n",
      "question_fact_seeking rho: 0.2924463448252978\n",
      "question_has_commonly_accepted_answer rho: 0.43074189047518024\n",
      "question_interestingness_others rho: 0.359231931441515\n",
      "question_interestingness_self rho: 0.5296698734246272\n",
      "question_multi_intent rho: 0.5536135549757131\n",
      "question_not_really_a_question rho: 0.044986918748183564\n",
      "question_opinion_seeking rho: 0.41730642054482153\n",
      "question_type_choice rho: 0.7108493913764568\n",
      "question_type_compare rho: 0.3175388694033976\n",
      "question_type_consequence rho: 0.17357377813160882\n",
      "question_type_definition rho: 0.3802707966452319\n",
      "question_type_entity rho: 0.4683351433445989\n",
      "question_type_instructions rho: 0.7515650540871954\n",
      "question_type_procedure rho: 0.3134736296103787\n",
      "question_type_reason_explanation rho: 0.6485032347569971\n",
      "question_type_spelling rho: 0.08073215687813858\n",
      "question_well_written rho: 0.49446181696993036\n",
      "answer_helpful rho: 0.18564174439016884\n",
      "answer_level_of_information rho: 0.41123513390994065\n",
      "answer_plausible rho: 0.10726440642506871\n",
      "answer_relevance rho: 0.1454099001993566\n",
      "answer_satisfaction rho: 0.23262802275830666\n",
      "answer_type_instructions rho: 0.7509816464008888\n",
      "answer_type_procedure rho: 0.26825355705718296\n",
      "answer_type_reason_explanation rho: 0.6616938911115452\n",
      "answer_well_written rho: 0.1771083917408459\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    print(f\"fold {fold}\")\n",
    "    K.clear_session()\n",
    "    model = bert_model()\n",
    "\n",
    "    train_inputs = [inputs[i][train_idx] for i in range(3)]\n",
    "    train_outputs = outputs[train_idx]\n",
    "\n",
    "    valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n",
    "    valid_outputs = outputs[valid_idx]\n",
    "\n",
    "    # history contains two lists of valid and test preds respectively:\n",
    "    #  [valid_predictions_{fold}, test_predictions_{fold}]\n",
    "    history = train_and_predict(model, \n",
    "                      train_data=(train_inputs, train_outputs), \n",
    "                      valid_data=(valid_inputs, valid_outputs),\n",
    "                      test_data=test_inputs, \n",
    "                      learning_rate=3e-5, epochs=3, batch_size=8,\n",
    "                      loss_function='binary_crossentropy', fold=fold)\n",
    "\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = [histories[i].test_predictions for i in range(len(histories))]\n",
    "test_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\n",
    "test_predictions = np.mean(test_predictions, axis=0)\n",
    "\n",
    "df_sub.iloc[:, 1:] = test_predictions\n",
    "\n",
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16b1ca2e78994b88858ff4cfc0c35003": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f03bbd6397d04afa836a5761cdf34be1",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_44f0159fb03c4de9b8c8cda70437e072",
       "value": 1
      }
     },
     "2bbfad45aef343438e11a176bbb7e416": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "44f0159fb03c4de9b8c8cda70437e072": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "47e2c31511974011892f2e902a593f52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55d4e05e2bd8402b98bac8f239dd0d4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cf25631e9b00455f9c937e6c939eb8c5",
       "placeholder": "​",
       "style": "IPY_MODEL_f832387eb14b4de2a880a0723dc074fc",
       "value": " 6079/? [01:14&lt;00:00, 81.51it/s]"
      }
     },
     "56105ad9b6b24b68a510f50bc97a371f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "581961b8cd0b44ff864958a6b6bb2005": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_16b1ca2e78994b88858ff4cfc0c35003",
        "IPY_MODEL_bccacfd43c18423c87e7f7a9277426dd"
       ],
       "layout": "IPY_MODEL_56105ad9b6b24b68a510f50bc97a371f"
      }
     },
     "68ca1b569c114e7585f98e414aca8f9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b9658617f834a7ab902a4ade2af6c15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bccacfd43c18423c87e7f7a9277426dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_47e2c31511974011892f2e902a593f52",
       "placeholder": "​",
       "style": "IPY_MODEL_9b9658617f834a7ab902a4ade2af6c15",
       "value": " 476/? [00:06&lt;00:00, 73.69it/s]"
      }
     },
     "cf25631e9b00455f9c937e6c939eb8c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d38d175bb5204f3589222aecf2570df2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_def8de7e55a94562b2d622e180b29b64",
        "IPY_MODEL_55d4e05e2bd8402b98bac8f239dd0d4d"
       ],
       "layout": "IPY_MODEL_f9c91690020f40a6b95e2dba7ad5584b"
      }
     },
     "def8de7e55a94562b2d622e180b29b64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_68ca1b569c114e7585f98e414aca8f9c",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2bbfad45aef343438e11a176bbb7e416",
       "value": 1
      }
     },
     "f03bbd6397d04afa836a5761cdf34be1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f832387eb14b4de2a880a0723dc074fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f9c91690020f40a6b95e2dba7ad5584b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
